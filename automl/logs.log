2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:01:49,215:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:04:30,599:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:09:08,643:INFO:PyCaret ClassificationExperiment
2024-04-23 20:09:08,643:INFO:Logging name: clf-default-name
2024-04-23 20:09:08,643:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-23 20:09:08,643:INFO:version 3.1.0
2024-04-23 20:09:08,643:INFO:Initializing setup()
2024-04-23 20:09:08,643:INFO:self.USI: 4fd9
2024-04-23 20:09:08,643:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'fix_imbalance', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:09:08,643:INFO:Checking environment
2024-04-23 20:09:08,643:INFO:python_version: 3.10.0
2024-04-23 20:09:08,643:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:09:08,643:INFO:machine: AMD64
2024-04-23 20:09:08,651:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:09:08,654:INFO:Memory: svmem(total=17041117184, available=7162732544, percent=58.0, used=9878384640, free=7162732544)
2024-04-23 20:09:08,654:INFO:Physical Core: 6
2024-04-23 20:09:08,654:INFO:Logical Core: 12
2024-04-23 20:09:08,654:INFO:Checking libraries
2024-04-23 20:09:08,655:INFO:System:
2024-04-23 20:09:08,655:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:09:08,655:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:09:08,655:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:09:08,655:INFO:PyCaret required dependencies:
2024-04-23 20:09:08,741:INFO:                 pip: 21.2.3
2024-04-23 20:09:08,742:INFO:          setuptools: 57.4.0
2024-04-23 20:09:08,742:INFO:             pycaret: 3.1.0
2024-04-23 20:09:08,742:INFO:             IPython: 8.17.2
2024-04-23 20:09:08,742:INFO:          ipywidgets: 8.1.1
2024-04-23 20:09:08,742:INFO:                tqdm: 4.66.1
2024-04-23 20:09:08,742:INFO:               numpy: 1.25.2
2024-04-23 20:09:08,742:INFO:              pandas: 2.0.3
2024-04-23 20:09:08,742:INFO:              jinja2: 3.1.2
2024-04-23 20:09:08,742:INFO:               scipy: 1.10.1
2024-04-23 20:09:08,742:INFO:              joblib: 1.3.2
2024-04-23 20:09:08,742:INFO:             sklearn: 1.2.2
2024-04-23 20:09:08,742:INFO:                pyod: 1.1.1
2024-04-23 20:09:08,742:INFO:            imblearn: 0.11.0
2024-04-23 20:09:08,742:INFO:   category_encoders: 2.6.3
2024-04-23 20:09:08,742:INFO:            lightgbm: 4.1.0
2024-04-23 20:09:08,742:INFO:               numba: 0.58.1
2024-04-23 20:09:08,742:INFO:            requests: 2.31.0
2024-04-23 20:09:08,742:INFO:          matplotlib: 3.7.3
2024-04-23 20:09:08,742:INFO:          scikitplot: 0.3.7
2024-04-23 20:09:08,742:INFO:         yellowbrick: 1.5
2024-04-23 20:09:08,742:INFO:              plotly: 5.18.0
2024-04-23 20:09:08,742:INFO:    plotly-resampler: Not installed
2024-04-23 20:09:08,742:INFO:             kaleido: 0.2.1
2024-04-23 20:09:08,742:INFO:           schemdraw: 0.15
2024-04-23 20:09:08,742:INFO:         statsmodels: 0.14.0
2024-04-23 20:09:08,743:INFO:              sktime: 0.21.1
2024-04-23 20:09:08,743:INFO:               tbats: 1.1.3
2024-04-23 20:09:08,743:INFO:            pmdarima: 2.0.4
2024-04-23 20:09:08,743:INFO:              psutil: 5.9.6
2024-04-23 20:09:08,743:INFO:          markupsafe: 2.1.3
2024-04-23 20:09:08,743:INFO:             pickle5: Not installed
2024-04-23 20:09:08,743:INFO:         cloudpickle: 3.0.0
2024-04-23 20:09:08,743:INFO:         deprecation: 2.1.0
2024-04-23 20:09:08,743:INFO:              xxhash: 3.4.1
2024-04-23 20:09:08,743:INFO:           wurlitzer: Not installed
2024-04-23 20:09:08,743:INFO:PyCaret optional dependencies:
2024-04-23 20:09:08,756:INFO:                shap: Not installed
2024-04-23 20:09:08,756:INFO:           interpret: Not installed
2024-04-23 20:09:08,756:INFO:                umap: Not installed
2024-04-23 20:09:08,756:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:09:08,756:INFO:  explainerdashboard: Not installed
2024-04-23 20:09:08,756:INFO:             autoviz: Not installed
2024-04-23 20:09:08,756:INFO:           fairlearn: Not installed
2024-04-23 20:09:08,757:INFO:          deepchecks: Not installed
2024-04-23 20:09:08,757:INFO:             xgboost: Not installed
2024-04-23 20:09:08,757:INFO:            catboost: Not installed
2024-04-23 20:09:08,757:INFO:              kmodes: Not installed
2024-04-23 20:09:08,757:INFO:             mlxtend: Not installed
2024-04-23 20:09:08,757:INFO:       statsforecast: Not installed
2024-04-23 20:09:08,757:INFO:        tune_sklearn: Not installed
2024-04-23 20:09:08,757:INFO:                 ray: Not installed
2024-04-23 20:09:08,757:INFO:            hyperopt: Not installed
2024-04-23 20:09:08,757:INFO:              optuna: Not installed
2024-04-23 20:09:08,757:INFO:               skopt: Not installed
2024-04-23 20:09:08,757:INFO:              mlflow: Not installed
2024-04-23 20:09:08,757:INFO:              gradio: Not installed
2024-04-23 20:09:08,757:INFO:             fastapi: Not installed
2024-04-23 20:09:08,757:INFO:             uvicorn: Not installed
2024-04-23 20:09:08,757:INFO:              m2cgen: Not installed
2024-04-23 20:09:08,757:INFO:           evidently: Not installed
2024-04-23 20:09:08,757:INFO:               fugue: Not installed
2024-04-23 20:09:08,757:INFO:           streamlit: 1.28.0
2024-04-23 20:09:08,757:INFO:             prophet: Not installed
2024-04-23 20:09:08,757:INFO:None
2024-04-23 20:09:08,757:INFO:Set up data.
2024-04-23 20:09:08,768:INFO:Set up folding strategy.
2024-04-23 20:09:08,768:INFO:Set up train/test split.
2024-04-23 20:09:08,776:INFO:Set up index.
2024-04-23 20:09:08,776:INFO:Assigning column types.
2024-04-23 20:09:08,779:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:09:08,826:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,829:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,912:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,913:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:08,941:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,942:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:08,942:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:09:08,987:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:09,017:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,017:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:09:09,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,099:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-23 20:09:09,178:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,179:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,251:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,251:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,253:INFO:Preparing preprocessing pipeline...
2024-04-23 20:09:09,254:INFO:Set up simple imputation.
2024-04-23 20:09:09,258:INFO:Set up encoding of ordinal features.
2024-04-23 20:09:09,259:INFO:Set up encoding of categorical features.
2024-04-23 20:09:09,416:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:09:09,436:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-23 20:09:09,437:INFO:Creating final display dataframe.
2024-04-23 20:09:09,868:INFO:Setup _display_container:                     Description             Value
0                    Session id               208
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              4fd9
2024-04-23 20:09:09,948:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:09,948:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,022:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,022:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:09:10,023:INFO:setup() successfully completed in 1.39s...............
2024-04-23 20:09:10,026:INFO:Initializing compare_models()
2024-04-23 20:09:10,026:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-23 20:09:10,026:INFO:Checking exceptions
2024-04-23 20:09:10,029:INFO:Preparing display monitor
2024-04-23 20:09:10,037:INFO:Initializing Logistic Regression
2024-04-23 20:09:10,037:INFO:Total runtime is 0.0 minutes
2024-04-23 20:09:10,037:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:10,038:INFO:Initializing create_model()
2024-04-23 20:09:10,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:10,038:INFO:Checking exceptions
2024-04-23 20:09:10,038:INFO:Importing libraries
2024-04-23 20:09:10,038:INFO:Copying training dataset
2024-04-23 20:09:10,042:INFO:Defining folds
2024-04-23 20:09:10,042:INFO:Declaring metric variables
2024-04-23 20:09:10,042:INFO:Importing untrained model
2024-04-23 20:09:10,042:INFO:Logistic Regression Imported successfully
2024-04-23 20:09:10,043:INFO:Starting cross validation
2024-04-23 20:09:10,044:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:16,316:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,368:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,373:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,436:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,454:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,480:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,513:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,548:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,906:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:16,951:INFO:Calculating mean and std
2024-04-23 20:09:16,952:INFO:Creating metrics dataframe
2024-04-23 20:09:16,955:INFO:Uploading results into container
2024-04-23 20:09:16,956:INFO:Uploading model into container now
2024-04-23 20:09:16,956:INFO:_master_model_container: 1
2024-04-23 20:09:16,956:INFO:_display_container: 2
2024-04-23 20:09:16,956:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:16,956:INFO:create_model() successfully completed......................................
2024-04-23 20:09:17,096:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:17,097:INFO:Creating metrics dataframe
2024-04-23 20:09:17,101:INFO:Initializing K Neighbors Classifier
2024-04-23 20:09:17,102:INFO:Total runtime is 0.11774900356928507 minutes
2024-04-23 20:09:17,102:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:17,102:INFO:Initializing create_model()
2024-04-23 20:09:17,102:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:17,102:INFO:Checking exceptions
2024-04-23 20:09:17,103:INFO:Importing libraries
2024-04-23 20:09:17,103:INFO:Copying training dataset
2024-04-23 20:09:17,107:INFO:Defining folds
2024-04-23 20:09:17,107:INFO:Declaring metric variables
2024-04-23 20:09:17,107:INFO:Importing untrained model
2024-04-23 20:09:17,107:INFO:K Neighbors Classifier Imported successfully
2024-04-23 20:09:17,108:INFO:Starting cross validation
2024-04-23 20:09:17,109:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:19,557:INFO:Calculating mean and std
2024-04-23 20:09:19,559:INFO:Creating metrics dataframe
2024-04-23 20:09:19,566:INFO:Uploading results into container
2024-04-23 20:09:19,568:INFO:Uploading model into container now
2024-04-23 20:09:19,568:INFO:_master_model_container: 2
2024-04-23 20:09:19,569:INFO:_display_container: 2
2024-04-23 20:09:19,569:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-23 20:09:19,569:INFO:create_model() successfully completed......................................
2024-04-23 20:09:19,701:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:19,701:INFO:Creating metrics dataframe
2024-04-23 20:09:19,705:INFO:Initializing Naive Bayes
2024-04-23 20:09:19,705:INFO:Total runtime is 0.16112928390502929 minutes
2024-04-23 20:09:19,706:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:19,706:INFO:Initializing create_model()
2024-04-23 20:09:19,706:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:19,706:INFO:Checking exceptions
2024-04-23 20:09:19,706:INFO:Importing libraries
2024-04-23 20:09:19,706:INFO:Copying training dataset
2024-04-23 20:09:19,709:INFO:Defining folds
2024-04-23 20:09:19,709:INFO:Declaring metric variables
2024-04-23 20:09:19,710:INFO:Importing untrained model
2024-04-23 20:09:19,710:INFO:Naive Bayes Imported successfully
2024-04-23 20:09:19,710:INFO:Starting cross validation
2024-04-23 20:09:19,711:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:19,994:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,069:INFO:Calculating mean and std
2024-04-23 20:09:20,070:INFO:Creating metrics dataframe
2024-04-23 20:09:20,073:INFO:Uploading results into container
2024-04-23 20:09:20,074:INFO:Uploading model into container now
2024-04-23 20:09:20,075:INFO:_master_model_container: 3
2024-04-23 20:09:20,075:INFO:_display_container: 2
2024-04-23 20:09:20,075:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-23 20:09:20,075:INFO:create_model() successfully completed......................................
2024-04-23 20:09:20,198:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:20,198:INFO:Creating metrics dataframe
2024-04-23 20:09:20,203:INFO:Initializing Decision Tree Classifier
2024-04-23 20:09:20,203:INFO:Total runtime is 0.16942691405614216 minutes
2024-04-23 20:09:20,203:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:20,203:INFO:Initializing create_model()
2024-04-23 20:09:20,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:20,203:INFO:Checking exceptions
2024-04-23 20:09:20,204:INFO:Importing libraries
2024-04-23 20:09:20,204:INFO:Copying training dataset
2024-04-23 20:09:20,208:INFO:Defining folds
2024-04-23 20:09:20,209:INFO:Declaring metric variables
2024-04-23 20:09:20,209:INFO:Importing untrained model
2024-04-23 20:09:20,209:INFO:Decision Tree Classifier Imported successfully
2024-04-23 20:09:20,209:INFO:Starting cross validation
2024-04-23 20:09:20,210:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:20,462:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,477:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,487:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,502:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,511:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,515:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,539:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,540:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,575:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,603:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:20,612:INFO:Calculating mean and std
2024-04-23 20:09:20,613:INFO:Creating metrics dataframe
2024-04-23 20:09:20,615:INFO:Uploading results into container
2024-04-23 20:09:20,616:INFO:Uploading model into container now
2024-04-23 20:09:20,616:INFO:_master_model_container: 4
2024-04-23 20:09:20,616:INFO:_display_container: 2
2024-04-23 20:09:20,617:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=208, splitter='best')
2024-04-23 20:09:20,617:INFO:create_model() successfully completed......................................
2024-04-23 20:09:20,740:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:20,740:INFO:Creating metrics dataframe
2024-04-23 20:09:20,744:INFO:Initializing SVM - Linear Kernel
2024-04-23 20:09:20,744:INFO:Total runtime is 0.17843695481618244 minutes
2024-04-23 20:09:20,745:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:20,745:INFO:Initializing create_model()
2024-04-23 20:09:20,745:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:20,745:INFO:Checking exceptions
2024-04-23 20:09:20,745:INFO:Importing libraries
2024-04-23 20:09:20,745:INFO:Copying training dataset
2024-04-23 20:09:20,749:INFO:Defining folds
2024-04-23 20:09:20,749:INFO:Declaring metric variables
2024-04-23 20:09:20,749:INFO:Importing untrained model
2024-04-23 20:09:20,749:INFO:SVM - Linear Kernel Imported successfully
2024-04-23 20:09:20,749:INFO:Starting cross validation
2024-04-23 20:09:20,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,116:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,119:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,144:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:09:21,150:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:21,160:INFO:Calculating mean and std
2024-04-23 20:09:21,161:INFO:Creating metrics dataframe
2024-04-23 20:09:21,164:INFO:Uploading results into container
2024-04-23 20:09:21,165:INFO:Uploading model into container now
2024-04-23 20:09:21,165:INFO:_master_model_container: 5
2024-04-23 20:09:21,165:INFO:_display_container: 2
2024-04-23 20:09:21,166:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=208, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-23 20:09:21,166:INFO:create_model() successfully completed......................................
2024-04-23 20:09:21,293:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:21,294:INFO:Creating metrics dataframe
2024-04-23 20:09:21,298:INFO:Initializing Ridge Classifier
2024-04-23 20:09:21,298:INFO:Total runtime is 0.18767929871877032 minutes
2024-04-23 20:09:21,298:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:21,299:INFO:Initializing create_model()
2024-04-23 20:09:21,299:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:21,299:INFO:Checking exceptions
2024-04-23 20:09:21,299:INFO:Importing libraries
2024-04-23 20:09:21,299:INFO:Copying training dataset
2024-04-23 20:09:21,304:INFO:Defining folds
2024-04-23 20:09:21,304:INFO:Declaring metric variables
2024-04-23 20:09:21,305:INFO:Importing untrained model
2024-04-23 20:09:21,305:INFO:Ridge Classifier Imported successfully
2024-04-23 20:09:21,305:INFO:Starting cross validation
2024-04-23 20:09:21,306:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:21,573:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,590:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,597:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,607:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,639:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,640:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,650:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,654:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,702:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:09:21,711:INFO:Calculating mean and std
2024-04-23 20:09:21,712:INFO:Creating metrics dataframe
2024-04-23 20:09:21,716:INFO:Uploading results into container
2024-04-23 20:09:21,717:INFO:Uploading model into container now
2024-04-23 20:09:21,717:INFO:_master_model_container: 6
2024-04-23 20:09:21,717:INFO:_display_container: 2
2024-04-23 20:09:21,718:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=208, solver='auto',
                tol=0.0001)
2024-04-23 20:09:21,718:INFO:create_model() successfully completed......................................
2024-04-23 20:09:21,841:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:21,841:INFO:Creating metrics dataframe
2024-04-23 20:09:21,847:INFO:Initializing Random Forest Classifier
2024-04-23 20:09:21,847:INFO:Total runtime is 0.19682150284449257 minutes
2024-04-23 20:09:21,848:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:21,848:INFO:Initializing create_model()
2024-04-23 20:09:21,848:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:21,848:INFO:Checking exceptions
2024-04-23 20:09:21,848:INFO:Importing libraries
2024-04-23 20:09:21,848:INFO:Copying training dataset
2024-04-23 20:09:21,852:INFO:Defining folds
2024-04-23 20:09:21,853:INFO:Declaring metric variables
2024-04-23 20:09:21,853:INFO:Importing untrained model
2024-04-23 20:09:21,854:INFO:Random Forest Classifier Imported successfully
2024-04-23 20:09:21,854:INFO:Starting cross validation
2024-04-23 20:09:21,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:22,531:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,531:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,532:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,535:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,587:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,599:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,678:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:22,709:INFO:Calculating mean and std
2024-04-23 20:09:22,710:INFO:Creating metrics dataframe
2024-04-23 20:09:22,713:INFO:Uploading results into container
2024-04-23 20:09:22,714:INFO:Uploading model into container now
2024-04-23 20:09:22,714:INFO:_master_model_container: 7
2024-04-23 20:09:22,714:INFO:_display_container: 2
2024-04-23 20:09:22,715:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=208, verbose=0, warm_start=False)
2024-04-23 20:09:22,715:INFO:create_model() successfully completed......................................
2024-04-23 20:09:22,833:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:22,833:INFO:Creating metrics dataframe
2024-04-23 20:09:22,837:INFO:Initializing Quadratic Discriminant Analysis
2024-04-23 20:09:22,837:INFO:Total runtime is 0.21333289941151934 minutes
2024-04-23 20:09:22,837:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:22,838:INFO:Initializing create_model()
2024-04-23 20:09:22,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:22,838:INFO:Checking exceptions
2024-04-23 20:09:22,838:INFO:Importing libraries
2024-04-23 20:09:22,838:INFO:Copying training dataset
2024-04-23 20:09:22,841:INFO:Defining folds
2024-04-23 20:09:22,841:INFO:Declaring metric variables
2024-04-23 20:09:22,841:INFO:Importing untrained model
2024-04-23 20:09:22,842:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-23 20:09:22,842:INFO:Starting cross validation
2024-04-23 20:09:22,843:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:23,017:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,020:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,023:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,023:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,032:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,036:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,041:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,101:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,114:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,117:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,119:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,128:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,131:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,132:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,134:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,135:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,176:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:09:23,188:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,221:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,226:INFO:Calculating mean and std
2024-04-23 20:09:23,227:INFO:Creating metrics dataframe
2024-04-23 20:09:23,231:INFO:Uploading results into container
2024-04-23 20:09:23,231:INFO:Uploading model into container now
2024-04-23 20:09:23,231:INFO:_master_model_container: 8
2024-04-23 20:09:23,232:INFO:_display_container: 2
2024-04-23 20:09:23,232:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-23 20:09:23,232:INFO:create_model() successfully completed......................................
2024-04-23 20:09:23,354:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:23,354:INFO:Creating metrics dataframe
2024-04-23 20:09:23,359:INFO:Initializing Ada Boost Classifier
2024-04-23 20:09:23,359:INFO:Total runtime is 0.22201821009318032 minutes
2024-04-23 20:09:23,359:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:23,359:INFO:Initializing create_model()
2024-04-23 20:09:23,359:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:23,359:INFO:Checking exceptions
2024-04-23 20:09:23,359:INFO:Importing libraries
2024-04-23 20:09:23,359:INFO:Copying training dataset
2024-04-23 20:09:23,363:INFO:Defining folds
2024-04-23 20:09:23,363:INFO:Declaring metric variables
2024-04-23 20:09:23,363:INFO:Importing untrained model
2024-04-23 20:09:23,363:INFO:Ada Boost Classifier Imported successfully
2024-04-23 20:09:23,363:INFO:Starting cross validation
2024-04-23 20:09:23,365:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:23,619:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,623:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,629:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,641:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,647:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,653:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,653:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,662:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,665:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,670:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:23,683:INFO:Calculating mean and std
2024-04-23 20:09:23,684:INFO:Creating metrics dataframe
2024-04-23 20:09:23,687:INFO:Uploading results into container
2024-04-23 20:09:23,688:INFO:Uploading model into container now
2024-04-23 20:09:23,688:INFO:_master_model_container: 9
2024-04-23 20:09:23,688:INFO:_display_container: 2
2024-04-23 20:09:23,688:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=208)
2024-04-23 20:09:23,688:INFO:create_model() successfully completed......................................
2024-04-23 20:09:23,805:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:23,805:INFO:Creating metrics dataframe
2024-04-23 20:09:23,811:INFO:Initializing Gradient Boosting Classifier
2024-04-23 20:09:23,811:INFO:Total runtime is 0.22955313126246132 minutes
2024-04-23 20:09:23,811:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:23,812:INFO:Initializing create_model()
2024-04-23 20:09:23,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:23,812:INFO:Checking exceptions
2024-04-23 20:09:23,812:INFO:Importing libraries
2024-04-23 20:09:23,812:INFO:Copying training dataset
2024-04-23 20:09:23,817:INFO:Defining folds
2024-04-23 20:09:23,817:INFO:Declaring metric variables
2024-04-23 20:09:23,817:INFO:Importing untrained model
2024-04-23 20:09:23,817:INFO:Gradient Boosting Classifier Imported successfully
2024-04-23 20:09:23,817:INFO:Starting cross validation
2024-04-23 20:09:23,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:24,205:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,220:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,223:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,232:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,239:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,244:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,245:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,246:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,265:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,374:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,388:INFO:Calculating mean and std
2024-04-23 20:09:24,389:INFO:Creating metrics dataframe
2024-04-23 20:09:24,392:INFO:Uploading results into container
2024-04-23 20:09:24,392:INFO:Uploading model into container now
2024-04-23 20:09:24,393:INFO:_master_model_container: 10
2024-04-23 20:09:24,393:INFO:_display_container: 2
2024-04-23 20:09:24,393:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=208, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-23 20:09:24,393:INFO:create_model() successfully completed......................................
2024-04-23 20:09:24,513:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:24,513:INFO:Creating metrics dataframe
2024-04-23 20:09:24,518:INFO:Initializing Linear Discriminant Analysis
2024-04-23 20:09:24,518:INFO:Total runtime is 0.241348926226298 minutes
2024-04-23 20:09:24,518:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:24,518:INFO:Initializing create_model()
2024-04-23 20:09:24,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:24,519:INFO:Checking exceptions
2024-04-23 20:09:24,519:INFO:Importing libraries
2024-04-23 20:09:24,519:INFO:Copying training dataset
2024-04-23 20:09:24,522:INFO:Defining folds
2024-04-23 20:09:24,523:INFO:Declaring metric variables
2024-04-23 20:09:24,523:INFO:Importing untrained model
2024-04-23 20:09:24,523:INFO:Linear Discriminant Analysis Imported successfully
2024-04-23 20:09:24,523:INFO:Starting cross validation
2024-04-23 20:09:24,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:24,773:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,787:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,793:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,796:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,803:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,818:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,830:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,839:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:24,847:INFO:Calculating mean and std
2024-04-23 20:09:24,848:INFO:Creating metrics dataframe
2024-04-23 20:09:24,851:INFO:Uploading results into container
2024-04-23 20:09:24,851:INFO:Uploading model into container now
2024-04-23 20:09:24,851:INFO:_master_model_container: 11
2024-04-23 20:09:24,851:INFO:_display_container: 2
2024-04-23 20:09:24,852:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-23 20:09:24,852:INFO:create_model() successfully completed......................................
2024-04-23 20:09:24,977:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:24,977:INFO:Creating metrics dataframe
2024-04-23 20:09:24,983:INFO:Initializing Extra Trees Classifier
2024-04-23 20:09:24,983:INFO:Total runtime is 0.2490948716799418 minutes
2024-04-23 20:09:24,983:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:24,984:INFO:Initializing create_model()
2024-04-23 20:09:24,984:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:24,984:INFO:Checking exceptions
2024-04-23 20:09:24,984:INFO:Importing libraries
2024-04-23 20:09:24,984:INFO:Copying training dataset
2024-04-23 20:09:24,987:INFO:Defining folds
2024-04-23 20:09:24,988:INFO:Declaring metric variables
2024-04-23 20:09:24,988:INFO:Importing untrained model
2024-04-23 20:09:24,988:INFO:Extra Trees Classifier Imported successfully
2024-04-23 20:09:24,988:INFO:Starting cross validation
2024-04-23 20:09:24,990:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:25,662:INFO:Calculating mean and std
2024-04-23 20:09:25,663:INFO:Creating metrics dataframe
2024-04-23 20:09:25,667:INFO:Uploading results into container
2024-04-23 20:09:25,668:INFO:Uploading model into container now
2024-04-23 20:09:25,669:INFO:_master_model_container: 12
2024-04-23 20:09:25,669:INFO:_display_container: 2
2024-04-23 20:09:25,669:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=208, verbose=0, warm_start=False)
2024-04-23 20:09:25,669:INFO:create_model() successfully completed......................................
2024-04-23 20:09:25,788:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:25,788:INFO:Creating metrics dataframe
2024-04-23 20:09:25,792:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:09:25,792:INFO:Total runtime is 0.2625685175259908 minutes
2024-04-23 20:09:25,792:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:25,792:INFO:Initializing create_model()
2024-04-23 20:09:25,793:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:25,793:INFO:Checking exceptions
2024-04-23 20:09:25,793:INFO:Importing libraries
2024-04-23 20:09:25,793:INFO:Copying training dataset
2024-04-23 20:09:25,796:INFO:Defining folds
2024-04-23 20:09:25,796:INFO:Declaring metric variables
2024-04-23 20:09:25,797:INFO:Importing untrained model
2024-04-23 20:09:25,797:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:09:25,797:INFO:Starting cross validation
2024-04-23 20:09:25,798:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:26,403:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,404:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,421:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,440:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,553:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,578:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,677:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,734:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,749:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:26,764:INFO:Calculating mean and std
2024-04-23 20:09:26,765:INFO:Creating metrics dataframe
2024-04-23 20:09:26,769:INFO:Uploading results into container
2024-04-23 20:09:26,770:INFO:Uploading model into container now
2024-04-23 20:09:26,771:INFO:_master_model_container: 13
2024-04-23 20:09:26,771:INFO:_display_container: 2
2024-04-23 20:09:26,772:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=208, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-23 20:09:26,772:INFO:create_model() successfully completed......................................
2024-04-23 20:09:26,920:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:26,921:INFO:Creating metrics dataframe
2024-04-23 20:09:26,925:INFO:Initializing Dummy Classifier
2024-04-23 20:09:26,925:INFO:Total runtime is 0.28145132859547933 minutes
2024-04-23 20:09:26,925:INFO:SubProcess create_model() called ==================================
2024-04-23 20:09:26,925:INFO:Initializing create_model()
2024-04-23 20:09:26,925:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B330146620>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:26,925:INFO:Checking exceptions
2024-04-23 20:09:26,926:INFO:Importing libraries
2024-04-23 20:09:26,926:INFO:Copying training dataset
2024-04-23 20:09:26,929:INFO:Defining folds
2024-04-23 20:09:26,929:INFO:Declaring metric variables
2024-04-23 20:09:26,929:INFO:Importing untrained model
2024-04-23 20:09:26,930:INFO:Dummy Classifier Imported successfully
2024-04-23 20:09:26,930:INFO:Starting cross validation
2024-04-23 20:09:26,931:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:09:27,214:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,224:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,239:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,274:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,275:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,290:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,309:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,311:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,313:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,329:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:09:27,334:INFO:Calculating mean and std
2024-04-23 20:09:27,334:INFO:Creating metrics dataframe
2024-04-23 20:09:27,337:INFO:Uploading results into container
2024-04-23 20:09:27,338:INFO:Uploading model into container now
2024-04-23 20:09:27,338:INFO:_master_model_container: 14
2024-04-23 20:09:27,338:INFO:_display_container: 2
2024-04-23 20:09:27,338:INFO:DummyClassifier(constant=None, random_state=208, strategy='prior')
2024-04-23 20:09:27,338:INFO:create_model() successfully completed......................................
2024-04-23 20:09:27,488:INFO:SubProcess create_model() end ==================================
2024-04-23 20:09:27,488:INFO:Creating metrics dataframe
2024-04-23 20:09:27,500:INFO:Initializing create_model()
2024-04-23 20:09:27,500:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32AE101F0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:09:27,501:INFO:Checking exceptions
2024-04-23 20:09:27,502:INFO:Importing libraries
2024-04-23 20:09:27,502:INFO:Copying training dataset
2024-04-23 20:09:27,506:INFO:Defining folds
2024-04-23 20:09:27,506:INFO:Declaring metric variables
2024-04-23 20:09:27,506:INFO:Importing untrained model
2024-04-23 20:09:27,506:INFO:Declaring custom model
2024-04-23 20:09:27,506:INFO:Logistic Regression Imported successfully
2024-04-23 20:09:27,508:INFO:Cross validation set to False
2024-04-23 20:09:27,508:INFO:Fitting Model
2024-04-23 20:09:27,729:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:09:27,729:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:27,729:INFO:create_model() successfully completed......................................
2024-04-23 20:09:27,896:INFO:_master_model_container: 14
2024-04-23 20:09:27,896:INFO:_display_container: 2
2024-04-23 20:09:27,896:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:09:27,896:INFO:compare_models() successfully completed......................................
2024-04-23 20:09:27,921:INFO:Initializing save_model()
2024-04-23 20:09:27,921:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=208, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-23 20:09:27,921:INFO:Adding model into prep_pipe
2024-04-23 20:09:27,931:INFO:best_classifier.pkl saved in current working directory
2024-04-23 20:09:27,957:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=208,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-23 20:09:27,957:INFO:save_model() successfully completed......................................
2024-04-23 20:13:44,753:INFO:Initializing load_model()
2024-04-23 20:13:44,753:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-23 20:14:08,154:INFO:PyCaret ClassificationExperiment
2024-04-23 20:14:08,154:INFO:Logging name: clf-default-name
2024-04-23 20:14:08,154:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-23 20:14:08,154:INFO:version 3.1.0
2024-04-23 20:14:08,154:INFO:Initializing setup()
2024-04-23 20:14:08,154:INFO:self.USI: 15d3
2024-04-23 20:14:08,154:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'is_multiclass', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'fix_imbalance', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:14:08,154:INFO:Checking environment
2024-04-23 20:14:08,154:INFO:python_version: 3.10.0
2024-04-23 20:14:08,154:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:14:08,154:INFO:machine: AMD64
2024-04-23 20:14:08,154:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:14:08,159:INFO:Memory: svmem(total=17041117184, available=5699416064, percent=66.6, used=11341701120, free=5699416064)
2024-04-23 20:14:08,159:INFO:Physical Core: 6
2024-04-23 20:14:08,159:INFO:Logical Core: 12
2024-04-23 20:14:08,159:INFO:Checking libraries
2024-04-23 20:14:08,160:INFO:System:
2024-04-23 20:14:08,160:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:14:08,160:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:14:08,160:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:14:08,160:INFO:PyCaret required dependencies:
2024-04-23 20:14:08,160:INFO:                 pip: 21.2.3
2024-04-23 20:14:08,160:INFO:          setuptools: 57.4.0
2024-04-23 20:14:08,160:INFO:             pycaret: 3.1.0
2024-04-23 20:14:08,160:INFO:             IPython: 8.17.2
2024-04-23 20:14:08,160:INFO:          ipywidgets: 8.1.1
2024-04-23 20:14:08,160:INFO:                tqdm: 4.66.1
2024-04-23 20:14:08,160:INFO:               numpy: 1.25.2
2024-04-23 20:14:08,160:INFO:              pandas: 2.0.3
2024-04-23 20:14:08,160:INFO:              jinja2: 3.1.2
2024-04-23 20:14:08,160:INFO:               scipy: 1.10.1
2024-04-23 20:14:08,160:INFO:              joblib: 1.3.2
2024-04-23 20:14:08,160:INFO:             sklearn: 1.2.2
2024-04-23 20:14:08,160:INFO:                pyod: 1.1.1
2024-04-23 20:14:08,160:INFO:            imblearn: 0.11.0
2024-04-23 20:14:08,160:INFO:   category_encoders: 2.6.3
2024-04-23 20:14:08,160:INFO:            lightgbm: 4.1.0
2024-04-23 20:14:08,160:INFO:               numba: 0.58.1
2024-04-23 20:14:08,160:INFO:            requests: 2.31.0
2024-04-23 20:14:08,160:INFO:          matplotlib: 3.7.3
2024-04-23 20:14:08,160:INFO:          scikitplot: 0.3.7
2024-04-23 20:14:08,161:INFO:         yellowbrick: 1.5
2024-04-23 20:14:08,161:INFO:              plotly: 5.18.0
2024-04-23 20:14:08,161:INFO:    plotly-resampler: Not installed
2024-04-23 20:14:08,161:INFO:             kaleido: 0.2.1
2024-04-23 20:14:08,161:INFO:           schemdraw: 0.15
2024-04-23 20:14:08,161:INFO:         statsmodels: 0.14.0
2024-04-23 20:14:08,161:INFO:              sktime: 0.21.1
2024-04-23 20:14:08,161:INFO:               tbats: 1.1.3
2024-04-23 20:14:08,161:INFO:            pmdarima: 2.0.4
2024-04-23 20:14:08,161:INFO:              psutil: 5.9.6
2024-04-23 20:14:08,161:INFO:          markupsafe: 2.1.3
2024-04-23 20:14:08,161:INFO:             pickle5: Not installed
2024-04-23 20:14:08,161:INFO:         cloudpickle: 3.0.0
2024-04-23 20:14:08,161:INFO:         deprecation: 2.1.0
2024-04-23 20:14:08,161:INFO:              xxhash: 3.4.1
2024-04-23 20:14:08,161:INFO:           wurlitzer: Not installed
2024-04-23 20:14:08,162:INFO:PyCaret optional dependencies:
2024-04-23 20:14:08,162:INFO:                shap: Not installed
2024-04-23 20:14:08,162:INFO:           interpret: Not installed
2024-04-23 20:14:08,162:INFO:                umap: Not installed
2024-04-23 20:14:08,162:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:14:08,162:INFO:  explainerdashboard: Not installed
2024-04-23 20:14:08,162:INFO:             autoviz: Not installed
2024-04-23 20:14:08,162:INFO:           fairlearn: Not installed
2024-04-23 20:14:08,162:INFO:          deepchecks: Not installed
2024-04-23 20:14:08,162:INFO:             xgboost: Not installed
2024-04-23 20:14:08,162:INFO:            catboost: Not installed
2024-04-23 20:14:08,162:INFO:              kmodes: Not installed
2024-04-23 20:14:08,162:INFO:             mlxtend: Not installed
2024-04-23 20:14:08,162:INFO:       statsforecast: Not installed
2024-04-23 20:14:08,162:INFO:        tune_sklearn: Not installed
2024-04-23 20:14:08,162:INFO:                 ray: Not installed
2024-04-23 20:14:08,162:INFO:            hyperopt: Not installed
2024-04-23 20:14:08,163:INFO:              optuna: Not installed
2024-04-23 20:14:08,163:INFO:               skopt: Not installed
2024-04-23 20:14:08,163:INFO:              mlflow: Not installed
2024-04-23 20:14:08,163:INFO:              gradio: Not installed
2024-04-23 20:14:08,163:INFO:             fastapi: Not installed
2024-04-23 20:14:08,163:INFO:             uvicorn: Not installed
2024-04-23 20:14:08,163:INFO:              m2cgen: Not installed
2024-04-23 20:14:08,163:INFO:           evidently: Not installed
2024-04-23 20:14:08,163:INFO:               fugue: Not installed
2024-04-23 20:14:08,163:INFO:           streamlit: 1.28.0
2024-04-23 20:14:08,163:INFO:             prophet: Not installed
2024-04-23 20:14:08,163:INFO:None
2024-04-23 20:14:08,163:INFO:Set up data.
2024-04-23 20:14:08,171:INFO:Set up folding strategy.
2024-04-23 20:14:08,171:INFO:Set up train/test split.
2024-04-23 20:14:08,178:INFO:Set up index.
2024-04-23 20:14:08,179:INFO:Assigning column types.
2024-04-23 20:14:08,184:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:14:08,246:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,248:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,280:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,280:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,330:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,331:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,361:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,361:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:14:08,414:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,443:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,489:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-23 20:14:08,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,521:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-23 20:14:08,594:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,595:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:08,676:INFO:Preparing preprocessing pipeline...
2024-04-23 20:14:08,678:INFO:Set up simple imputation.
2024-04-23 20:14:08,682:INFO:Set up encoding of ordinal features.
2024-04-23 20:14:08,685:INFO:Set up encoding of categorical features.
2024-04-23 20:14:08,815:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:14:08,837:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-23 20:14:08,837:INFO:Creating final display dataframe.
2024-04-23 20:14:09,271:INFO:Setup _display_container:                     Description             Value
0                    Session id              3685
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Ordinal features                 1
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              15d3
2024-04-23 20:14:09,348:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,349:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,422:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,423:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:14:09,423:INFO:setup() successfully completed in 1.27s...............
2024-04-23 20:14:09,426:INFO:Initializing compare_models()
2024-04-23 20:14:09,426:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-23 20:14:09,426:INFO:Checking exceptions
2024-04-23 20:14:09,429:INFO:Preparing display monitor
2024-04-23 20:14:09,432:INFO:Initializing Logistic Regression
2024-04-23 20:14:09,432:INFO:Total runtime is 0.0 minutes
2024-04-23 20:14:09,432:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:09,432:INFO:Initializing create_model()
2024-04-23 20:14:09,432:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:09,433:INFO:Checking exceptions
2024-04-23 20:14:09,433:INFO:Importing libraries
2024-04-23 20:14:09,433:INFO:Copying training dataset
2024-04-23 20:14:09,439:INFO:Defining folds
2024-04-23 20:14:09,439:INFO:Declaring metric variables
2024-04-23 20:14:09,439:INFO:Importing untrained model
2024-04-23 20:14:09,440:INFO:Logistic Regression Imported successfully
2024-04-23 20:14:09,440:INFO:Starting cross validation
2024-04-23 20:14:09,442:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:09,968:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:09,972:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,020:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,058:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,098:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,151:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,160:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,161:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:10,239:INFO:Calculating mean and std
2024-04-23 20:14:10,240:INFO:Creating metrics dataframe
2024-04-23 20:14:10,248:INFO:Uploading results into container
2024-04-23 20:14:10,249:INFO:Uploading model into container now
2024-04-23 20:14:10,250:INFO:_master_model_container: 1
2024-04-23 20:14:10,250:INFO:_display_container: 2
2024-04-23 20:14:10,250:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:10,250:INFO:create_model() successfully completed......................................
2024-04-23 20:14:10,389:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:10,389:INFO:Creating metrics dataframe
2024-04-23 20:14:10,393:INFO:Initializing K Neighbors Classifier
2024-04-23 20:14:10,393:INFO:Total runtime is 0.016020663579305015 minutes
2024-04-23 20:14:10,393:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:10,394:INFO:Initializing create_model()
2024-04-23 20:14:10,394:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:10,394:INFO:Checking exceptions
2024-04-23 20:14:10,394:INFO:Importing libraries
2024-04-23 20:14:10,394:INFO:Copying training dataset
2024-04-23 20:14:10,398:INFO:Defining folds
2024-04-23 20:14:10,398:INFO:Declaring metric variables
2024-04-23 20:14:10,398:INFO:Importing untrained model
2024-04-23 20:14:10,398:INFO:K Neighbors Classifier Imported successfully
2024-04-23 20:14:10,398:INFO:Starting cross validation
2024-04-23 20:14:10,400:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:10,897:INFO:Calculating mean and std
2024-04-23 20:14:10,898:INFO:Creating metrics dataframe
2024-04-23 20:14:10,901:INFO:Uploading results into container
2024-04-23 20:14:10,901:INFO:Uploading model into container now
2024-04-23 20:14:10,901:INFO:_master_model_container: 2
2024-04-23 20:14:10,901:INFO:_display_container: 2
2024-04-23 20:14:10,902:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-23 20:14:10,902:INFO:create_model() successfully completed......................................
2024-04-23 20:14:11,042:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:11,042:INFO:Creating metrics dataframe
2024-04-23 20:14:11,048:INFO:Initializing Naive Bayes
2024-04-23 20:14:11,048:INFO:Total runtime is 0.026941430568695073 minutes
2024-04-23 20:14:11,049:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:11,049:INFO:Initializing create_model()
2024-04-23 20:14:11,049:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:11,049:INFO:Checking exceptions
2024-04-23 20:14:11,049:INFO:Importing libraries
2024-04-23 20:14:11,049:INFO:Copying training dataset
2024-04-23 20:14:11,053:INFO:Defining folds
2024-04-23 20:14:11,053:INFO:Declaring metric variables
2024-04-23 20:14:11,053:INFO:Importing untrained model
2024-04-23 20:14:11,054:INFO:Naive Bayes Imported successfully
2024-04-23 20:14:11,054:INFO:Starting cross validation
2024-04-23 20:14:11,055:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:11,463:INFO:Calculating mean and std
2024-04-23 20:14:11,464:INFO:Creating metrics dataframe
2024-04-23 20:14:11,467:INFO:Uploading results into container
2024-04-23 20:14:11,467:INFO:Uploading model into container now
2024-04-23 20:14:11,468:INFO:_master_model_container: 3
2024-04-23 20:14:11,468:INFO:_display_container: 2
2024-04-23 20:14:11,468:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-23 20:14:11,468:INFO:create_model() successfully completed......................................
2024-04-23 20:14:11,608:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:11,608:INFO:Creating metrics dataframe
2024-04-23 20:14:11,613:INFO:Initializing Decision Tree Classifier
2024-04-23 20:14:11,613:INFO:Total runtime is 0.036349594593048096 minutes
2024-04-23 20:14:11,613:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:11,614:INFO:Initializing create_model()
2024-04-23 20:14:11,614:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:11,614:INFO:Checking exceptions
2024-04-23 20:14:11,614:INFO:Importing libraries
2024-04-23 20:14:11,614:INFO:Copying training dataset
2024-04-23 20:14:11,619:INFO:Defining folds
2024-04-23 20:14:11,619:INFO:Declaring metric variables
2024-04-23 20:14:11,620:INFO:Importing untrained model
2024-04-23 20:14:11,620:INFO:Decision Tree Classifier Imported successfully
2024-04-23 20:14:11,621:INFO:Starting cross validation
2024-04-23 20:14:11,622:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:11,953:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:11,966:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:11,991:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,019:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,026:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,027:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,027:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,066:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,099:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,103:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,108:INFO:Calculating mean and std
2024-04-23 20:14:12,109:INFO:Creating metrics dataframe
2024-04-23 20:14:12,112:INFO:Uploading results into container
2024-04-23 20:14:12,112:INFO:Uploading model into container now
2024-04-23 20:14:12,113:INFO:_master_model_container: 4
2024-04-23 20:14:12,113:INFO:_display_container: 2
2024-04-23 20:14:12,114:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=3685, splitter='best')
2024-04-23 20:14:12,114:INFO:create_model() successfully completed......................................
2024-04-23 20:14:12,264:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:12,264:INFO:Creating metrics dataframe
2024-04-23 20:14:12,269:INFO:Initializing SVM - Linear Kernel
2024-04-23 20:14:12,269:INFO:Total runtime is 0.04728872776031494 minutes
2024-04-23 20:14:12,269:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:12,269:INFO:Initializing create_model()
2024-04-23 20:14:12,269:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:12,269:INFO:Checking exceptions
2024-04-23 20:14:12,269:INFO:Importing libraries
2024-04-23 20:14:12,269:INFO:Copying training dataset
2024-04-23 20:14:12,273:INFO:Defining folds
2024-04-23 20:14:12,273:INFO:Declaring metric variables
2024-04-23 20:14:12,273:INFO:Importing untrained model
2024-04-23 20:14:12,274:INFO:SVM - Linear Kernel Imported successfully
2024-04-23 20:14:12,274:INFO:Starting cross validation
2024-04-23 20:14:12,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:12,585:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,621:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,626:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,637:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,659:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,665:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,690:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,702:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,704:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,710:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:12,724:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2024-04-23 20:14:12,742:INFO:Calculating mean and std
2024-04-23 20:14:12,743:INFO:Creating metrics dataframe
2024-04-23 20:14:12,747:INFO:Uploading results into container
2024-04-23 20:14:12,747:INFO:Uploading model into container now
2024-04-23 20:14:12,748:INFO:_master_model_container: 5
2024-04-23 20:14:12,748:INFO:_display_container: 2
2024-04-23 20:14:12,748:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3685, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-23 20:14:12,748:INFO:create_model() successfully completed......................................
2024-04-23 20:14:12,882:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:12,882:INFO:Creating metrics dataframe
2024-04-23 20:14:12,887:INFO:Initializing Ridge Classifier
2024-04-23 20:14:12,887:INFO:Total runtime is 0.057596131165822344 minutes
2024-04-23 20:14:12,887:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:12,887:INFO:Initializing create_model()
2024-04-23 20:14:12,887:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:12,888:INFO:Checking exceptions
2024-04-23 20:14:12,888:INFO:Importing libraries
2024-04-23 20:14:12,888:INFO:Copying training dataset
2024-04-23 20:14:12,891:INFO:Defining folds
2024-04-23 20:14:12,891:INFO:Declaring metric variables
2024-04-23 20:14:12,892:INFO:Importing untrained model
2024-04-23 20:14:12,892:INFO:Ridge Classifier Imported successfully
2024-04-23 20:14:12,892:INFO:Starting cross validation
2024-04-23 20:14:12,893:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:13,174:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,180:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,180:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,213:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,225:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,227:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,235:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,243:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py:190: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\pycaret\internal\metrics.py", line 182, in _score
    return super()._score(
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2024-04-23 20:14:13,252:INFO:Calculating mean and std
2024-04-23 20:14:13,252:INFO:Creating metrics dataframe
2024-04-23 20:14:13,256:INFO:Uploading results into container
2024-04-23 20:14:13,256:INFO:Uploading model into container now
2024-04-23 20:14:13,257:INFO:_master_model_container: 6
2024-04-23 20:14:13,257:INFO:_display_container: 2
2024-04-23 20:14:13,257:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3685, solver='auto',
                tol=0.0001)
2024-04-23 20:14:13,257:INFO:create_model() successfully completed......................................
2024-04-23 20:14:13,390:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:13,390:INFO:Creating metrics dataframe
2024-04-23 20:14:13,395:INFO:Initializing Random Forest Classifier
2024-04-23 20:14:13,395:INFO:Total runtime is 0.0660632570584615 minutes
2024-04-23 20:14:13,395:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:13,395:INFO:Initializing create_model()
2024-04-23 20:14:13,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:13,395:INFO:Checking exceptions
2024-04-23 20:14:13,395:INFO:Importing libraries
2024-04-23 20:14:13,395:INFO:Copying training dataset
2024-04-23 20:14:13,399:INFO:Defining folds
2024-04-23 20:14:13,399:INFO:Declaring metric variables
2024-04-23 20:14:13,399:INFO:Importing untrained model
2024-04-23 20:14:13,400:INFO:Random Forest Classifier Imported successfully
2024-04-23 20:14:13,400:INFO:Starting cross validation
2024-04-23 20:14:13,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:14,227:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,238:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,241:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,242:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,250:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,294:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,303:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,366:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,414:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,422:INFO:Calculating mean and std
2024-04-23 20:14:14,423:INFO:Creating metrics dataframe
2024-04-23 20:14:14,427:INFO:Uploading results into container
2024-04-23 20:14:14,429:INFO:Uploading model into container now
2024-04-23 20:14:14,430:INFO:_master_model_container: 7
2024-04-23 20:14:14,430:INFO:_display_container: 2
2024-04-23 20:14:14,431:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=3685, verbose=0, warm_start=False)
2024-04-23 20:14:14,431:INFO:create_model() successfully completed......................................
2024-04-23 20:14:14,634:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:14,635:INFO:Creating metrics dataframe
2024-04-23 20:14:14,648:INFO:Initializing Quadratic Discriminant Analysis
2024-04-23 20:14:14,648:INFO:Total runtime is 0.08693687915802001 minutes
2024-04-23 20:14:14,649:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:14,649:INFO:Initializing create_model()
2024-04-23 20:14:14,649:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:14,649:INFO:Checking exceptions
2024-04-23 20:14:14,649:INFO:Importing libraries
2024-04-23 20:14:14,649:INFO:Copying training dataset
2024-04-23 20:14:14,657:INFO:Defining folds
2024-04-23 20:14:14,657:INFO:Declaring metric variables
2024-04-23 20:14:14,658:INFO:Importing untrained model
2024-04-23 20:14:14,658:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-23 20:14:14,658:INFO:Starting cross validation
2024-04-23 20:14:14,660:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:14,873:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,875:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,899:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,904:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,941:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,941:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,958:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,962:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:14,976:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:14,976:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,009:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,012:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,016:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,032:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,039:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,051:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,064:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-23 20:14:15,072:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,095:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,111:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,122:INFO:Calculating mean and std
2024-04-23 20:14:15,123:INFO:Creating metrics dataframe
2024-04-23 20:14:15,126:INFO:Uploading results into container
2024-04-23 20:14:15,126:INFO:Uploading model into container now
2024-04-23 20:14:15,126:INFO:_master_model_container: 8
2024-04-23 20:14:15,126:INFO:_display_container: 2
2024-04-23 20:14:15,127:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-23 20:14:15,127:INFO:create_model() successfully completed......................................
2024-04-23 20:14:15,264:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:15,264:INFO:Creating metrics dataframe
2024-04-23 20:14:15,271:INFO:Initializing Ada Boost Classifier
2024-04-23 20:14:15,271:INFO:Total runtime is 0.09731918176015217 minutes
2024-04-23 20:14:15,271:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:15,271:INFO:Initializing create_model()
2024-04-23 20:14:15,271:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:15,271:INFO:Checking exceptions
2024-04-23 20:14:15,271:INFO:Importing libraries
2024-04-23 20:14:15,271:INFO:Copying training dataset
2024-04-23 20:14:15,275:INFO:Defining folds
2024-04-23 20:14:15,275:INFO:Declaring metric variables
2024-04-23 20:14:15,275:INFO:Importing untrained model
2024-04-23 20:14:15,276:INFO:Ada Boost Classifier Imported successfully
2024-04-23 20:14:15,276:INFO:Starting cross validation
2024-04-23 20:14:15,277:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:15,484:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,488:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,493:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,499:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,500:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,649:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,649:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,667:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,675:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,679:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:15,689:INFO:Calculating mean and std
2024-04-23 20:14:15,691:INFO:Creating metrics dataframe
2024-04-23 20:14:15,698:INFO:Uploading results into container
2024-04-23 20:14:15,700:INFO:Uploading model into container now
2024-04-23 20:14:15,700:INFO:_master_model_container: 9
2024-04-23 20:14:15,700:INFO:_display_container: 2
2024-04-23 20:14:15,701:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=3685)
2024-04-23 20:14:15,701:INFO:create_model() successfully completed......................................
2024-04-23 20:14:15,851:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:15,851:INFO:Creating metrics dataframe
2024-04-23 20:14:15,856:INFO:Initializing Gradient Boosting Classifier
2024-04-23 20:14:15,856:INFO:Total runtime is 0.10707320769627887 minutes
2024-04-23 20:14:15,856:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:15,857:INFO:Initializing create_model()
2024-04-23 20:14:15,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:15,857:INFO:Checking exceptions
2024-04-23 20:14:15,857:INFO:Importing libraries
2024-04-23 20:14:15,857:INFO:Copying training dataset
2024-04-23 20:14:15,861:INFO:Defining folds
2024-04-23 20:14:15,861:INFO:Declaring metric variables
2024-04-23 20:14:15,861:INFO:Importing untrained model
2024-04-23 20:14:15,861:INFO:Gradient Boosting Classifier Imported successfully
2024-04-23 20:14:15,862:INFO:Starting cross validation
2024-04-23 20:14:15,863:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:16,305:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,315:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,316:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,330:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,333:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,348:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,510:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,521:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,527:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,533:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,548:INFO:Calculating mean and std
2024-04-23 20:14:16,549:INFO:Creating metrics dataframe
2024-04-23 20:14:16,552:INFO:Uploading results into container
2024-04-23 20:14:16,553:INFO:Uploading model into container now
2024-04-23 20:14:16,553:INFO:_master_model_container: 10
2024-04-23 20:14:16,553:INFO:_display_container: 2
2024-04-23 20:14:16,553:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3685, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-23 20:14:16,553:INFO:create_model() successfully completed......................................
2024-04-23 20:14:16,729:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:16,729:INFO:Creating metrics dataframe
2024-04-23 20:14:16,739:INFO:Initializing Linear Discriminant Analysis
2024-04-23 20:14:16,739:INFO:Total runtime is 0.12179587284723915 minutes
2024-04-23 20:14:16,740:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:16,740:INFO:Initializing create_model()
2024-04-23 20:14:16,741:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:16,741:INFO:Checking exceptions
2024-04-23 20:14:16,741:INFO:Importing libraries
2024-04-23 20:14:16,741:INFO:Copying training dataset
2024-04-23 20:14:16,748:INFO:Defining folds
2024-04-23 20:14:16,748:INFO:Declaring metric variables
2024-04-23 20:14:16,749:INFO:Importing untrained model
2024-04-23 20:14:16,749:INFO:Linear Discriminant Analysis Imported successfully
2024-04-23 20:14:16,750:INFO:Starting cross validation
2024-04-23 20:14:16,751:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:16,960:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,969:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:16,971:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,141:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,156:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,159:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,194:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,206:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,229:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:17,239:INFO:Calculating mean and std
2024-04-23 20:14:17,240:INFO:Creating metrics dataframe
2024-04-23 20:14:17,243:INFO:Uploading results into container
2024-04-23 20:14:17,244:INFO:Uploading model into container now
2024-04-23 20:14:17,244:INFO:_master_model_container: 11
2024-04-23 20:14:17,244:INFO:_display_container: 2
2024-04-23 20:14:17,245:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-23 20:14:17,245:INFO:create_model() successfully completed......................................
2024-04-23 20:14:17,400:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:17,400:INFO:Creating metrics dataframe
2024-04-23 20:14:17,404:INFO:Initializing Extra Trees Classifier
2024-04-23 20:14:17,404:INFO:Total runtime is 0.13287239869435627 minutes
2024-04-23 20:14:17,405:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:17,405:INFO:Initializing create_model()
2024-04-23 20:14:17,405:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:17,405:INFO:Checking exceptions
2024-04-23 20:14:17,405:INFO:Importing libraries
2024-04-23 20:14:17,405:INFO:Copying training dataset
2024-04-23 20:14:17,409:INFO:Defining folds
2024-04-23 20:14:17,409:INFO:Declaring metric variables
2024-04-23 20:14:17,409:INFO:Importing untrained model
2024-04-23 20:14:17,409:INFO:Extra Trees Classifier Imported successfully
2024-04-23 20:14:17,410:INFO:Starting cross validation
2024-04-23 20:14:17,411:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:18,319:INFO:Calculating mean and std
2024-04-23 20:14:18,320:INFO:Creating metrics dataframe
2024-04-23 20:14:18,324:INFO:Uploading results into container
2024-04-23 20:14:18,327:INFO:Uploading model into container now
2024-04-23 20:14:18,327:INFO:_master_model_container: 12
2024-04-23 20:14:18,328:INFO:_display_container: 2
2024-04-23 20:14:18,329:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=3685, verbose=0, warm_start=False)
2024-04-23 20:14:18,329:INFO:create_model() successfully completed......................................
2024-04-23 20:14:18,529:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:18,529:INFO:Creating metrics dataframe
2024-04-23 20:14:18,539:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:14:18,540:INFO:Total runtime is 0.1518085956573486 minutes
2024-04-23 20:14:18,540:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:18,540:INFO:Initializing create_model()
2024-04-23 20:14:18,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:18,541:INFO:Checking exceptions
2024-04-23 20:14:18,541:INFO:Importing libraries
2024-04-23 20:14:18,541:INFO:Copying training dataset
2024-04-23 20:14:18,547:INFO:Defining folds
2024-04-23 20:14:18,548:INFO:Declaring metric variables
2024-04-23 20:14:18,548:INFO:Importing untrained model
2024-04-23 20:14:18,548:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:14:18,548:INFO:Starting cross validation
2024-04-23 20:14:18,550:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:19,143:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,143:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,154:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,159:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,220:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,351:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,363:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,372:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,414:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,444:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:19,450:INFO:Calculating mean and std
2024-04-23 20:14:19,451:INFO:Creating metrics dataframe
2024-04-23 20:14:19,455:INFO:Uploading results into container
2024-04-23 20:14:19,456:INFO:Uploading model into container now
2024-04-23 20:14:19,456:INFO:_master_model_container: 13
2024-04-23 20:14:19,456:INFO:_display_container: 2
2024-04-23 20:14:19,457:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3685, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-23 20:14:19,457:INFO:create_model() successfully completed......................................
2024-04-23 20:14:19,643:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:19,643:INFO:Creating metrics dataframe
2024-04-23 20:14:19,650:INFO:Initializing Dummy Classifier
2024-04-23 20:14:19,650:INFO:Total runtime is 0.17030945221583046 minutes
2024-04-23 20:14:19,650:INFO:SubProcess create_model() called ==================================
2024-04-23 20:14:19,651:INFO:Initializing create_model()
2024-04-23 20:14:19,651:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002B3266C6020>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:19,651:INFO:Checking exceptions
2024-04-23 20:14:19,651:INFO:Importing libraries
2024-04-23 20:14:19,651:INFO:Copying training dataset
2024-04-23 20:14:19,659:INFO:Defining folds
2024-04-23 20:14:19,659:INFO:Declaring metric variables
2024-04-23 20:14:19,660:INFO:Importing untrained model
2024-04-23 20:14:19,660:INFO:Dummy Classifier Imported successfully
2024-04-23 20:14:19,661:INFO:Starting cross validation
2024-04-23 20:14:19,662:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:14:20,052:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,058:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,086:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,088:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,122:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,130:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,131:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,138:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,152:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,164:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2024-04-23 20:14:20,179:INFO:Calculating mean and std
2024-04-23 20:14:20,180:INFO:Creating metrics dataframe
2024-04-23 20:14:20,187:INFO:Uploading results into container
2024-04-23 20:14:20,188:INFO:Uploading model into container now
2024-04-23 20:14:20,189:INFO:_master_model_container: 14
2024-04-23 20:14:20,189:INFO:_display_container: 2
2024-04-23 20:14:20,189:INFO:DummyClassifier(constant=None, random_state=3685, strategy='prior')
2024-04-23 20:14:20,189:INFO:create_model() successfully completed......................................
2024-04-23 20:14:20,354:INFO:SubProcess create_model() end ==================================
2024-04-23 20:14:20,355:INFO:Creating metrics dataframe
2024-04-23 20:14:20,362:INFO:Initializing create_model()
2024-04-23 20:14:20,362:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:14:20,362:INFO:Checking exceptions
2024-04-23 20:14:20,363:INFO:Importing libraries
2024-04-23 20:14:20,363:INFO:Copying training dataset
2024-04-23 20:14:20,368:INFO:Defining folds
2024-04-23 20:14:20,368:INFO:Declaring metric variables
2024-04-23 20:14:20,369:INFO:Importing untrained model
2024-04-23 20:14:20,369:INFO:Declaring custom model
2024-04-23 20:14:20,370:INFO:Logistic Regression Imported successfully
2024-04-23 20:14:20,372:INFO:Cross validation set to False
2024-04-23 20:14:20,372:INFO:Fitting Model
2024-04-23 20:14:20,663:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-23 20:14:20,664:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:20,664:INFO:create_model() successfully completed......................................
2024-04-23 20:14:20,837:INFO:_master_model_container: 14
2024-04-23 20:14:20,837:INFO:_display_container: 2
2024-04-23 20:14:20,838:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-23 20:14:20,838:INFO:compare_models() successfully completed......................................
2024-04-23 20:14:20,861:INFO:Initializing save_model()
2024-04-23 20:14:20,861:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3685, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecate...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-23 20:14:20,862:INFO:Adding model into prep_pipe
2024-04-23 20:14:20,873:INFO:best_classifier.pkl saved in current working directory
2024-04-23 20:14:20,895:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean',
                                                              verbose='deprecated'))),
                ('categorical_imputer',
                 Transforme...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=3685,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-23 20:14:20,895:INFO:save_model() successfully completed......................................
2024-04-23 20:15:01,593:INFO:Initializing load_model()
2024-04-23 20:15:01,593:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-23 20:15:01,655:INFO:Initializing predict_model()
2024-04-23 20:15:01,655:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000002B32A9CF790>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='most_...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=3685))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000002B32ABDB7F0>)
2024-04-23 20:15:01,655:INFO:Checking exceptions
2024-04-23 20:15:01,655:INFO:Preloading libraries
2024-04-23 20:15:01,655:INFO:Set up data.
2024-04-23 20:15:01,662:INFO:Set up index.
2024-04-23 20:20:05,118:INFO:PyCaret RegressionExperiment
2024-04-23 20:20:05,124:INFO:Logging name: reg-default-name
2024-04-23 20:20:05,130:INFO:ML Usecase: MLUsecase.REGRESSION
2024-04-23 20:20:05,136:INFO:version 3.1.0
2024-04-23 20:20:05,142:INFO:Initializing setup()
2024-04-23 20:20:05,148:INFO:self.USI: 0905
2024-04-23 20:20:05,154:INFO:self._variable_keys: {'_ml_usecase', 'logging_param', 'fold_groups_param', 'X_test', 'y', 'fold_shuffle_param', 'transform_target_param', 'seed', 'data', '_available_plots', 'exp_name_log', 'X', 'pipeline', 'X_train', 'y_test', 'fold_generator', 'memory', 'target_param', 'gpu_n_jobs_param', 'exp_id', 'gpu_param', 'log_plots_param', 'idx', 'n_jobs_param', 'USI', 'y_train', 'html_param'}
2024-04-23 20:20:05,160:INFO:Checking environment
2024-04-23 20:20:05,160:INFO:python_version: 3.10.0
2024-04-23 20:20:05,165:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:20:05,171:INFO:machine: AMD64
2024-04-23 20:20:05,177:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:20:05,187:INFO:Memory: svmem(total=17041117184, available=7126892544, percent=58.2, used=9914224640, free=7126892544)
2024-04-23 20:20:05,194:INFO:Physical Core: 6
2024-04-23 20:20:05,200:INFO:Logical Core: 12
2024-04-23 20:20:05,206:INFO:Checking libraries
2024-04-23 20:20:05,206:INFO:System:
2024-04-23 20:20:05,206:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:20:05,206:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:20:05,206:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:20:05,206:INFO:PyCaret required dependencies:
2024-04-23 20:20:05,212:INFO:                 pip: 21.2.3
2024-04-23 20:20:05,218:INFO:          setuptools: 57.4.0
2024-04-23 20:20:05,224:INFO:             pycaret: 3.1.0
2024-04-23 20:20:05,230:INFO:             IPython: 8.17.2
2024-04-23 20:20:05,230:INFO:          ipywidgets: 8.1.1
2024-04-23 20:20:05,230:INFO:                tqdm: 4.66.1
2024-04-23 20:20:05,236:INFO:               numpy: 1.25.2
2024-04-23 20:20:05,241:INFO:              pandas: 2.0.3
2024-04-23 20:20:05,247:INFO:              jinja2: 3.1.2
2024-04-23 20:20:05,253:INFO:               scipy: 1.10.1
2024-04-23 20:20:05,259:INFO:              joblib: 1.3.2
2024-04-23 20:20:05,265:INFO:             sklearn: 1.2.2
2024-04-23 20:20:05,271:INFO:                pyod: 1.1.1
2024-04-23 20:20:05,277:INFO:            imblearn: 0.11.0
2024-04-23 20:20:05,277:INFO:   category_encoders: 2.6.3
2024-04-23 20:20:05,277:INFO:            lightgbm: 4.1.0
2024-04-23 20:20:05,277:INFO:               numba: 0.58.1
2024-04-23 20:20:05,277:INFO:            requests: 2.31.0
2024-04-23 20:20:05,277:INFO:          matplotlib: 3.7.3
2024-04-23 20:20:05,283:INFO:          scikitplot: 0.3.7
2024-04-23 20:20:05,288:INFO:         yellowbrick: 1.5
2024-04-23 20:20:05,294:INFO:              plotly: 5.18.0
2024-04-23 20:20:05,300:INFO:    plotly-resampler: Not installed
2024-04-23 20:20:05,306:INFO:             kaleido: 0.2.1
2024-04-23 20:20:05,312:INFO:           schemdraw: 0.15
2024-04-23 20:20:05,318:INFO:         statsmodels: 0.14.0
2024-04-23 20:20:05,324:INFO:              sktime: 0.21.1
2024-04-23 20:20:05,330:INFO:               tbats: 1.1.3
2024-04-23 20:20:05,336:INFO:            pmdarima: 2.0.4
2024-04-23 20:20:05,342:INFO:              psutil: 5.9.6
2024-04-23 20:20:05,348:INFO:          markupsafe: 2.1.3
2024-04-23 20:20:05,354:INFO:             pickle5: Not installed
2024-04-23 20:20:05,360:INFO:         cloudpickle: 3.0.0
2024-04-23 20:20:05,366:INFO:         deprecation: 2.1.0
2024-04-23 20:20:05,372:INFO:              xxhash: 3.4.1
2024-04-23 20:20:05,378:INFO:           wurlitzer: Not installed
2024-04-23 20:20:05,384:INFO:PyCaret optional dependencies:
2024-04-23 20:20:05,390:INFO:                shap: Not installed
2024-04-23 20:20:05,396:INFO:           interpret: Not installed
2024-04-23 20:20:05,402:INFO:                umap: Not installed
2024-04-23 20:20:05,408:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:20:05,414:INFO:  explainerdashboard: Not installed
2024-04-23 20:20:05,420:INFO:             autoviz: Not installed
2024-04-23 20:20:05,432:INFO:           fairlearn: Not installed
2024-04-23 20:20:05,438:INFO:          deepchecks: Not installed
2024-04-23 20:20:05,444:INFO:             xgboost: Not installed
2024-04-23 20:20:05,450:INFO:            catboost: Not installed
2024-04-23 20:20:05,456:INFO:              kmodes: Not installed
2024-04-23 20:20:05,462:INFO:             mlxtend: Not installed
2024-04-23 20:20:05,467:INFO:       statsforecast: Not installed
2024-04-23 20:20:05,473:INFO:        tune_sklearn: Not installed
2024-04-23 20:20:05,479:INFO:                 ray: Not installed
2024-04-23 20:20:05,485:INFO:            hyperopt: Not installed
2024-04-23 20:20:05,497:INFO:              optuna: Not installed
2024-04-23 20:20:05,497:INFO:               skopt: Not installed
2024-04-23 20:20:05,503:INFO:              mlflow: Not installed
2024-04-23 20:20:05,509:INFO:              gradio: Not installed
2024-04-23 20:20:05,515:INFO:             fastapi: Not installed
2024-04-23 20:20:05,521:INFO:             uvicorn: Not installed
2024-04-23 20:20:05,527:INFO:              m2cgen: Not installed
2024-04-23 20:20:05,533:INFO:           evidently: Not installed
2024-04-23 20:20:05,539:INFO:               fugue: Not installed
2024-04-23 20:20:05,545:INFO:           streamlit: 1.28.0
2024-04-23 20:20:05,551:INFO:             prophet: Not installed
2024-04-23 20:20:05,557:INFO:None
2024-04-23 20:20:05,563:INFO:Set up data.
2024-04-23 20:20:06,410:INFO:Set up folding strategy.
2024-04-23 20:20:06,416:INFO:Set up train/test split.
2024-04-23 20:20:06,590:INFO:Set up index.
2024-04-23 20:20:06,603:INFO:Assigning column types.
2024-04-23 20:20:06,709:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:20:06,715:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,725:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,743:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:06,996:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,098:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,104:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,117:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,121:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,131:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,323:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,420:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,426:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,432:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,438:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-04-23 20:20:07,448:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,452:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,612:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,703:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,709:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,709:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:07,714:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,724:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:07,915:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,003:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,009:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,015:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,021:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-04-23 20:20:08,035:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,187:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,286:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,292:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,298:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,307:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,512:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,606:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,612:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-04-23 20:20:08,800:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,896:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:08,896:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:08,896:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,094:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,195:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,201:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,207:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,213:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:20:09,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,482:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,668:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:20:09,759:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,759:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:09,766:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-04-23 20:20:10,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,026:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,337:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,343:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:10,379:INFO:Preparing preprocessing pipeline...
2024-04-23 20:20:10,385:INFO:Set up simple imputation.
2024-04-23 20:20:10,712:INFO:Set up encoding of ordinal features.
2024-04-23 20:20:10,739:INFO:Set up encoding of categorical features.
2024-04-23 20:20:25,441:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:20:25,494:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Id', 'MSSubClass', 'LotFrontage',
                                             'LotArea', 'OverallQual',
                                             'OverallCond', 'YearBuilt',
                                             'YearRemodAdd', 'MasVnrArea',
                                             'BsmtFinSF1', 'BsmtFinSF2',
                                             'BsmtUnfSF', 'TotalBsmtSF',
                                             '1stFlrSF', '2ndFlrSF',
                                             'LowQualFinSF', 'GrLivArea',
                                             'BsmtF...
                                                                    'Condition1',
                                                                    'Condition2',
                                                                    'BldgType',
                                                                    'HouseStyle',
                                                                    'RoofStyle',
                                                                    'RoofMatl',
                                                                    'Exterior1st',
                                                                    'Exterior2nd',
                                                                    'MasVnrType',
                                                                    'ExterQual',
                                                                    'ExterCond',
                                                                    'Foundation',
                                                                    'BsmtQual',
                                                                    'BsmtCond',
                                                                    'BsmtExposure',
                                                                    'BsmtFinType1',
                                                                    'BsmtFinType2',
                                                                    'Heating',
                                                                    'HeatingQC',
                                                                    'Electrical',
                                                                    'KitchenQual',
                                                                    'Functional',
                                                                    'FireplaceQu', ...],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-04-23 20:20:25,495:INFO:Creating final display dataframe.
2024-04-23 20:20:27,291:INFO:Setup _display_container:                     Description             Value
0                    Session id              6210
1                        Target         SalePrice
2                   Target type        Regression
3           Original data shape        (1460, 81)
4        Transformed data shape       (1460, 277)
5   Transformed train set shape       (1021, 277)
6    Transformed test set shape        (439, 277)
7              Ordinal features                 3
8              Numeric features                37
9          Categorical features                43
10     Rows with missing values            100.0%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator             KFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  reg-default-name
23                          USI              0905
2024-04-23 20:20:27,421:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,422:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,544:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,544:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:20:27,545:INFO:setup() successfully completed in 22.97s...............
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:20:51,854:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 20:25:31,225:INFO:PyCaret RegressionExperiment
2024-04-23 20:25:31,225:INFO:Logging name: reg-default-name
2024-04-23 20:25:31,225:INFO:ML Usecase: MLUsecase.REGRESSION
2024-04-23 20:25:31,225:INFO:version 3.1.0
2024-04-23 20:25:31,225:INFO:Initializing setup()
2024-04-23 20:25:31,225:INFO:self.USI: ade5
2024-04-23 20:25:31,225:INFO:self._variable_keys: {'fold_shuffle_param', '_available_plots', 'html_param', 'gpu_param', 'exp_id', 'USI', 'n_jobs_param', 'seed', 'idx', 'y_train', 'y', 'X', 'memory', 'logging_param', 'fold_generator', 'transform_target_param', 'target_param', '_ml_usecase', 'y_test', 'X_test', 'pipeline', 'log_plots_param', 'X_train', 'data', 'exp_name_log', 'gpu_n_jobs_param', 'fold_groups_param'}
2024-04-23 20:25:31,225:INFO:Checking environment
2024-04-23 20:25:31,226:INFO:python_version: 3.10.0
2024-04-23 20:25:31,226:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-23 20:25:31,226:INFO:machine: AMD64
2024-04-23 20:25:31,238:INFO:platform: Windows-10-10.0.19045-SP0
2024-04-23 20:25:31,243:INFO:Memory: svmem(total=17041117184, available=6372716544, percent=62.6, used=10668400640, free=6372716544)
2024-04-23 20:25:31,243:INFO:Physical Core: 6
2024-04-23 20:25:31,243:INFO:Logical Core: 12
2024-04-23 20:25:31,243:INFO:Checking libraries
2024-04-23 20:25:31,243:INFO:System:
2024-04-23 20:25:31,243:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-23 20:25:31,243:INFO:executable: C:\Users\User\AppData\Local\Programs\Python\Python310\python.exe
2024-04-23 20:25:31,243:INFO:   machine: Windows-10-10.0.19045-SP0
2024-04-23 20:25:31,243:INFO:PyCaret required dependencies:
2024-04-23 20:25:31,277:INFO:                 pip: 21.2.3
2024-04-23 20:25:31,278:INFO:          setuptools: 57.4.0
2024-04-23 20:25:31,278:INFO:             pycaret: 3.1.0
2024-04-23 20:25:31,278:INFO:             IPython: 8.17.2
2024-04-23 20:25:31,278:INFO:          ipywidgets: 8.1.1
2024-04-23 20:25:31,278:INFO:                tqdm: 4.66.1
2024-04-23 20:25:31,278:INFO:               numpy: 1.25.2
2024-04-23 20:25:31,278:INFO:              pandas: 2.0.3
2024-04-23 20:25:31,278:INFO:              jinja2: 3.1.2
2024-04-23 20:25:31,278:INFO:               scipy: 1.10.1
2024-04-23 20:25:31,278:INFO:              joblib: 1.3.2
2024-04-23 20:25:31,278:INFO:             sklearn: 1.2.2
2024-04-23 20:25:31,279:INFO:                pyod: 1.1.1
2024-04-23 20:25:31,279:INFO:            imblearn: 0.11.0
2024-04-23 20:25:31,279:INFO:   category_encoders: 2.6.3
2024-04-23 20:25:31,279:INFO:            lightgbm: 4.1.0
2024-04-23 20:25:31,279:INFO:               numba: 0.58.1
2024-04-23 20:25:31,279:INFO:            requests: 2.31.0
2024-04-23 20:25:31,279:INFO:          matplotlib: 3.7.3
2024-04-23 20:25:31,279:INFO:          scikitplot: 0.3.7
2024-04-23 20:25:31,279:INFO:         yellowbrick: 1.5
2024-04-23 20:25:31,279:INFO:              plotly: 5.18.0
2024-04-23 20:25:31,279:INFO:    plotly-resampler: Not installed
2024-04-23 20:25:31,279:INFO:             kaleido: 0.2.1
2024-04-23 20:25:31,279:INFO:           schemdraw: 0.15
2024-04-23 20:25:31,279:INFO:         statsmodels: 0.14.0
2024-04-23 20:25:31,279:INFO:              sktime: 0.21.1
2024-04-23 20:25:31,279:INFO:               tbats: 1.1.3
2024-04-23 20:25:31,280:INFO:            pmdarima: 2.0.4
2024-04-23 20:25:31,280:INFO:              psutil: 5.9.6
2024-04-23 20:25:31,280:INFO:          markupsafe: 2.1.3
2024-04-23 20:25:31,280:INFO:             pickle5: Not installed
2024-04-23 20:25:31,280:INFO:         cloudpickle: 3.0.0
2024-04-23 20:25:31,280:INFO:         deprecation: 2.1.0
2024-04-23 20:25:31,280:INFO:              xxhash: 3.4.1
2024-04-23 20:25:31,280:INFO:           wurlitzer: Not installed
2024-04-23 20:25:31,280:INFO:PyCaret optional dependencies:
2024-04-23 20:25:31,295:INFO:                shap: Not installed
2024-04-23 20:25:31,295:INFO:           interpret: Not installed
2024-04-23 20:25:31,296:INFO:                umap: Not installed
2024-04-23 20:25:31,296:INFO:     ydata_profiling: 4.6.1
2024-04-23 20:25:31,296:INFO:  explainerdashboard: Not installed
2024-04-23 20:25:31,296:INFO:             autoviz: Not installed
2024-04-23 20:25:31,296:INFO:           fairlearn: Not installed
2024-04-23 20:25:31,296:INFO:          deepchecks: Not installed
2024-04-23 20:25:31,296:INFO:             xgboost: Not installed
2024-04-23 20:25:31,296:INFO:            catboost: Not installed
2024-04-23 20:25:31,296:INFO:              kmodes: Not installed
2024-04-23 20:25:31,296:INFO:             mlxtend: Not installed
2024-04-23 20:25:31,296:INFO:       statsforecast: Not installed
2024-04-23 20:25:31,296:INFO:        tune_sklearn: Not installed
2024-04-23 20:25:31,296:INFO:                 ray: Not installed
2024-04-23 20:25:31,296:INFO:            hyperopt: Not installed
2024-04-23 20:25:31,296:INFO:              optuna: Not installed
2024-04-23 20:25:31,296:INFO:               skopt: Not installed
2024-04-23 20:25:31,296:INFO:              mlflow: Not installed
2024-04-23 20:25:31,296:INFO:              gradio: Not installed
2024-04-23 20:25:31,296:INFO:             fastapi: Not installed
2024-04-23 20:25:31,296:INFO:             uvicorn: Not installed
2024-04-23 20:25:31,296:INFO:              m2cgen: Not installed
2024-04-23 20:25:31,296:INFO:           evidently: Not installed
2024-04-23 20:25:31,296:INFO:               fugue: Not installed
2024-04-23 20:25:31,297:INFO:           streamlit: 1.28.0
2024-04-23 20:25:31,297:INFO:             prophet: Not installed
2024-04-23 20:25:31,297:INFO:None
2024-04-23 20:25:31,297:INFO:Set up data.
2024-04-23 20:25:31,307:INFO:Set up folding strategy.
2024-04-23 20:25:31,308:INFO:Set up train/test split.
2024-04-23 20:25:31,316:INFO:Set up index.
2024-04-23 20:25:31,317:INFO:Assigning column types.
2024-04-23 20:25:31,320:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-23 20:25:31,320:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,325:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,330:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,395:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,448:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,453:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,462:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,528:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,582:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,582:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,583:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2024-04-23 20:25:31,587:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,592:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,661:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,710:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,710:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,711:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,718:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,723:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,786:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,848:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,849:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2024-04-23 20:25:31,859:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,923:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:31,979:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:31,990:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,049:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,097:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,098:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,098:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2024-04-23 20:25:32,167:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,218:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,219:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,219:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,297:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,354:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-23 20:25:32,432:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,485:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,567:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2024-04-23 20:25:32,617:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,617:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,618:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2024-04-23 20:25:32,734:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:32,854:INFO:Preparing preprocessing pipeline...
2024-04-23 20:25:32,854:INFO:Set up simple imputation.
2024-04-23 20:25:32,858:INFO:Set up encoding of ordinal features.
2024-04-23 20:25:32,865:INFO:Set up encoding of categorical features.
2024-04-23 20:25:32,982:INFO:Finished creating preprocessing pipeline.
2024-04-23 20:25:33,066:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2024-04-23 20:25:33,066:INFO:Creating final display dataframe.
2024-04-23 20:25:33,364:INFO:Setup _display_container:                     Description             Value
0                    Session id               571
1                        Target             price
2                   Target type        Regression
3           Original data shape         (545, 13)
4        Transformed data shape         (545, 15)
5   Transformed train set shape         (381, 15)
6    Transformed test set shape         (164, 15)
7              Ordinal features                 6
8              Numeric features                 5
9          Categorical features                 7
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              ade5
2024-04-23 20:25:33,483:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,483:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,597:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,598:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-23 20:25:33,599:INFO:setup() successfully completed in 2.38s...............
2024-04-23 20:25:33,605:INFO:Initializing compare_models()
2024-04-23 20:25:33,606:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, include=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>}, exclude=None)
2024-04-23 20:25:33,606:INFO:Checking exceptions
2024-04-23 20:25:33,607:INFO:Preparing display monitor
2024-04-23 20:25:33,611:INFO:Initializing Linear Regression
2024-04-23 20:25:33,611:INFO:Total runtime is 0.0 minutes
2024-04-23 20:25:33,612:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:33,612:INFO:Initializing create_model()
2024-04-23 20:25:33,612:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:33,612:INFO:Checking exceptions
2024-04-23 20:25:33,612:INFO:Importing libraries
2024-04-23 20:25:33,612:INFO:Copying training dataset
2024-04-23 20:25:33,620:INFO:Defining folds
2024-04-23 20:25:33,620:INFO:Declaring metric variables
2024-04-23 20:25:33,620:INFO:Importing untrained model
2024-04-23 20:25:33,621:INFO:Linear Regression Imported successfully
2024-04-23 20:25:33,621:INFO:Starting cross validation
2024-04-23 20:25:33,638:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:40,717:INFO:Calculating mean and std
2024-04-23 20:25:40,718:INFO:Creating metrics dataframe
2024-04-23 20:25:40,724:INFO:Uploading results into container
2024-04-23 20:25:40,725:INFO:Uploading model into container now
2024-04-23 20:25:40,726:INFO:_master_model_container: 1
2024-04-23 20:25:40,726:INFO:_display_container: 2
2024-04-23 20:25:40,727:INFO:LinearRegression(n_jobs=-1)
2024-04-23 20:25:40,727:INFO:create_model() successfully completed......................................
2024-04-23 20:25:40,900:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:40,900:INFO:Creating metrics dataframe
2024-04-23 20:25:40,904:INFO:Initializing Lasso Regression
2024-04-23 20:25:40,904:INFO:Total runtime is 0.12154926856358846 minutes
2024-04-23 20:25:40,904:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:40,905:INFO:Initializing create_model()
2024-04-23 20:25:40,905:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:40,905:INFO:Checking exceptions
2024-04-23 20:25:40,905:INFO:Importing libraries
2024-04-23 20:25:40,905:INFO:Copying training dataset
2024-04-23 20:25:40,909:INFO:Defining folds
2024-04-23 20:25:40,909:INFO:Declaring metric variables
2024-04-23 20:25:40,909:INFO:Importing untrained model
2024-04-23 20:25:40,910:INFO:Lasso Regression Imported successfully
2024-04-23 20:25:40,910:INFO:Starting cross validation
2024-04-23 20:25:40,912:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:43,268:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_coordinate_descent.py:631: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 1.247e+13, tolerance: 1.249e+11
  model = cd_fast.enet_coordinate_descent(

2024-04-23 20:25:43,308:INFO:Calculating mean and std
2024-04-23 20:25:43,309:INFO:Creating metrics dataframe
2024-04-23 20:25:43,312:INFO:Uploading results into container
2024-04-23 20:25:43,313:INFO:Uploading model into container now
2024-04-23 20:25:43,313:INFO:_master_model_container: 2
2024-04-23 20:25:43,313:INFO:_display_container: 2
2024-04-23 20:25:43,313:INFO:Lasso(random_state=571)
2024-04-23 20:25:43,313:INFO:create_model() successfully completed......................................
2024-04-23 20:25:43,464:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:43,464:INFO:Creating metrics dataframe
2024-04-23 20:25:43,469:INFO:Initializing Ridge Regression
2024-04-23 20:25:43,469:INFO:Total runtime is 0.16429104010264078 minutes
2024-04-23 20:25:43,469:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:43,469:INFO:Initializing create_model()
2024-04-23 20:25:43,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:43,469:INFO:Checking exceptions
2024-04-23 20:25:43,469:INFO:Importing libraries
2024-04-23 20:25:43,469:INFO:Copying training dataset
2024-04-23 20:25:43,473:INFO:Defining folds
2024-04-23 20:25:43,473:INFO:Declaring metric variables
2024-04-23 20:25:43,473:INFO:Importing untrained model
2024-04-23 20:25:43,473:INFO:Ridge Regression Imported successfully
2024-04-23 20:25:43,473:INFO:Starting cross validation
2024-04-23 20:25:43,475:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:43,801:INFO:Calculating mean and std
2024-04-23 20:25:43,802:INFO:Creating metrics dataframe
2024-04-23 20:25:43,805:INFO:Uploading results into container
2024-04-23 20:25:43,805:INFO:Uploading model into container now
2024-04-23 20:25:43,806:INFO:_master_model_container: 3
2024-04-23 20:25:43,806:INFO:_display_container: 2
2024-04-23 20:25:43,806:INFO:Ridge(random_state=571)
2024-04-23 20:25:43,806:INFO:create_model() successfully completed......................................
2024-04-23 20:25:43,940:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:43,940:INFO:Creating metrics dataframe
2024-04-23 20:25:43,945:INFO:Initializing Elastic Net
2024-04-23 20:25:43,945:INFO:Total runtime is 0.17223515510559081 minutes
2024-04-23 20:25:43,945:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:43,946:INFO:Initializing create_model()
2024-04-23 20:25:43,946:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:43,946:INFO:Checking exceptions
2024-04-23 20:25:43,946:INFO:Importing libraries
2024-04-23 20:25:43,946:INFO:Copying training dataset
2024-04-23 20:25:43,949:INFO:Defining folds
2024-04-23 20:25:43,949:INFO:Declaring metric variables
2024-04-23 20:25:43,950:INFO:Importing untrained model
2024-04-23 20:25:43,950:INFO:Elastic Net Imported successfully
2024-04-23 20:25:43,950:INFO:Starting cross validation
2024-04-23 20:25:43,952:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:44,306:INFO:Calculating mean and std
2024-04-23 20:25:44,307:INFO:Creating metrics dataframe
2024-04-23 20:25:44,310:INFO:Uploading results into container
2024-04-23 20:25:44,311:INFO:Uploading model into container now
2024-04-23 20:25:44,311:INFO:_master_model_container: 4
2024-04-23 20:25:44,311:INFO:_display_container: 2
2024-04-23 20:25:44,312:INFO:ElasticNet(random_state=571)
2024-04-23 20:25:44,312:INFO:create_model() successfully completed......................................
2024-04-23 20:25:44,469:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:44,469:INFO:Creating metrics dataframe
2024-04-23 20:25:44,473:INFO:Initializing Least Angle Regression
2024-04-23 20:25:44,473:INFO:Total runtime is 0.18103678623835245 minutes
2024-04-23 20:25:44,473:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:44,474:INFO:Initializing create_model()
2024-04-23 20:25:44,474:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:44,474:INFO:Checking exceptions
2024-04-23 20:25:44,474:INFO:Importing libraries
2024-04-23 20:25:44,474:INFO:Copying training dataset
2024-04-23 20:25:44,477:INFO:Defining folds
2024-04-23 20:25:44,478:INFO:Declaring metric variables
2024-04-23 20:25:44,478:INFO:Importing untrained model
2024-04-23 20:25:44,478:INFO:Least Angle Regression Imported successfully
2024-04-23 20:25:44,479:INFO:Starting cross validation
2024-04-23 20:25:44,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:44,840:INFO:Calculating mean and std
2024-04-23 20:25:44,841:INFO:Creating metrics dataframe
2024-04-23 20:25:44,844:INFO:Uploading results into container
2024-04-23 20:25:44,845:INFO:Uploading model into container now
2024-04-23 20:25:44,845:INFO:_master_model_container: 5
2024-04-23 20:25:44,845:INFO:_display_container: 2
2024-04-23 20:25:44,845:INFO:Lars(random_state=571)
2024-04-23 20:25:44,845:INFO:create_model() successfully completed......................................
2024-04-23 20:25:44,994:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:44,995:INFO:Creating metrics dataframe
2024-04-23 20:25:44,999:INFO:Initializing Lasso Least Angle Regression
2024-04-23 20:25:45,000:INFO:Total runtime is 0.18981643120447794 minutes
2024-04-23 20:25:45,000:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:45,000:INFO:Initializing create_model()
2024-04-23 20:25:45,000:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:45,000:INFO:Checking exceptions
2024-04-23 20:25:45,000:INFO:Importing libraries
2024-04-23 20:25:45,000:INFO:Copying training dataset
2024-04-23 20:25:45,004:INFO:Defining folds
2024-04-23 20:25:45,005:INFO:Declaring metric variables
2024-04-23 20:25:45,005:INFO:Importing untrained model
2024-04-23 20:25:45,005:INFO:Lasso Least Angle Regression Imported successfully
2024-04-23 20:25:45,005:INFO:Starting cross validation
2024-04-23 20:25:45,006:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:45,349:INFO:Calculating mean and std
2024-04-23 20:25:45,351:INFO:Creating metrics dataframe
2024-04-23 20:25:45,354:INFO:Uploading results into container
2024-04-23 20:25:45,355:INFO:Uploading model into container now
2024-04-23 20:25:45,355:INFO:_master_model_container: 6
2024-04-23 20:25:45,355:INFO:_display_container: 2
2024-04-23 20:25:45,356:INFO:LassoLars(random_state=571)
2024-04-23 20:25:45,356:INFO:create_model() successfully completed......................................
2024-04-23 20:25:45,492:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:45,492:INFO:Creating metrics dataframe
2024-04-23 20:25:45,496:INFO:Initializing Orthogonal Matching Pursuit
2024-04-23 20:25:45,496:INFO:Total runtime is 0.19807765086491902 minutes
2024-04-23 20:25:45,496:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:45,497:INFO:Initializing create_model()
2024-04-23 20:25:45,497:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:45,497:INFO:Checking exceptions
2024-04-23 20:25:45,497:INFO:Importing libraries
2024-04-23 20:25:45,497:INFO:Copying training dataset
2024-04-23 20:25:45,500:INFO:Defining folds
2024-04-23 20:25:45,501:INFO:Declaring metric variables
2024-04-23 20:25:45,501:INFO:Importing untrained model
2024-04-23 20:25:45,501:INFO:Orthogonal Matching Pursuit Imported successfully
2024-04-23 20:25:45,501:INFO:Starting cross validation
2024-04-23 20:25:45,503:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:45,872:INFO:Calculating mean and std
2024-04-23 20:25:45,872:INFO:Creating metrics dataframe
2024-04-23 20:25:45,875:INFO:Uploading results into container
2024-04-23 20:25:45,876:INFO:Uploading model into container now
2024-04-23 20:25:45,876:INFO:_master_model_container: 7
2024-04-23 20:25:45,876:INFO:_display_container: 2
2024-04-23 20:25:45,876:INFO:OrthogonalMatchingPursuit()
2024-04-23 20:25:45,876:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,009:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,009:INFO:Creating metrics dataframe
2024-04-23 20:25:46,013:INFO:Initializing Bayesian Ridge
2024-04-23 20:25:46,013:INFO:Total runtime is 0.2067064881324768 minutes
2024-04-23 20:25:46,014:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,014:INFO:Initializing create_model()
2024-04-23 20:25:46,014:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,014:INFO:Checking exceptions
2024-04-23 20:25:46,014:INFO:Importing libraries
2024-04-23 20:25:46,014:INFO:Copying training dataset
2024-04-23 20:25:46,018:INFO:Defining folds
2024-04-23 20:25:46,018:INFO:Declaring metric variables
2024-04-23 20:25:46,019:INFO:Importing untrained model
2024-04-23 20:25:46,019:INFO:Bayesian Ridge Imported successfully
2024-04-23 20:25:46,019:INFO:Starting cross validation
2024-04-23 20:25:46,021:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:46,356:INFO:Calculating mean and std
2024-04-23 20:25:46,357:INFO:Creating metrics dataframe
2024-04-23 20:25:46,360:INFO:Uploading results into container
2024-04-23 20:25:46,360:INFO:Uploading model into container now
2024-04-23 20:25:46,360:INFO:_master_model_container: 8
2024-04-23 20:25:46,360:INFO:_display_container: 2
2024-04-23 20:25:46,361:INFO:BayesianRidge()
2024-04-23 20:25:46,361:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,490:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,490:INFO:Creating metrics dataframe
2024-04-23 20:25:46,494:INFO:Initializing Passive Aggressive Regressor
2024-04-23 20:25:46,494:INFO:Total runtime is 0.2147192319234212 minutes
2024-04-23 20:25:46,495:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,495:INFO:Initializing create_model()
2024-04-23 20:25:46,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,495:INFO:Checking exceptions
2024-04-23 20:25:46,495:INFO:Importing libraries
2024-04-23 20:25:46,495:INFO:Copying training dataset
2024-04-23 20:25:46,499:INFO:Defining folds
2024-04-23 20:25:46,499:INFO:Declaring metric variables
2024-04-23 20:25:46,499:INFO:Importing untrained model
2024-04-23 20:25:46,499:INFO:Passive Aggressive Regressor Imported successfully
2024-04-23 20:25:46,500:INFO:Starting cross validation
2024-04-23 20:25:46,501:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:46,831:INFO:Calculating mean and std
2024-04-23 20:25:46,831:INFO:Creating metrics dataframe
2024-04-23 20:25:46,834:INFO:Uploading results into container
2024-04-23 20:25:46,835:INFO:Uploading model into container now
2024-04-23 20:25:46,835:INFO:_master_model_container: 9
2024-04-23 20:25:46,835:INFO:_display_container: 2
2024-04-23 20:25:46,835:INFO:PassiveAggressiveRegressor(random_state=571)
2024-04-23 20:25:46,835:INFO:create_model() successfully completed......................................
2024-04-23 20:25:46,975:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:46,975:INFO:Creating metrics dataframe
2024-04-23 20:25:46,980:INFO:Initializing Huber Regressor
2024-04-23 20:25:46,981:INFO:Total runtime is 0.2228252053260803 minutes
2024-04-23 20:25:46,981:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:46,982:INFO:Initializing create_model()
2024-04-23 20:25:46,982:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:46,982:INFO:Checking exceptions
2024-04-23 20:25:46,982:INFO:Importing libraries
2024-04-23 20:25:46,983:INFO:Copying training dataset
2024-04-23 20:25:46,987:INFO:Defining folds
2024-04-23 20:25:46,987:INFO:Declaring metric variables
2024-04-23 20:25:46,987:INFO:Importing untrained model
2024-04-23 20:25:46,987:INFO:Huber Regressor Imported successfully
2024-04-23 20:25:46,987:INFO:Starting cross validation
2024-04-23 20:25:46,989:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:47,268:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,282:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,304:WARNING:C:\Users\User\AppData\Roaming\Python\Python310\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2024-04-23 20:25:47,367:INFO:Calculating mean and std
2024-04-23 20:25:47,368:INFO:Creating metrics dataframe
2024-04-23 20:25:47,370:INFO:Uploading results into container
2024-04-23 20:25:47,371:INFO:Uploading model into container now
2024-04-23 20:25:47,371:INFO:_master_model_container: 10
2024-04-23 20:25:47,371:INFO:_display_container: 2
2024-04-23 20:25:47,371:INFO:HuberRegressor()
2024-04-23 20:25:47,371:INFO:create_model() successfully completed......................................
2024-04-23 20:25:47,503:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:47,503:INFO:Creating metrics dataframe
2024-04-23 20:25:47,507:INFO:Initializing K Neighbors Regressor
2024-04-23 20:25:47,507:INFO:Total runtime is 0.2316017150878906 minutes
2024-04-23 20:25:47,508:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:47,508:INFO:Initializing create_model()
2024-04-23 20:25:47,508:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:47,508:INFO:Checking exceptions
2024-04-23 20:25:47,508:INFO:Importing libraries
2024-04-23 20:25:47,508:INFO:Copying training dataset
2024-04-23 20:25:47,512:INFO:Defining folds
2024-04-23 20:25:47,512:INFO:Declaring metric variables
2024-04-23 20:25:47,512:INFO:Importing untrained model
2024-04-23 20:25:47,512:INFO:K Neighbors Regressor Imported successfully
2024-04-23 20:25:47,512:INFO:Starting cross validation
2024-04-23 20:25:47,513:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:47,891:INFO:Calculating mean and std
2024-04-23 20:25:47,891:INFO:Creating metrics dataframe
2024-04-23 20:25:47,894:INFO:Uploading results into container
2024-04-23 20:25:47,895:INFO:Uploading model into container now
2024-04-23 20:25:47,895:INFO:_master_model_container: 11
2024-04-23 20:25:47,895:INFO:_display_container: 2
2024-04-23 20:25:47,896:INFO:KNeighborsRegressor(n_jobs=-1)
2024-04-23 20:25:47,896:INFO:create_model() successfully completed......................................
2024-04-23 20:25:48,027:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:48,027:INFO:Creating metrics dataframe
2024-04-23 20:25:48,031:INFO:Initializing Decision Tree Regressor
2024-04-23 20:25:48,031:INFO:Total runtime is 0.24032702048619586 minutes
2024-04-23 20:25:48,032:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:48,032:INFO:Initializing create_model()
2024-04-23 20:25:48,032:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:48,032:INFO:Checking exceptions
2024-04-23 20:25:48,032:INFO:Importing libraries
2024-04-23 20:25:48,032:INFO:Copying training dataset
2024-04-23 20:25:48,036:INFO:Defining folds
2024-04-23 20:25:48,036:INFO:Declaring metric variables
2024-04-23 20:25:48,036:INFO:Importing untrained model
2024-04-23 20:25:48,036:INFO:Decision Tree Regressor Imported successfully
2024-04-23 20:25:48,036:INFO:Starting cross validation
2024-04-23 20:25:48,037:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:48,349:INFO:Calculating mean and std
2024-04-23 20:25:48,350:INFO:Creating metrics dataframe
2024-04-23 20:25:48,353:INFO:Uploading results into container
2024-04-23 20:25:48,354:INFO:Uploading model into container now
2024-04-23 20:25:48,354:INFO:_master_model_container: 12
2024-04-23 20:25:48,354:INFO:_display_container: 2
2024-04-23 20:25:48,355:INFO:DecisionTreeRegressor(random_state=571)
2024-04-23 20:25:48,355:INFO:create_model() successfully completed......................................
2024-04-23 20:25:48,484:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:48,484:INFO:Creating metrics dataframe
2024-04-23 20:25:48,489:INFO:Initializing Random Forest Regressor
2024-04-23 20:25:48,489:INFO:Total runtime is 0.24795717795689898 minutes
2024-04-23 20:25:48,489:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:48,489:INFO:Initializing create_model()
2024-04-23 20:25:48,490:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:48,490:INFO:Checking exceptions
2024-04-23 20:25:48,490:INFO:Importing libraries
2024-04-23 20:25:48,490:INFO:Copying training dataset
2024-04-23 20:25:48,492:INFO:Defining folds
2024-04-23 20:25:48,492:INFO:Declaring metric variables
2024-04-23 20:25:48,493:INFO:Importing untrained model
2024-04-23 20:25:48,493:INFO:Random Forest Regressor Imported successfully
2024-04-23 20:25:48,493:INFO:Starting cross validation
2024-04-23 20:25:48,494:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:49,231:INFO:Calculating mean and std
2024-04-23 20:25:49,231:INFO:Creating metrics dataframe
2024-04-23 20:25:49,235:INFO:Uploading results into container
2024-04-23 20:25:49,235:INFO:Uploading model into container now
2024-04-23 20:25:49,236:INFO:_master_model_container: 13
2024-04-23 20:25:49,236:INFO:_display_container: 2
2024-04-23 20:25:49,236:INFO:RandomForestRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:49,236:INFO:create_model() successfully completed......................................
2024-04-23 20:25:49,367:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:49,367:INFO:Creating metrics dataframe
2024-04-23 20:25:49,372:INFO:Initializing Extra Trees Regressor
2024-04-23 20:25:49,372:INFO:Total runtime is 0.2626766403516133 minutes
2024-04-23 20:25:49,372:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:49,373:INFO:Initializing create_model()
2024-04-23 20:25:49,373:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:49,373:INFO:Checking exceptions
2024-04-23 20:25:49,373:INFO:Importing libraries
2024-04-23 20:25:49,373:INFO:Copying training dataset
2024-04-23 20:25:49,379:INFO:Defining folds
2024-04-23 20:25:49,379:INFO:Declaring metric variables
2024-04-23 20:25:49,379:INFO:Importing untrained model
2024-04-23 20:25:49,380:INFO:Extra Trees Regressor Imported successfully
2024-04-23 20:25:49,380:INFO:Starting cross validation
2024-04-23 20:25:49,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:50,026:INFO:Calculating mean and std
2024-04-23 20:25:50,027:INFO:Creating metrics dataframe
2024-04-23 20:25:50,030:INFO:Uploading results into container
2024-04-23 20:25:50,030:INFO:Uploading model into container now
2024-04-23 20:25:50,031:INFO:_master_model_container: 14
2024-04-23 20:25:50,031:INFO:_display_container: 2
2024-04-23 20:25:50,031:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:50,031:INFO:create_model() successfully completed......................................
2024-04-23 20:25:50,164:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:50,164:INFO:Creating metrics dataframe
2024-04-23 20:25:50,169:INFO:Initializing AdaBoost Regressor
2024-04-23 20:25:50,169:INFO:Total runtime is 0.2759583473205566 minutes
2024-04-23 20:25:50,169:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:50,170:INFO:Initializing create_model()
2024-04-23 20:25:50,170:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:50,170:INFO:Checking exceptions
2024-04-23 20:25:50,170:INFO:Importing libraries
2024-04-23 20:25:50,170:INFO:Copying training dataset
2024-04-23 20:25:50,174:INFO:Defining folds
2024-04-23 20:25:50,174:INFO:Declaring metric variables
2024-04-23 20:25:50,174:INFO:Importing untrained model
2024-04-23 20:25:50,175:INFO:AdaBoost Regressor Imported successfully
2024-04-23 20:25:50,175:INFO:Starting cross validation
2024-04-23 20:25:50,176:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:50,659:INFO:Calculating mean and std
2024-04-23 20:25:50,661:INFO:Creating metrics dataframe
2024-04-23 20:25:50,664:INFO:Uploading results into container
2024-04-23 20:25:50,664:INFO:Uploading model into container now
2024-04-23 20:25:50,664:INFO:_master_model_container: 15
2024-04-23 20:25:50,664:INFO:_display_container: 2
2024-04-23 20:25:50,665:INFO:AdaBoostRegressor(random_state=571)
2024-04-23 20:25:50,665:INFO:create_model() successfully completed......................................
2024-04-23 20:25:50,798:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:50,798:INFO:Creating metrics dataframe
2024-04-23 20:25:50,802:INFO:Initializing Gradient Boosting Regressor
2024-04-23 20:25:50,803:INFO:Total runtime is 0.2865343769391377 minutes
2024-04-23 20:25:50,803:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:50,803:INFO:Initializing create_model()
2024-04-23 20:25:50,803:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:50,803:INFO:Checking exceptions
2024-04-23 20:25:50,803:INFO:Importing libraries
2024-04-23 20:25:50,803:INFO:Copying training dataset
2024-04-23 20:25:50,807:INFO:Defining folds
2024-04-23 20:25:50,807:INFO:Declaring metric variables
2024-04-23 20:25:50,807:INFO:Importing untrained model
2024-04-23 20:25:50,808:INFO:Gradient Boosting Regressor Imported successfully
2024-04-23 20:25:50,808:INFO:Starting cross validation
2024-04-23 20:25:50,809:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:51,377:INFO:Calculating mean and std
2024-04-23 20:25:51,379:INFO:Creating metrics dataframe
2024-04-23 20:25:51,383:INFO:Uploading results into container
2024-04-23 20:25:51,384:INFO:Uploading model into container now
2024-04-23 20:25:51,384:INFO:_master_model_container: 16
2024-04-23 20:25:51,384:INFO:_display_container: 2
2024-04-23 20:25:51,384:INFO:GradientBoostingRegressor(random_state=571)
2024-04-23 20:25:51,385:INFO:create_model() successfully completed......................................
2024-04-23 20:25:51,535:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:51,535:INFO:Creating metrics dataframe
2024-04-23 20:25:51,539:INFO:Initializing Light Gradient Boosting Machine
2024-04-23 20:25:51,540:INFO:Total runtime is 0.2988181749979654 minutes
2024-04-23 20:25:51,540:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:51,540:INFO:Initializing create_model()
2024-04-23 20:25:51,540:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:51,540:INFO:Checking exceptions
2024-04-23 20:25:51,540:INFO:Importing libraries
2024-04-23 20:25:51,540:INFO:Copying training dataset
2024-04-23 20:25:51,544:INFO:Defining folds
2024-04-23 20:25:51,545:INFO:Declaring metric variables
2024-04-23 20:25:51,545:INFO:Importing untrained model
2024-04-23 20:25:51,545:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-23 20:25:51,546:INFO:Starting cross validation
2024-04-23 20:25:51,548:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:52,950:INFO:Calculating mean and std
2024-04-23 20:25:52,951:INFO:Creating metrics dataframe
2024-04-23 20:25:52,955:INFO:Uploading results into container
2024-04-23 20:25:52,955:INFO:Uploading model into container now
2024-04-23 20:25:52,956:INFO:_master_model_container: 17
2024-04-23 20:25:52,956:INFO:_display_container: 2
2024-04-23 20:25:52,956:INFO:LGBMRegressor(n_jobs=-1, random_state=571)
2024-04-23 20:25:52,956:INFO:create_model() successfully completed......................................
2024-04-23 20:25:53,163:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:53,163:INFO:Creating metrics dataframe
2024-04-23 20:25:53,171:INFO:Initializing Dummy Regressor
2024-04-23 20:25:53,171:INFO:Total runtime is 0.32599687178929637 minutes
2024-04-23 20:25:53,171:INFO:SubProcess create_model() called ==================================
2024-04-23 20:25:53,172:INFO:Initializing create_model()
2024-04-23 20:25:53,172:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001CC32DB87F0>, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:53,172:INFO:Checking exceptions
2024-04-23 20:25:53,172:INFO:Importing libraries
2024-04-23 20:25:53,172:INFO:Copying training dataset
2024-04-23 20:25:53,195:INFO:Defining folds
2024-04-23 20:25:53,197:INFO:Declaring metric variables
2024-04-23 20:25:53,197:INFO:Importing untrained model
2024-04-23 20:25:53,203:INFO:Dummy Regressor Imported successfully
2024-04-23 20:25:53,206:INFO:Starting cross validation
2024-04-23 20:25:53,212:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-23 20:25:53,865:INFO:Calculating mean and std
2024-04-23 20:25:53,866:INFO:Creating metrics dataframe
2024-04-23 20:25:53,870:INFO:Uploading results into container
2024-04-23 20:25:53,870:INFO:Uploading model into container now
2024-04-23 20:25:53,871:INFO:_master_model_container: 18
2024-04-23 20:25:53,871:INFO:_display_container: 2
2024-04-23 20:25:53,871:INFO:DummyRegressor()
2024-04-23 20:25:53,871:INFO:create_model() successfully completed......................................
2024-04-23 20:25:54,048:INFO:SubProcess create_model() end ==================================
2024-04-23 20:25:54,048:INFO:Creating metrics dataframe
2024-04-23 20:25:54,055:INFO:Initializing create_model()
2024-04-23 20:25:54,055:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=Ridge(random_state=571), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2024-04-23 20:25:54,055:INFO:Checking exceptions
2024-04-23 20:25:54,056:INFO:Importing libraries
2024-04-23 20:25:54,056:INFO:Copying training dataset
2024-04-23 20:25:54,059:INFO:Defining folds
2024-04-23 20:25:54,059:INFO:Declaring metric variables
2024-04-23 20:25:54,059:INFO:Importing untrained model
2024-04-23 20:25:54,059:INFO:Declaring custom model
2024-04-23 20:25:54,060:INFO:Ridge Regression Imported successfully
2024-04-23 20:25:54,061:INFO:Cross validation set to False
2024-04-23 20:25:54,061:INFO:Fitting Model
2024-04-23 20:25:54,138:INFO:Ridge(random_state=571)
2024-04-23 20:25:54,138:INFO:create_model() successfully completed......................................
2024-04-23 20:25:54,304:INFO:_master_model_container: 18
2024-04-23 20:25:54,304:INFO:_display_container: 2
2024-04-23 20:25:54,305:INFO:Ridge(random_state=571)
2024-04-23 20:25:54,305:INFO:compare_models() successfully completed......................................
2024-04-23 20:25:54,399:INFO:Initializing save_model()
2024-04-23 20:25:54,400:INFO:save_model(model=Ridge(random_state=571), model_name=best_regressor, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
NaN   -1
dtype: int64},
                                                                        {'col': 'airconditioning',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))]), verbose=True, use_case=MLUsecase.REGRESSION, kwargs={})
2024-04-23 20:25:54,400:INFO:Adding model into prep_pipe
2024-04-23 20:25:54,409:INFO:best_regressor.pkl saved in current working directory
2024-04-23 20:25:54,504:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'furnishingstatus'],
                                    transformer=SimpleImput...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=571))])
2024-04-23 20:25:54,504:INFO:save_model() successfully completed......................................
2024-04-23 20:26:55,320:INFO:Initializing load_model()
2024-04-23 20:26:55,320:INFO:load_model(model_name=trained_regressor, platform=None, authentication=None, verbose=True)
2024-04-23 20:26:55,471:INFO:Initializing predict_model()
2024-04-23 20:26:55,471:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000001CC70A41BD0>, estimator=Pipeline(memory=FastMemory(location=C:\Users\User\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['area', 'bedrooms', 'bathrooms',
                                             'stories', 'parking'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['mainroad', 'guestroom',
                                             'basement', 'hotwaterheating',
                                             'airconditioning', 'prefarea',
                                             'fur...
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64},
                                                                        {'col': 'prefarea',
                                                                         'data_type': dtype('O'),
                                                                         'mapping': no     0
yes    1
NaN   -1
dtype: int64}]))),
                ('onehot_encoding',
                 TransformerWrapper(include=['furnishingstatus'],
                                    transformer=OneHotEncoder(cols=['furnishingstatus'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('trained_model', Ridge(random_state=571))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001CC31F94310>)
2024-04-23 20:26:55,471:INFO:Checking exceptions
2024-04-23 20:26:55,471:INFO:Preloading libraries
2024-04-23 20:26:55,472:INFO:Set up data.
2024-04-23 20:26:55,479:INFO:Set up index.
2024-04-23 21:46:31,270:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 21:46:31,286:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 21:46:31,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 21:46:31,287:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-23 21:48:11,352:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'could not convert string to float: 'yes'')
  warnings.warn(

2024-04-23 21:50:18,983:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000026771FA2E40, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-23 21:51:55,436:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x0000026771FA2E40, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-29 21:20:09,501:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-29 21:20:09,513:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-29 21:20:09,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-29 21:20:09,595:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2024-04-29 21:24:21,867:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001E4A218BC00, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-29 21:26:48,970:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001E4A218BC00, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-29 21:26:54,888:INFO:PyCaret ClassificationExperiment
2024-04-29 21:26:54,889:INFO:Logging name: clf-default-name
2024-04-29 21:26:54,890:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:26:54,890:INFO:version 3.3.1
2024-04-29 21:26:54,890:INFO:Initializing setup()
2024-04-29 21:26:54,890:INFO:self.USI: 3255
2024-04-29 21:26:54,890:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:26:54,890:INFO:Checking environment
2024-04-29 21:26:54,890:INFO:python_version: 3.10.0
2024-04-29 21:26:54,891:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:26:54,891:INFO:machine: AMD64
2024-04-29 21:26:55,006:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:26:55,015:INFO:Memory: svmem(total=8361132032, available=1570709504, percent=81.2, used=6790422528, free=1570709504)
2024-04-29 21:26:55,015:INFO:Physical Core: 4
2024-04-29 21:26:55,015:INFO:Logical Core: 8
2024-04-29 21:26:55,015:INFO:Checking libraries
2024-04-29 21:26:55,015:INFO:System:
2024-04-29 21:26:55,015:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:26:55,016:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:26:55,016:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:26:55,017:INFO:PyCaret required dependencies:
2024-04-29 21:26:56,005:INFO:                 pip: 21.2.3
2024-04-29 21:26:56,005:INFO:          setuptools: 57.4.0
2024-04-29 21:26:56,006:INFO:             pycaret: 3.3.1
2024-04-29 21:26:56,006:INFO:             IPython: 8.23.0
2024-04-29 21:26:56,006:INFO:          ipywidgets: 8.1.2
2024-04-29 21:26:56,006:INFO:                tqdm: 4.66.2
2024-04-29 21:26:56,006:INFO:               numpy: 1.26.4
2024-04-29 21:26:56,006:INFO:              pandas: 2.1.4
2024-04-29 21:26:56,006:INFO:              jinja2: 3.1.3
2024-04-29 21:26:56,007:INFO:               scipy: 1.11.4
2024-04-29 21:26:56,007:INFO:              joblib: 1.3.2
2024-04-29 21:26:56,011:INFO:             sklearn: 1.4.2
2024-04-29 21:26:56,011:INFO:                pyod: 1.1.3
2024-04-29 21:26:56,013:INFO:            imblearn: 0.12.2
2024-04-29 21:26:56,017:INFO:   category_encoders: 2.6.3
2024-04-29 21:26:56,018:INFO:            lightgbm: 4.3.0
2024-04-29 21:26:56,036:INFO:               numba: 0.59.1
2024-04-29 21:26:56,049:INFO:            requests: 2.31.0
2024-04-29 21:26:56,056:INFO:          matplotlib: 3.7.5
2024-04-29 21:26:56,056:INFO:          scikitplot: 0.3.7
2024-04-29 21:26:56,162:INFO:         yellowbrick: 1.5
2024-04-29 21:26:56,162:INFO:              plotly: 5.21.0
2024-04-29 21:26:56,162:INFO:    plotly-resampler: Not installed
2024-04-29 21:26:56,162:INFO:             kaleido: 0.2.1
2024-04-29 21:26:56,162:INFO:           schemdraw: 0.15
2024-04-29 21:26:56,162:INFO:         statsmodels: 0.14.2
2024-04-29 21:26:56,162:INFO:              sktime: 0.26.0
2024-04-29 21:26:56,162:INFO:               tbats: 1.1.3
2024-04-29 21:26:56,162:INFO:            pmdarima: 2.0.4
2024-04-29 21:26:56,162:INFO:              psutil: 5.9.8
2024-04-29 21:26:56,162:INFO:          markupsafe: 2.1.5
2024-04-29 21:26:56,162:INFO:             pickle5: Not installed
2024-04-29 21:26:56,162:INFO:         cloudpickle: 3.0.0
2024-04-29 21:26:56,163:INFO:         deprecation: 2.1.0
2024-04-29 21:26:56,163:INFO:              xxhash: 3.4.1
2024-04-29 21:26:56,163:INFO:           wurlitzer: Not installed
2024-04-29 21:26:56,163:INFO:PyCaret optional dependencies:
2024-04-29 21:26:56,405:INFO:                shap: Not installed
2024-04-29 21:26:56,405:INFO:           interpret: Not installed
2024-04-29 21:26:56,405:INFO:                umap: Not installed
2024-04-29 21:26:56,405:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:26:56,405:INFO:  explainerdashboard: Not installed
2024-04-29 21:26:56,405:INFO:             autoviz: Not installed
2024-04-29 21:26:56,405:INFO:           fairlearn: Not installed
2024-04-29 21:26:56,405:INFO:          deepchecks: Not installed
2024-04-29 21:26:56,405:INFO:             xgboost: Not installed
2024-04-29 21:26:56,405:INFO:            catboost: Not installed
2024-04-29 21:26:56,405:INFO:              kmodes: Not installed
2024-04-29 21:26:56,406:INFO:             mlxtend: Not installed
2024-04-29 21:26:56,406:INFO:       statsforecast: Not installed
2024-04-29 21:26:56,406:INFO:        tune_sklearn: Not installed
2024-04-29 21:26:56,406:INFO:                 ray: Not installed
2024-04-29 21:26:56,406:INFO:            hyperopt: Not installed
2024-04-29 21:26:56,406:INFO:              optuna: Not installed
2024-04-29 21:26:56,406:INFO:               skopt: Not installed
2024-04-29 21:26:56,406:INFO:              mlflow: Not installed
2024-04-29 21:26:56,406:INFO:              gradio: Not installed
2024-04-29 21:26:56,406:INFO:             fastapi: Not installed
2024-04-29 21:26:56,406:INFO:             uvicorn: Not installed
2024-04-29 21:26:56,406:INFO:              m2cgen: Not installed
2024-04-29 21:26:56,406:INFO:           evidently: Not installed
2024-04-29 21:26:56,407:INFO:               fugue: Not installed
2024-04-29 21:26:56,407:INFO:           streamlit: 1.33.0
2024-04-29 21:26:56,407:INFO:             prophet: Not installed
2024-04-29 21:26:56,407:INFO:None
2024-04-29 21:26:56,407:INFO:Set up data.
2024-04-29 21:26:56,468:INFO:Set up folding strategy.
2024-04-29 21:26:56,469:INFO:Set up train/test split.
2024-04-29 21:26:56,506:INFO:Set up index.
2024-04-29 21:26:56,507:INFO:Assigning column types.
2024-04-29 21:26:56,514:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-29 21:26:56,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:26:56,701:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:26:56,932:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:56,933:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,014:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:26:57,015:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:26:57,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,061:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,063:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-29 21:26:57,160:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:26:57,229:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,229:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,322:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:26:57,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,371:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-29 21:26:57,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,752:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,753:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:26:57,797:INFO:Preparing preprocessing pipeline...
2024-04-29 21:26:57,879:INFO:Set up simple imputation.
2024-04-29 21:26:57,903:INFO:Set up encoding of ordinal features.
2024-04-29 21:26:57,917:INFO:Set up encoding of categorical features.
2024-04-29 21:26:58,501:INFO:Finished creating preprocessing pipeline.
2024-04-29 21:26:58,534:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-29 21:26:58,534:INFO:Creating final display dataframe.
2024-04-29 21:26:59,964:INFO:Setup _display_container:                     Description             Value
0                    Session id              7406
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              3255
2024-04-29 21:27:00,147:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:00,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:00,309:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:00,312:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:00,314:INFO:setup() successfully completed in 5.48s...............
2024-04-29 21:27:00,403:INFO:Initializing compare_models()
2024-04-29 21:27:00,403:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-29 21:27:00,403:INFO:Checking exceptions
2024-04-29 21:27:00,438:INFO:Preparing display monitor
2024-04-29 21:27:00,451:INFO:Initializing Logistic Regression
2024-04-29 21:27:00,451:INFO:Total runtime is 0.0 minutes
2024-04-29 21:27:00,451:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:00,451:INFO:Initializing create_model()
2024-04-29 21:27:00,452:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:00,452:INFO:Checking exceptions
2024-04-29 21:27:00,452:INFO:Importing libraries
2024-04-29 21:27:00,452:INFO:Copying training dataset
2024-04-29 21:27:00,479:INFO:Defining folds
2024-04-29 21:27:00,484:INFO:Declaring metric variables
2024-04-29 21:27:00,492:INFO:Importing untrained model
2024-04-29 21:27:00,494:INFO:Logistic Regression Imported successfully
2024-04-29 21:27:00,497:INFO:Starting cross validation
2024-04-29 21:27:00,505:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:14,177:WARNING:Render HTML:   0%|                                                                                                  | 0/1 [00:00<?, ?it/s]
2024-04-29 21:27:17,263:WARNING:Render HTML: 100%|##########################################################################################| 1/1 [00:03<00:00,  3.08s/it]
2024-04-29 21:27:17,263:WARNING:Render HTML: 100%|##########################################################################################| 1/1 [00:03<00:00,  3.09s/it]
2024-04-29 21:27:17,263:WARNING:
2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:20,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:21,127:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:21,166:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:21,254:INFO:Calculating mean and std
2024-04-29 21:27:21,255:INFO:Creating metrics dataframe
2024-04-29 21:27:21,259:INFO:Uploading results into container
2024-04-29 21:27:21,260:INFO:Uploading model into container now
2024-04-29 21:27:21,261:INFO:_master_model_container: 1
2024-04-29 21:27:21,261:INFO:_display_container: 2
2024-04-29 21:27:21,262:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7406, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:27:21,262:INFO:create_model() successfully completed......................................
2024-04-29 21:27:21,449:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:21,449:INFO:Creating metrics dataframe
2024-04-29 21:27:21,453:INFO:Initializing K Neighbors Classifier
2024-04-29 21:27:21,454:INFO:Total runtime is 0.35005677143732705 minutes
2024-04-29 21:27:21,454:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:21,455:INFO:Initializing create_model()
2024-04-29 21:27:21,455:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:21,455:INFO:Checking exceptions
2024-04-29 21:27:21,455:INFO:Importing libraries
2024-04-29 21:27:21,456:INFO:Copying training dataset
2024-04-29 21:27:21,467:INFO:Defining folds
2024-04-29 21:27:21,467:INFO:Declaring metric variables
2024-04-29 21:27:21,468:INFO:Importing untrained model
2024-04-29 21:27:21,468:INFO:K Neighbors Classifier Imported successfully
2024-04-29 21:27:21,469:INFO:Starting cross validation
2024-04-29 21:27:21,475:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:22,129:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,130:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,130:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,150:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,416:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,456:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:22,500:INFO:Calculating mean and std
2024-04-29 21:27:22,504:INFO:Creating metrics dataframe
2024-04-29 21:27:22,510:INFO:Uploading results into container
2024-04-29 21:27:22,512:INFO:Uploading model into container now
2024-04-29 21:27:22,514:INFO:_master_model_container: 2
2024-04-29 21:27:22,514:INFO:_display_container: 2
2024-04-29 21:27:22,515:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-29 21:27:22,515:INFO:create_model() successfully completed......................................
2024-04-29 21:27:22,675:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:22,675:INFO:Creating metrics dataframe
2024-04-29 21:27:22,683:INFO:Initializing Naive Bayes
2024-04-29 21:27:22,683:INFO:Total runtime is 0.37054643233617146 minutes
2024-04-29 21:27:22,684:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:22,685:INFO:Initializing create_model()
2024-04-29 21:27:22,685:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:22,685:INFO:Checking exceptions
2024-04-29 21:27:22,685:INFO:Importing libraries
2024-04-29 21:27:22,685:INFO:Copying training dataset
2024-04-29 21:27:22,697:INFO:Defining folds
2024-04-29 21:27:22,697:INFO:Declaring metric variables
2024-04-29 21:27:22,697:INFO:Importing untrained model
2024-04-29 21:27:22,698:INFO:Naive Bayes Imported successfully
2024-04-29 21:27:22,698:INFO:Starting cross validation
2024-04-29 21:27:22,702:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:23,193:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,205:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,213:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,223:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,245:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,253:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,263:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,270:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,476:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,513:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:23,534:INFO:Calculating mean and std
2024-04-29 21:27:23,536:INFO:Creating metrics dataframe
2024-04-29 21:27:23,542:INFO:Uploading results into container
2024-04-29 21:27:23,544:INFO:Uploading model into container now
2024-04-29 21:27:23,545:INFO:_master_model_container: 3
2024-04-29 21:27:23,545:INFO:_display_container: 2
2024-04-29 21:27:23,546:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-29 21:27:23,546:INFO:create_model() successfully completed......................................
2024-04-29 21:27:23,769:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:23,769:INFO:Creating metrics dataframe
2024-04-29 21:27:23,774:INFO:Initializing Decision Tree Classifier
2024-04-29 21:27:23,775:INFO:Total runtime is 0.3887383699417114 minutes
2024-04-29 21:27:23,775:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:23,776:INFO:Initializing create_model()
2024-04-29 21:27:23,776:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:23,776:INFO:Checking exceptions
2024-04-29 21:27:23,776:INFO:Importing libraries
2024-04-29 21:27:23,776:INFO:Copying training dataset
2024-04-29 21:27:23,788:INFO:Defining folds
2024-04-29 21:27:23,788:INFO:Declaring metric variables
2024-04-29 21:27:23,788:INFO:Importing untrained model
2024-04-29 21:27:23,789:INFO:Decision Tree Classifier Imported successfully
2024-04-29 21:27:23,790:INFO:Starting cross validation
2024-04-29 21:27:23,793:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:24,373:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,376:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,377:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,385:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,389:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,393:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,398:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,405:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:24,411:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:24,420:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,435:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:24,708:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,727:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:24,772:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:24,789:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:24,806:INFO:Calculating mean and std
2024-04-29 21:27:24,810:INFO:Creating metrics dataframe
2024-04-29 21:27:24,815:INFO:Uploading results into container
2024-04-29 21:27:24,816:INFO:Uploading model into container now
2024-04-29 21:27:24,817:INFO:_master_model_container: 4
2024-04-29 21:27:24,817:INFO:_display_container: 2
2024-04-29 21:27:24,818:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=7406, splitter='best')
2024-04-29 21:27:24,818:INFO:create_model() successfully completed......................................
2024-04-29 21:27:24,966:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:24,966:INFO:Creating metrics dataframe
2024-04-29 21:27:24,969:INFO:Initializing SVM - Linear Kernel
2024-04-29 21:27:24,970:INFO:Total runtime is 0.408654514948527 minutes
2024-04-29 21:27:24,970:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:24,970:INFO:Initializing create_model()
2024-04-29 21:27:24,970:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:24,970:INFO:Checking exceptions
2024-04-29 21:27:24,970:INFO:Importing libraries
2024-04-29 21:27:24,970:INFO:Copying training dataset
2024-04-29 21:27:24,976:INFO:Defining folds
2024-04-29 21:27:24,976:INFO:Declaring metric variables
2024-04-29 21:27:24,976:INFO:Importing untrained model
2024-04-29 21:27:24,976:INFO:SVM - Linear Kernel Imported successfully
2024-04-29 21:27:24,978:INFO:Starting cross validation
2024-04-29 21:27:24,979:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:25,780:INFO:Calculating mean and std
2024-04-29 21:27:25,783:INFO:Creating metrics dataframe
2024-04-29 21:27:25,789:INFO:Uploading results into container
2024-04-29 21:27:25,792:INFO:Uploading model into container now
2024-04-29 21:27:25,793:INFO:_master_model_container: 5
2024-04-29 21:27:25,793:INFO:_display_container: 2
2024-04-29 21:27:25,795:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=7406, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-29 21:27:25,795:INFO:create_model() successfully completed......................................
2024-04-29 21:27:26,007:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:26,007:INFO:Creating metrics dataframe
2024-04-29 21:27:26,013:INFO:Initializing Ridge Classifier
2024-04-29 21:27:26,014:INFO:Total runtime is 0.42606019179026283 minutes
2024-04-29 21:27:26,014:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:26,015:INFO:Initializing create_model()
2024-04-29 21:27:26,015:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:26,015:INFO:Checking exceptions
2024-04-29 21:27:26,015:INFO:Importing libraries
2024-04-29 21:27:26,016:INFO:Copying training dataset
2024-04-29 21:27:26,026:INFO:Defining folds
2024-04-29 21:27:26,027:INFO:Declaring metric variables
2024-04-29 21:27:26,027:INFO:Importing untrained model
2024-04-29 21:27:26,028:INFO:Ridge Classifier Imported successfully
2024-04-29 21:27:26,029:INFO:Starting cross validation
2024-04-29 21:27:26,033:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:27,147:INFO:Calculating mean and std
2024-04-29 21:27:27,150:INFO:Creating metrics dataframe
2024-04-29 21:27:27,154:INFO:Uploading results into container
2024-04-29 21:27:27,155:INFO:Uploading model into container now
2024-04-29 21:27:27,156:INFO:_master_model_container: 6
2024-04-29 21:27:27,156:INFO:_display_container: 2
2024-04-29 21:27:27,157:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=7406, solver='auto',
                tol=0.0001)
2024-04-29 21:27:27,157:INFO:create_model() successfully completed......................................
2024-04-29 21:27:27,318:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:27,318:INFO:Creating metrics dataframe
2024-04-29 21:27:27,324:INFO:Initializing Random Forest Classifier
2024-04-29 21:27:27,324:INFO:Total runtime is 0.44789272149403886 minutes
2024-04-29 21:27:27,325:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:27,326:INFO:Initializing create_model()
2024-04-29 21:27:27,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:27,326:INFO:Checking exceptions
2024-04-29 21:27:27,326:INFO:Importing libraries
2024-04-29 21:27:27,326:INFO:Copying training dataset
2024-04-29 21:27:27,334:INFO:Defining folds
2024-04-29 21:27:27,334:INFO:Declaring metric variables
2024-04-29 21:27:27,335:INFO:Importing untrained model
2024-04-29 21:27:27,336:INFO:Random Forest Classifier Imported successfully
2024-04-29 21:27:27,337:INFO:Starting cross validation
2024-04-29 21:27:27,343:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:28,221:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,222:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,224:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,237:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,238:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,251:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,284:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,292:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:28,296:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,928:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,939:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:28,972:INFO:Calculating mean and std
2024-04-29 21:27:28,974:INFO:Creating metrics dataframe
2024-04-29 21:27:28,978:INFO:Uploading results into container
2024-04-29 21:27:28,980:INFO:Uploading model into container now
2024-04-29 21:27:28,981:INFO:_master_model_container: 7
2024-04-29 21:27:28,981:INFO:_display_container: 2
2024-04-29 21:27:28,982:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=7406, verbose=0,
                       warm_start=False)
2024-04-29 21:27:28,982:INFO:create_model() successfully completed......................................
2024-04-29 21:27:29,135:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:29,135:INFO:Creating metrics dataframe
2024-04-29 21:27:29,142:INFO:Initializing Quadratic Discriminant Analysis
2024-04-29 21:27:29,142:INFO:Total runtime is 0.4781897902488708 minutes
2024-04-29 21:27:29,142:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:29,143:INFO:Initializing create_model()
2024-04-29 21:27:29,143:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:29,143:INFO:Checking exceptions
2024-04-29 21:27:29,143:INFO:Importing libraries
2024-04-29 21:27:29,143:INFO:Copying training dataset
2024-04-29 21:27:29,158:INFO:Defining folds
2024-04-29 21:27:29,158:INFO:Declaring metric variables
2024-04-29 21:27:29,158:INFO:Importing untrained model
2024-04-29 21:27:29,159:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-29 21:27:29,159:INFO:Starting cross validation
2024-04-29 21:27:29,161:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:29,793:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:29,793:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:29,794:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:29,794:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:29,834:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:29,977:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,011:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,047:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,054:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,055:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,059:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,075:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,222:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:30,228:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:30,324:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,329:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:30,340:INFO:Calculating mean and std
2024-04-29 21:27:30,342:INFO:Creating metrics dataframe
2024-04-29 21:27:30,346:INFO:Uploading results into container
2024-04-29 21:27:30,347:INFO:Uploading model into container now
2024-04-29 21:27:30,347:INFO:_master_model_container: 8
2024-04-29 21:27:30,348:INFO:_display_container: 2
2024-04-29 21:27:30,348:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-29 21:27:30,348:INFO:create_model() successfully completed......................................
2024-04-29 21:27:30,530:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:30,531:INFO:Creating metrics dataframe
2024-04-29 21:27:30,541:INFO:Initializing Ada Boost Classifier
2024-04-29 21:27:30,542:INFO:Total runtime is 0.5015248735745748 minutes
2024-04-29 21:27:30,543:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:30,543:INFO:Initializing create_model()
2024-04-29 21:27:30,544:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:30,544:INFO:Checking exceptions
2024-04-29 21:27:30,544:INFO:Importing libraries
2024-04-29 21:27:30,545:INFO:Copying training dataset
2024-04-29 21:27:30,554:INFO:Defining folds
2024-04-29 21:27:30,555:INFO:Declaring metric variables
2024-04-29 21:27:30,555:INFO:Importing untrained model
2024-04-29 21:27:30,555:INFO:Ada Boost Classifier Imported successfully
2024-04-29 21:27:30,556:INFO:Starting cross validation
2024-04-29 21:27:30,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:31,021:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,022:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,024:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,024:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,052:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,061:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,094:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,140:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,188:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,204:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,205:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,216:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,216:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,223:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,235:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,316:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,351:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:27:31,392:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,441:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:31,480:INFO:Calculating mean and std
2024-04-29 21:27:31,483:INFO:Creating metrics dataframe
2024-04-29 21:27:31,489:INFO:Uploading results into container
2024-04-29 21:27:31,491:INFO:Uploading model into container now
2024-04-29 21:27:31,495:INFO:_master_model_container: 9
2024-04-29 21:27:31,497:INFO:_display_container: 2
2024-04-29 21:27:31,497:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=7406)
2024-04-29 21:27:31,502:INFO:create_model() successfully completed......................................
2024-04-29 21:27:31,738:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:31,738:INFO:Creating metrics dataframe
2024-04-29 21:27:31,746:INFO:Initializing Gradient Boosting Classifier
2024-04-29 21:27:31,746:INFO:Total runtime is 0.5215822498003642 minutes
2024-04-29 21:27:31,746:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:31,747:INFO:Initializing create_model()
2024-04-29 21:27:31,747:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:31,748:INFO:Checking exceptions
2024-04-29 21:27:31,748:INFO:Importing libraries
2024-04-29 21:27:31,748:INFO:Copying training dataset
2024-04-29 21:27:31,763:INFO:Defining folds
2024-04-29 21:27:31,764:INFO:Declaring metric variables
2024-04-29 21:27:31,764:INFO:Importing untrained model
2024-04-29 21:27:31,765:INFO:Gradient Boosting Classifier Imported successfully
2024-04-29 21:27:31,766:INFO:Starting cross validation
2024-04-29 21:27:31,770:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:32,621:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,655:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,632:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,694:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,840:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,936:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,952:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:32,968:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:33,362:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:33,464:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:33,489:INFO:Calculating mean and std
2024-04-29 21:27:33,491:INFO:Creating metrics dataframe
2024-04-29 21:27:33,495:INFO:Uploading results into container
2024-04-29 21:27:33,496:INFO:Uploading model into container now
2024-04-29 21:27:33,496:INFO:_master_model_container: 10
2024-04-29 21:27:33,496:INFO:_display_container: 2
2024-04-29 21:27:33,497:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=7406, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-29 21:27:33,498:INFO:create_model() successfully completed......................................
2024-04-29 21:27:33,654:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:33,654:INFO:Creating metrics dataframe
2024-04-29 21:27:33,659:INFO:Initializing Linear Discriminant Analysis
2024-04-29 21:27:33,659:INFO:Total runtime is 0.5534751534461975 minutes
2024-04-29 21:27:33,659:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:33,660:INFO:Initializing create_model()
2024-04-29 21:27:33,660:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:33,660:INFO:Checking exceptions
2024-04-29 21:27:33,660:INFO:Importing libraries
2024-04-29 21:27:33,660:INFO:Copying training dataset
2024-04-29 21:27:33,668:INFO:Defining folds
2024-04-29 21:27:33,668:INFO:Declaring metric variables
2024-04-29 21:27:33,669:INFO:Importing untrained model
2024-04-29 21:27:33,670:INFO:Linear Discriminant Analysis Imported successfully
2024-04-29 21:27:33,671:INFO:Starting cross validation
2024-04-29 21:27:33,675:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:34,243:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,245:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,252:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,252:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,255:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,272:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,284:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,545:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:34,562:INFO:Calculating mean and std
2024-04-29 21:27:34,563:INFO:Creating metrics dataframe
2024-04-29 21:27:34,571:INFO:Uploading results into container
2024-04-29 21:27:34,572:INFO:Uploading model into container now
2024-04-29 21:27:34,574:INFO:_master_model_container: 11
2024-04-29 21:27:34,574:INFO:_display_container: 2
2024-04-29 21:27:34,574:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-29 21:27:34,575:INFO:create_model() successfully completed......................................
2024-04-29 21:27:34,739:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:34,740:INFO:Creating metrics dataframe
2024-04-29 21:27:34,749:INFO:Initializing Extra Trees Classifier
2024-04-29 21:27:34,749:INFO:Total runtime is 0.5716393709182739 minutes
2024-04-29 21:27:34,749:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:34,750:INFO:Initializing create_model()
2024-04-29 21:27:34,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:34,751:INFO:Checking exceptions
2024-04-29 21:27:34,753:INFO:Importing libraries
2024-04-29 21:27:34,753:INFO:Copying training dataset
2024-04-29 21:27:34,770:INFO:Defining folds
2024-04-29 21:27:34,771:INFO:Declaring metric variables
2024-04-29 21:27:34,771:INFO:Importing untrained model
2024-04-29 21:27:34,772:INFO:Extra Trees Classifier Imported successfully
2024-04-29 21:27:34,773:INFO:Starting cross validation
2024-04-29 21:27:34,779:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:35,927:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:35,991:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:35,992:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,096:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,097:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,098:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,101:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,138:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,516:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,516:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:36,544:INFO:Calculating mean and std
2024-04-29 21:27:36,546:INFO:Creating metrics dataframe
2024-04-29 21:27:36,550:INFO:Uploading results into container
2024-04-29 21:27:36,551:INFO:Uploading model into container now
2024-04-29 21:27:36,552:INFO:_master_model_container: 12
2024-04-29 21:27:36,552:INFO:_display_container: 2
2024-04-29 21:27:36,552:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=7406, verbose=0,
                     warm_start=False)
2024-04-29 21:27:36,552:INFO:create_model() successfully completed......................................
2024-04-29 21:27:36,706:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:36,706:INFO:Creating metrics dataframe
2024-04-29 21:27:36,714:INFO:Initializing Light Gradient Boosting Machine
2024-04-29 21:27:36,715:INFO:Total runtime is 0.6044070839881897 minutes
2024-04-29 21:27:36,715:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:36,716:INFO:Initializing create_model()
2024-04-29 21:27:36,716:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:36,716:INFO:Checking exceptions
2024-04-29 21:27:36,716:INFO:Importing libraries
2024-04-29 21:27:36,716:INFO:Copying training dataset
2024-04-29 21:27:36,728:INFO:Defining folds
2024-04-29 21:27:36,728:INFO:Declaring metric variables
2024-04-29 21:27:36,728:INFO:Importing untrained model
2024-04-29 21:27:36,730:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-29 21:27:36,730:INFO:Starting cross validation
2024-04-29 21:27:36,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:38,587:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:38,602:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:38,618:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:38,631:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:38,663:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:38,684:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:38,829:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:38,839:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:38,985:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:38,997:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,000:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,012:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,024:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,032:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,036:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,085:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,294:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,300:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,300:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,312:INFO:Calculating mean and std
2024-04-29 21:27:39,313:INFO:Creating metrics dataframe
2024-04-29 21:27:39,316:INFO:Uploading results into container
2024-04-29 21:27:39,317:INFO:Uploading model into container now
2024-04-29 21:27:39,317:INFO:_master_model_container: 13
2024-04-29 21:27:39,317:INFO:_display_container: 2
2024-04-29 21:27:39,318:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=7406, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-29 21:27:39,318:INFO:create_model() successfully completed......................................
2024-04-29 21:27:39,435:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:39,435:INFO:Creating metrics dataframe
2024-04-29 21:27:39,439:INFO:Initializing Dummy Classifier
2024-04-29 21:27:39,439:INFO:Total runtime is 0.6498034238815307 minutes
2024-04-29 21:27:39,439:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:39,439:INFO:Initializing create_model()
2024-04-29 21:27:39,439:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BCD29C60>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:39,439:INFO:Checking exceptions
2024-04-29 21:27:39,439:INFO:Importing libraries
2024-04-29 21:27:39,439:INFO:Copying training dataset
2024-04-29 21:27:39,444:INFO:Defining folds
2024-04-29 21:27:39,444:INFO:Declaring metric variables
2024-04-29 21:27:39,444:INFO:Importing untrained model
2024-04-29 21:27:39,445:INFO:Dummy Classifier Imported successfully
2024-04-29 21:27:39,445:INFO:Starting cross validation
2024-04-29 21:27:39,450:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:39,945:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,949:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,959:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,959:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,963:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,965:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:39,967:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,974:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,976:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:39,987:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,009:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:40,013:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:40,017:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:40,021:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,024:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,029:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,262:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:40,265:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:40,275:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,279:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:40,296:INFO:Calculating mean and std
2024-04-29 21:27:40,297:INFO:Creating metrics dataframe
2024-04-29 21:27:40,300:INFO:Uploading results into container
2024-04-29 21:27:40,302:INFO:Uploading model into container now
2024-04-29 21:27:40,305:INFO:_master_model_container: 14
2024-04-29 21:27:40,306:INFO:_display_container: 2
2024-04-29 21:27:40,307:INFO:DummyClassifier(constant=None, random_state=7406, strategy='prior')
2024-04-29 21:27:40,308:INFO:create_model() successfully completed......................................
2024-04-29 21:27:40,459:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:40,460:INFO:Creating metrics dataframe
2024-04-29 21:27:40,496:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-29 21:27:40,501:INFO:Initializing create_model()
2024-04-29 21:27:40,501:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4912F4A90>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7406, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:40,501:INFO:Checking exceptions
2024-04-29 21:27:40,502:INFO:Importing libraries
2024-04-29 21:27:40,502:INFO:Copying training dataset
2024-04-29 21:27:40,513:INFO:Defining folds
2024-04-29 21:27:40,513:INFO:Declaring metric variables
2024-04-29 21:27:40,518:INFO:Importing untrained model
2024-04-29 21:27:40,518:INFO:Declaring custom model
2024-04-29 21:27:40,520:INFO:Logistic Regression Imported successfully
2024-04-29 21:27:40,523:INFO:Cross validation set to False
2024-04-29 21:27:40,524:INFO:Fitting Model
2024-04-29 21:27:40,900:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:40,902:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7406, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:27:40,902:INFO:create_model() successfully completed......................................
2024-04-29 21:27:41,162:INFO:_master_model_container: 14
2024-04-29 21:27:41,162:INFO:_display_container: 2
2024-04-29 21:27:41,163:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=7406, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:27:41,164:INFO:compare_models() successfully completed......................................
2024-04-29 21:27:43,644:INFO:PyCaret ClassificationExperiment
2024-04-29 21:27:43,644:INFO:Logging name: clf-default-name
2024-04-29 21:27:43,644:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:27:43,645:INFO:version 3.3.1
2024-04-29 21:27:43,645:INFO:Initializing setup()
2024-04-29 21:27:43,645:INFO:self.USI: bbd7
2024-04-29 21:27:43,645:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:27:43,645:INFO:Checking environment
2024-04-29 21:27:43,645:INFO:python_version: 3.10.0
2024-04-29 21:27:43,645:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:27:43,645:INFO:machine: AMD64
2024-04-29 21:27:43,645:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:27:43,651:INFO:Memory: svmem(total=8361132032, available=584093696, percent=93.0, used=7777038336, free=584093696)
2024-04-29 21:27:43,651:INFO:Physical Core: 4
2024-04-29 21:27:43,651:INFO:Logical Core: 8
2024-04-29 21:27:43,651:INFO:Checking libraries
2024-04-29 21:27:43,651:INFO:System:
2024-04-29 21:27:43,651:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:27:43,651:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:27:43,651:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:27:43,651:INFO:PyCaret required dependencies:
2024-04-29 21:27:43,652:INFO:                 pip: 21.2.3
2024-04-29 21:27:43,653:INFO:          setuptools: 57.4.0
2024-04-29 21:27:43,653:INFO:             pycaret: 3.3.1
2024-04-29 21:27:43,653:INFO:             IPython: 8.23.0
2024-04-29 21:27:43,653:INFO:          ipywidgets: 8.1.2
2024-04-29 21:27:43,653:INFO:                tqdm: 4.66.2
2024-04-29 21:27:43,653:INFO:               numpy: 1.26.4
2024-04-29 21:27:43,653:INFO:              pandas: 2.1.4
2024-04-29 21:27:43,653:INFO:              jinja2: 3.1.3
2024-04-29 21:27:43,653:INFO:               scipy: 1.11.4
2024-04-29 21:27:43,653:INFO:              joblib: 1.3.2
2024-04-29 21:27:43,653:INFO:             sklearn: 1.4.2
2024-04-29 21:27:43,653:INFO:                pyod: 1.1.3
2024-04-29 21:27:43,654:INFO:            imblearn: 0.12.2
2024-04-29 21:27:43,654:INFO:   category_encoders: 2.6.3
2024-04-29 21:27:43,654:INFO:            lightgbm: 4.3.0
2024-04-29 21:27:43,654:INFO:               numba: 0.59.1
2024-04-29 21:27:43,654:INFO:            requests: 2.31.0
2024-04-29 21:27:43,654:INFO:          matplotlib: 3.7.5
2024-04-29 21:27:43,654:INFO:          scikitplot: 0.3.7
2024-04-29 21:27:43,654:INFO:         yellowbrick: 1.5
2024-04-29 21:27:43,655:INFO:              plotly: 5.21.0
2024-04-29 21:27:43,655:INFO:    plotly-resampler: Not installed
2024-04-29 21:27:43,655:INFO:             kaleido: 0.2.1
2024-04-29 21:27:43,655:INFO:           schemdraw: 0.15
2024-04-29 21:27:43,655:INFO:         statsmodels: 0.14.2
2024-04-29 21:27:43,655:INFO:              sktime: 0.26.0
2024-04-29 21:27:43,655:INFO:               tbats: 1.1.3
2024-04-29 21:27:43,655:INFO:            pmdarima: 2.0.4
2024-04-29 21:27:43,655:INFO:              psutil: 5.9.8
2024-04-29 21:27:43,655:INFO:          markupsafe: 2.1.5
2024-04-29 21:27:43,655:INFO:             pickle5: Not installed
2024-04-29 21:27:43,656:INFO:         cloudpickle: 3.0.0
2024-04-29 21:27:43,656:INFO:         deprecation: 2.1.0
2024-04-29 21:27:43,656:INFO:              xxhash: 3.4.1
2024-04-29 21:27:43,656:INFO:           wurlitzer: Not installed
2024-04-29 21:27:43,656:INFO:PyCaret optional dependencies:
2024-04-29 21:27:43,656:INFO:                shap: Not installed
2024-04-29 21:27:43,656:INFO:           interpret: Not installed
2024-04-29 21:27:43,656:INFO:                umap: Not installed
2024-04-29 21:27:43,657:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:27:43,657:INFO:  explainerdashboard: Not installed
2024-04-29 21:27:43,657:INFO:             autoviz: Not installed
2024-04-29 21:27:43,657:INFO:           fairlearn: Not installed
2024-04-29 21:27:43,657:INFO:          deepchecks: Not installed
2024-04-29 21:27:43,657:INFO:             xgboost: Not installed
2024-04-29 21:27:43,657:INFO:            catboost: Not installed
2024-04-29 21:27:43,657:INFO:              kmodes: Not installed
2024-04-29 21:27:43,658:INFO:             mlxtend: Not installed
2024-04-29 21:27:43,658:INFO:       statsforecast: Not installed
2024-04-29 21:27:43,658:INFO:        tune_sklearn: Not installed
2024-04-29 21:27:43,658:INFO:                 ray: Not installed
2024-04-29 21:27:43,658:INFO:            hyperopt: Not installed
2024-04-29 21:27:43,658:INFO:              optuna: Not installed
2024-04-29 21:27:43,658:INFO:               skopt: Not installed
2024-04-29 21:27:43,658:INFO:              mlflow: Not installed
2024-04-29 21:27:43,659:INFO:              gradio: Not installed
2024-04-29 21:27:43,659:INFO:             fastapi: Not installed
2024-04-29 21:27:43,659:INFO:             uvicorn: Not installed
2024-04-29 21:27:43,659:INFO:              m2cgen: Not installed
2024-04-29 21:27:43,659:INFO:           evidently: Not installed
2024-04-29 21:27:43,659:INFO:               fugue: Not installed
2024-04-29 21:27:43,659:INFO:           streamlit: 1.33.0
2024-04-29 21:27:43,659:INFO:             prophet: Not installed
2024-04-29 21:27:43,659:INFO:None
2024-04-29 21:27:43,660:INFO:Set up data.
2024-04-29 21:27:43,677:INFO:Set up folding strategy.
2024-04-29 21:27:43,677:INFO:Set up train/test split.
2024-04-29 21:27:43,693:INFO:Set up index.
2024-04-29 21:27:43,694:INFO:Assigning column types.
2024-04-29 21:27:43,705:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-29 21:27:43,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:27:43,819:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:43,885:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:43,885:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:43,982:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:27:43,983:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:44,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,038:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,039:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-29 21:27:44,114:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:44,160:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,160:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:44,298:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,299:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,300:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-29 21:27:44,442:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,443:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,583:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,583:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:44,585:INFO:Preparing preprocessing pipeline...
2024-04-29 21:27:44,585:INFO:Set up label encoding.
2024-04-29 21:27:44,585:INFO:Set up simple imputation.
2024-04-29 21:27:44,588:INFO:Set up encoding of ordinal features.
2024-04-29 21:27:44,590:INFO:Set up encoding of categorical features.
2024-04-29 21:27:44,813:INFO:Finished creating preprocessing pipeline.
2024-04-29 21:27:44,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Survived', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=Fa...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-29 21:27:44,860:INFO:Creating final display dataframe.
2024-04-29 21:27:45,664:INFO:Setup _display_container:                     Description             Value
0                    Session id              3896
1                        Target            Pclass
2                   Target type        Multiclass
3                Target mapping  1: 0, 2: 1, 3: 2
4           Original data shape         (891, 12)
5        Transformed data shape         (891, 14)
6   Transformed train set shape         (623, 14)
7    Transformed test set shape         (268, 14)
8              Numeric features                 6
9          Categorical features                 5
10     Rows with missing values             79.5%
11                   Preprocess              True
12              Imputation type            simple
13           Numeric imputation              mean
14       Categorical imputation              mode
15     Maximum one-hot encoding                25
16              Encoding method              None
17               Fold Generator   StratifiedKFold
18                  Fold Number                10
19                     CPU Jobs                -1
20                      Use GPU             False
21               Log Experiment             False
22              Experiment Name  clf-default-name
23                          USI              bbd7
2024-04-29 21:27:45,809:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:45,809:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:45,961:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:45,962:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:45,964:INFO:setup() successfully completed in 2.33s...............
2024-04-29 21:27:45,970:INFO:Initializing compare_models()
2024-04-29 21:27:45,970:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-29 21:27:45,970:INFO:Checking exceptions
2024-04-29 21:27:45,977:INFO:Preparing display monitor
2024-04-29 21:27:45,981:INFO:Initializing Logistic Regression
2024-04-29 21:27:45,981:INFO:Total runtime is 0.0 minutes
2024-04-29 21:27:45,982:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:45,982:INFO:Initializing create_model()
2024-04-29 21:27:45,982:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:45,982:INFO:Checking exceptions
2024-04-29 21:27:45,982:INFO:Importing libraries
2024-04-29 21:27:45,982:INFO:Copying training dataset
2024-04-29 21:27:46,001:INFO:Defining folds
2024-04-29 21:27:46,002:INFO:Declaring metric variables
2024-04-29 21:27:46,002:INFO:Importing untrained model
2024-04-29 21:27:46,002:INFO:Logistic Regression Imported successfully
2024-04-29 21:27:46,003:INFO:Starting cross validation
2024-04-29 21:27:46,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:46,810:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:46,814:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:46,873:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:46,891:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,001:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,006:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,014:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,020:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,024:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,026:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,026:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,028:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,028:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,028:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,034:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ttps://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,037:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,044:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,052:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,053:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,054:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,064:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,078:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,190:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,193:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,194:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,194:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,197:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,199:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,202:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,205:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,205:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,206:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,208:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,208:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,210:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,214:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,223:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,230:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,695:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,729:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:47,755:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,758:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,764:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,770:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,778:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:47,781:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,786:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,792:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:47,811:INFO:Calculating mean and std
2024-04-29 21:27:47,812:INFO:Creating metrics dataframe
2024-04-29 21:27:47,816:INFO:Uploading results into container
2024-04-29 21:27:47,816:INFO:Uploading model into container now
2024-04-29 21:27:47,818:INFO:_master_model_container: 1
2024-04-29 21:27:47,818:INFO:_display_container: 2
2024-04-29 21:27:47,818:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3896, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:27:47,818:INFO:create_model() successfully completed......................................
2024-04-29 21:27:48,015:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:48,015:INFO:Creating metrics dataframe
2024-04-29 21:27:48,019:INFO:Initializing K Neighbors Classifier
2024-04-29 21:27:48,020:INFO:Total runtime is 0.03397197326024373 minutes
2024-04-29 21:27:48,020:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:48,021:INFO:Initializing create_model()
2024-04-29 21:27:48,021:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:48,021:INFO:Checking exceptions
2024-04-29 21:27:48,022:INFO:Importing libraries
2024-04-29 21:27:48,022:INFO:Copying training dataset
2024-04-29 21:27:48,039:INFO:Defining folds
2024-04-29 21:27:48,039:INFO:Declaring metric variables
2024-04-29 21:27:48,040:INFO:Importing untrained model
2024-04-29 21:27:48,040:INFO:K Neighbors Classifier Imported successfully
2024-04-29 21:27:48,040:INFO:Starting cross validation
2024-04-29 21:27:48,043:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:48,724:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,728:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,733:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,733:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,741:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,753:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,758:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,766:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,770:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,775:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,779:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,780:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,784:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,787:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,788:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,788:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,796:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,805:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,809:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,811:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,816:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,825:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,830:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,834:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,839:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,847:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,859:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,869:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:48,874:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,885:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:48,893:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,105:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:49,107:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,112:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,115:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,271:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:49,274:INFO:PyCaret ClassificationExperiment
2024-04-29 21:27:49,275:INFO:Logging name: clf-default-name
2024-04-29 21:27:49,275:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:27:49,275:INFO:version 3.3.1
2024-04-29 21:27:49,275:INFO:Initializing setup()
2024-04-29 21:27:49,275:INFO:self.USI: 4df6
2024-04-29 21:27:49,276:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:27:49,276:INFO:Checking environment
2024-04-29 21:27:49,276:INFO:python_version: 3.10.0
2024-04-29 21:27:49,276:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:27:49,276:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,276:INFO:machine: AMD64
2024-04-29 21:27:49,276:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:27:49,283:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,283:INFO:Memory: svmem(total=8361132032, available=584220672, percent=93.0, used=7776911360, free=584220672)
2024-04-29 21:27:49,283:INFO:Physical Core: 4
2024-04-29 21:27:49,283:INFO:Logical Core: 8
2024-04-29 21:27:49,284:INFO:Checking libraries
2024-04-29 21:27:49,284:INFO:System:
2024-04-29 21:27:49,284:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:27:49,284:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:27:49,284:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:27:49,284:INFO:PyCaret required dependencies:
2024-04-29 21:27:49,285:INFO:                 pip: 21.2.3
2024-04-29 21:27:49,285:INFO:          setuptools: 57.4.0
2024-04-29 21:27:49,285:INFO:             pycaret: 3.3.1
2024-04-29 21:27:49,285:INFO:             IPython: 8.23.0
2024-04-29 21:27:49,285:INFO:          ipywidgets: 8.1.2
2024-04-29 21:27:49,285:INFO:                tqdm: 4.66.2
2024-04-29 21:27:49,285:INFO:               numpy: 1.26.4
2024-04-29 21:27:49,285:INFO:              pandas: 2.1.4
2024-04-29 21:27:49,285:INFO:              jinja2: 3.1.3
2024-04-29 21:27:49,285:INFO:               scipy: 1.11.4
2024-04-29 21:27:49,285:INFO:              joblib: 1.3.2
2024-04-29 21:27:49,285:INFO:             sklearn: 1.4.2
2024-04-29 21:27:49,285:INFO:                pyod: 1.1.3
2024-04-29 21:27:49,286:INFO:            imblearn: 0.12.2
2024-04-29 21:27:49,286:INFO:   category_encoders: 2.6.3
2024-04-29 21:27:49,286:INFO:            lightgbm: 4.3.0
2024-04-29 21:27:49,286:INFO:               numba: 0.59.1
2024-04-29 21:27:49,286:INFO:            requests: 2.31.0
2024-04-29 21:27:49,287:INFO:          matplotlib: 3.7.5
2024-04-29 21:27:49,287:INFO:          scikitplot: 0.3.7
2024-04-29 21:27:49,287:INFO:         yellowbrick: 1.5
2024-04-29 21:27:49,287:INFO:              plotly: 5.21.0
2024-04-29 21:27:49,287:INFO:    plotly-resampler: Not installed
2024-04-29 21:27:49,288:INFO:             kaleido: 0.2.1
2024-04-29 21:27:49,288:INFO:           schemdraw: 0.15
2024-04-29 21:27:49,288:INFO:         statsmodels: 0.14.2
2024-04-29 21:27:49,288:INFO:              sktime: 0.26.0
2024-04-29 21:27:49,288:INFO:               tbats: 1.1.3
2024-04-29 21:27:49,289:INFO:            pmdarima: 2.0.4
2024-04-29 21:27:49,289:INFO:              psutil: 5.9.8
2024-04-29 21:27:49,289:INFO:          markupsafe: 2.1.5
2024-04-29 21:27:49,289:INFO:             pickle5: Not installed
2024-04-29 21:27:49,289:INFO:         cloudpickle: 3.0.0
2024-04-29 21:27:49,290:INFO:         deprecation: 2.1.0
2024-04-29 21:27:49,290:INFO:              xxhash: 3.4.1
2024-04-29 21:27:49,290:INFO:           wurlitzer: Not installed
2024-04-29 21:27:49,290:INFO:PyCaret optional dependencies:
2024-04-29 21:27:49,291:INFO:                shap: Not installed
2024-04-29 21:27:49,291:INFO:           interpret: Not installed
2024-04-29 21:27:49,291:INFO:                umap: Not installed
2024-04-29 21:27:49,291:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:27:49,291:INFO:  explainerdashboard: Not installed
2024-04-29 21:27:49,292:INFO:             autoviz: Not installed
2024-04-29 21:27:49,292:INFO:           fairlearn: Not installed
2024-04-29 21:27:49,292:INFO:          deepchecks: Not installed
2024-04-29 21:27:49,292:INFO:             xgboost: Not installed
2024-04-29 21:27:49,292:INFO:            catboost: Not installed
2024-04-29 21:27:49,292:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:49,292:INFO:              kmodes: Not installed
2024-04-29 21:27:49,292:INFO:             mlxtend: Not installed
2024-04-29 21:27:49,292:INFO:       statsforecast: Not installed
2024-04-29 21:27:49,292:INFO:        tune_sklearn: Not installed
2024-04-29 21:27:49,292:INFO:                 ray: Not installed
2024-04-29 21:27:49,292:INFO:            hyperopt: Not installed
2024-04-29 21:27:49,292:INFO:              optuna: Not installed
2024-04-29 21:27:49,292:INFO:               skopt: Not installed
2024-04-29 21:27:49,292:INFO:              mlflow: Not installed
2024-04-29 21:27:49,292:INFO:              gradio: Not installed
2024-04-29 21:27:49,292:INFO:             fastapi: Not installed
2024-04-29 21:27:49,292:INFO:             uvicorn: Not installed
2024-04-29 21:27:49,292:INFO:              m2cgen: Not installed
2024-04-29 21:27:49,292:INFO:           evidently: Not installed
2024-04-29 21:27:49,292:INFO:               fugue: Not installed
2024-04-29 21:27:49,292:INFO:           streamlit: 1.33.0
2024-04-29 21:27:49,292:INFO:             prophet: Not installed
2024-04-29 21:27:49,294:INFO:None
2024-04-29 21:27:49,294:INFO:Set up data.
2024-04-29 21:27:49,315:INFO:Set up folding strategy.
2024-04-29 21:27:49,317:INFO:Set up train/test split.
2024-04-29 21:27:49,318:INFO:Calculating mean and std
2024-04-29 21:27:49,327:INFO:Creating metrics dataframe
2024-04-29 21:27:49,339:INFO:Uploading results into container
2024-04-29 21:27:49,342:INFO:Uploading model into container now
2024-04-29 21:27:49,342:INFO:_master_model_container: 2
2024-04-29 21:27:49,344:INFO:_display_container: 2
2024-04-29 21:27:49,345:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-29 21:27:49,345:INFO:create_model() successfully completed......................................
2024-04-29 21:27:49,540:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:49,545:INFO:Creating metrics dataframe
2024-04-29 21:27:49,553:INFO:Set up index.
2024-04-29 21:27:49,557:INFO:Initializing Naive Bayes
2024-04-29 21:27:49,557:INFO:Assigning column types.
2024-04-29 21:27:49,558:INFO:Total runtime is 0.05961410999298096 minutes
2024-04-29 21:27:49,564:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:49,564:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-29 21:27:49,564:INFO:Initializing create_model()
2024-04-29 21:27:49,577:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:49,592:INFO:Checking exceptions
2024-04-29 21:27:49,607:INFO:Importing libraries
2024-04-29 21:27:49,623:INFO:Copying training dataset
2024-04-29 21:27:49,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:27:49,655:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:49,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:49,701:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:49,789:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:27:49,794:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:49,834:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:49,835:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:49,836:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-29 21:27:49,886:INFO:Defining folds
2024-04-29 21:27:49,901:INFO:Declaring metric variables
2024-04-29 21:27:49,917:INFO:Importing untrained model
2024-04-29 21:27:49,920:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:49,921:INFO:Naive Bayes Imported successfully
2024-04-29 21:27:49,934:INFO:Starting cross validation
2024-04-29 21:27:49,951:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:49,966:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:49,967:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,037:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:27:50,078:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,079:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-29 21:27:50,275:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,286:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,417:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:50,435:INFO:Preparing preprocessing pipeline...
2024-04-29 21:27:50,455:INFO:Set up simple imputation.
2024-04-29 21:27:50,496:INFO:Set up encoding of ordinal features.
2024-04-29 21:27:50,501:INFO:Set up encoding of categorical features.
2024-04-29 21:27:50,789:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:50,792:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,798:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,799:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:50,803:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,804:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,813:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,814:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:50,816:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:50,819:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,819:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,825:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,833:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,847:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:50,853:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,878:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:50,886:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,016:INFO:Finished creating preprocessing pipeline.
et\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:51,144:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,144:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,144:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,145:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,146:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,146:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,152:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,152:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,152:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,153:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,156:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,158:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,159:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,159:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,161:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,162:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,162:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,164:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,168:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,188:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-29 21:27:51,188:INFO:Creating final display dataframe.
2024-04-29 21:27:51,291:INFO:Calculating mean and std
2024-04-29 21:27:51,294:INFO:Creating metrics dataframe
2024-04-29 21:27:51,297:INFO:Uploading results into container
2024-04-29 21:27:51,304:INFO:Uploading model into container now
2024-04-29 21:27:51,306:INFO:_master_model_container: 3
2024-04-29 21:27:51,306:INFO:_display_container: 2
2024-04-29 21:27:51,312:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-29 21:27:51,312:INFO:create_model() successfully completed......................................
2024-04-29 21:27:51,467:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:51,468:INFO:Creating metrics dataframe
2024-04-29 21:27:51,483:INFO:Initializing Decision Tree Classifier
2024-04-29 21:27:51,483:INFO:Total runtime is 0.09170526266098022 minutes
2024-04-29 21:27:51,483:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:51,484:INFO:Initializing create_model()
2024-04-29 21:27:51,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:51,484:INFO:Checking exceptions
2024-04-29 21:27:51,484:INFO:Importing libraries
2024-04-29 21:27:51,484:INFO:Copying training dataset
2024-04-29 21:27:51,500:INFO:Defining folds
2024-04-29 21:27:51,504:INFO:Declaring metric variables
2024-04-29 21:27:51,504:INFO:Importing untrained model
2024-04-29 21:27:51,505:INFO:Decision Tree Classifier Imported successfully
2024-04-29 21:27:51,506:INFO:Starting cross validation
2024-04-29 21:27:51,511:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:51,940:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:51,945:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,953:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:51,955:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:51,957:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,959:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,964:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,965:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,967:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,970:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,972:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,974:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,980:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:51,980:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:51,985:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,020:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,024:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,031:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,036:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,040:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,066:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,069:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,076:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,077:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,080:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,081:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,084:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,086:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,089:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,089:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,092:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,096:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,097:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,100:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,104:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,115:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,117:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,123:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,126:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,129:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,183:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py:287: UserWarning: Persisting input arguments took 0.51s to run.If this happens often in your code, it can cause performance problems (results will be correct in all cases). The reason for this is probably some large input arguments for a wrapped function.
  X, y = self._memory_full_transform(

2024-04-29 21:27:52,243:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,245:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,249:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,251:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,253:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,262:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:52,264:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,268:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,271:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:52,273:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:52,377:INFO:Calculating mean and std
2024-04-29 21:27:52,379:INFO:Creating metrics dataframe
2024-04-29 21:27:52,381:INFO:Uploading results into container
2024-04-29 21:27:52,382:INFO:Uploading model into container now
2024-04-29 21:27:52,383:INFO:_master_model_container: 4
2024-04-29 21:27:52,384:INFO:_display_container: 2
2024-04-29 21:27:52,386:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3896, splitter='best')
2024-04-29 21:27:52,387:INFO:create_model() successfully completed......................................
2024-04-29 21:27:52,536:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:52,547:INFO:Creating metrics dataframe
2024-04-29 21:27:52,580:INFO:Initializing SVM - Linear Kernel
2024-04-29 21:27:52,611:INFO:Total runtime is 0.1105000615119934 minutes
2024-04-29 21:27:52,642:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:52,642:INFO:Initializing create_model()
2024-04-29 21:27:52,642:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:52,642:INFO:Checking exceptions
2024-04-29 21:27:52,646:INFO:Importing libraries
2024-04-29 21:27:52,646:INFO:Copying training dataset
2024-04-29 21:27:52,665:INFO:Defining folds
2024-04-29 21:27:52,665:INFO:Declaring metric variables
2024-04-29 21:27:52,666:INFO:Importing untrained model
2024-04-29 21:27:52,667:INFO:SVM - Linear Kernel Imported successfully
2024-04-29 21:27:52,729:INFO:Starting cross validation
2024-04-29 21:27:52,733:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:52,812:INFO:Setup _display_container:                     Description             Value
0                    Session id               635
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              4df6
2024-04-29 21:27:52,826:INFO:                    Description             Value
2024-04-29 21:27:52,826:INFO:0                    Session id               635
2024-04-29 21:27:52,826:INFO:1                        Target          Survived
2024-04-29 21:27:52,826:INFO:2                   Target type            Binary
2024-04-29 21:27:52,827:INFO:3           Original data shape         (891, 12)
2024-04-29 21:27:52,829:INFO:4        Transformed data shape         (891, 14)
2024-04-29 21:27:52,831:INFO:5   Transformed train set shape         (623, 14)
2024-04-29 21:27:52,831:INFO:6    Transformed test set shape         (268, 14)
2024-04-29 21:27:52,831:INFO:7              Numeric features                 6
2024-04-29 21:27:52,831:INFO:8          Categorical features                 5
2024-04-29 21:27:52,832:INFO:9      Rows with missing values             79.5%
2024-04-29 21:27:52,832:INFO:10                   Preprocess              True
2024-04-29 21:27:52,832:INFO:11              Imputation type            simple
2024-04-29 21:27:52,832:INFO:12           Numeric imputation              mean
2024-04-29 21:27:52,832:INFO:13       Categorical imputation              mode
2024-04-29 21:27:52,832:INFO:14     Maximum one-hot encoding                25
2024-04-29 21:27:52,832:INFO:15              Encoding method              None
2024-04-29 21:27:52,832:INFO:16               Fold Generator   StratifiedKFold
2024-04-29 21:27:52,832:INFO:17                  Fold Number                10
2024-04-29 21:27:52,832:INFO:18                     CPU Jobs                -1
2024-04-29 21:27:52,832:INFO:19                      Use GPU             False
2024-04-29 21:27:52,832:INFO:20               Log Experiment             False
2024-04-29 21:27:52,832:INFO:21              Experiment Name  clf-default-name
2024-04-29 21:27:52,832:INFO:22                          USI              4df6
2024-04-29 21:27:52,965:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:52,965:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:53,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:53,113:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:27:53,134:INFO:setup() successfully completed in 3.87s...............
2024-04-29 21:27:53,275:INFO:Initializing compare_models()
2024-04-29 21:27:53,275:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-29 21:27:53,276:INFO:Checking exceptions
2024-04-29 21:27:53,285:INFO:Preparing display monitor
2024-04-29 21:27:53,290:WARNING:
2024-04-29 21:27:53,291:WARNING:Processing:   0%|                                                                                                  | 0/61 [00:00<?, ?it/s]
2024-04-29 21:27:53,291:WARNING:[A
2024-04-29 21:27:53,292:INFO:Initializing Logistic Regression
2024-04-29 21:27:53,292:INFO:Total runtime is 8.18173090616862e-06 minutes
2024-04-29 21:27:53,293:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:53,293:INFO:Initializing create_model()
2024-04-29 21:27:53,293:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:53,293:INFO:Checking exceptions
2024-04-29 21:27:53,293:INFO:Importing libraries
2024-04-29 21:27:53,293:INFO:Copying training dataset
2024-04-29 21:27:53,331:INFO:Defining folds
2024-04-29 21:27:53,331:INFO:Declaring metric variables
2024-04-29 21:27:53,332:INFO:Importing untrained model
2024-04-29 21:27:53,333:INFO:Logistic Regression Imported successfully
2024-04-29 21:27:53,334:INFO:Starting cross validation
2024-04-29 21:27:53,338:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:53,583:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,588:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,590:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,595:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,597:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,600:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:53,601:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,603:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,604:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:53,607:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,612:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,616:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,629:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,632:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,633:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,636:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,636:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,638:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,639:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:53,645:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,645:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,645:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,648:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:53,651:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,665:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,668:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,675:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,678:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:53,682:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,767:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,772:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,778:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,785:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,810:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:53,814:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,824:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:53,832:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,033:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:54,039:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,045:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,052:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,173:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,211:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:54,214:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,220:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,222:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:54,225:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:54,247:INFO:Calculating mean and std
2024-04-29 21:27:54,283:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,296:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,304:INFO:Creating metrics dataframe
2024-04-29 21:27:54,317:INFO:Uploading results into container
2024-04-29 21:27:54,319:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,319:INFO:Uploading model into container now
2024-04-29 21:27:54,321:INFO:_master_model_container: 5
2024-04-29 21:27:54,321:INFO:_display_container: 2
2024-04-29 21:27:54,324:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3896, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-29 21:27:54,324:INFO:create_model() successfully completed......................................
2024-04-29 21:27:54,343:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,348:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,604:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:54,604:INFO:Creating metrics dataframe
2024-04-29 21:27:54,610:INFO:Initializing Ridge Classifier
2024-04-29 21:27:54,611:INFO:Total runtime is 0.14383645852406818 minutes
2024-04-29 21:27:54,612:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:54,612:INFO:Initializing create_model()
2024-04-29 21:27:54,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:54,613:INFO:Checking exceptions
2024-04-29 21:27:54,613:INFO:Importing libraries
2024-04-29 21:27:54,614:INFO:Copying training dataset
2024-04-29 21:27:54,626:INFO:Defining folds
2024-04-29 21:27:54,626:INFO:Declaring metric variables
2024-04-29 21:27:54,627:INFO:Importing untrained model
2024-04-29 21:27:54,627:INFO:Ridge Classifier Imported successfully
2024-04-29 21:27:54,627:INFO:Starting cross validation
2024-04-29 21:27:54,631:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:54,821:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,844:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,847:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:54,974:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:27:55,026:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,030:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,038:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,044:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

ead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,046:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,054:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,060:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,063:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,065:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,070:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,072:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,073:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,079:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,085:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,093:INFO:Calculating mean and std
2024-04-29 21:27:55,094:WARNING:
2024-04-29 21:27:55,094:WARNING:Processing:   8%|#######3                                                                                  | 5/61 [00:01<00:20,  2.78it/s]
2024-04-29 21:27:55,095:WARNING:[A
2024-04-29 21:27:55,095:INFO:Creating metrics dataframe
2024-04-29 21:27:55,101:INFO:Uploading results into container
2024-04-29 21:27:55,102:INFO:Uploading model into container now
2024-04-29 21:27:55,103:INFO:_master_model_container: 1
2024-04-29 21:27:55,104:INFO:_display_container: 2
2024-04-29 21:27:55,105:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=635, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:27:55,105:INFO:create_model() successfully completed......................................
2024-04-29 21:27:55,292:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,296:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,305:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,311:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,337:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,342:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,349:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,355:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,355:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:55,357:INFO:Creating metrics dataframe
2024-04-29 21:27:55,365:INFO:Initializing K Neighbors Classifier
2024-04-29 21:27:55,366:INFO:Total runtime is 0.0345721443494161 minutes
2024-04-29 21:27:55,367:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:55,368:INFO:Initializing create_model()
2024-04-29 21:27:55,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:55,368:INFO:Checking exceptions
2024-04-29 21:27:55,369:INFO:Importing libraries
2024-04-29 21:27:55,369:INFO:Copying training dataset
2024-04-29 21:27:55,377:WARNING:
2024-04-29 21:27:55,378:WARNING:Processing:  11%|##########3                                                                               | 7/61 [00:02<00:15,  3.56it/s]
2024-04-29 21:27:55,378:WARNING:[A
2024-04-29 21:27:55,378:INFO:Defining folds
2024-04-29 21:27:55,379:INFO:Declaring metric variables
2024-04-29 21:27:55,379:INFO:Importing untrained model
2024-04-29 21:27:55,380:INFO:K Neighbors Classifier Imported successfully
2024-04-29 21:27:55,380:INFO:Starting cross validation
2024-04-29 21:27:55,383:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:55,388:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,392:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,401:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,410:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,414:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,418:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,426:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,437:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,450:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,453:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,459:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,483:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,551:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:55,556:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,563:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,571:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:55,589:INFO:Calculating mean and std
2024-04-29 21:27:55,594:INFO:Creating metrics dataframe
2024-04-29 21:27:55,599:INFO:Uploading results into container
2024-04-29 21:27:55,600:INFO:Uploading model into container now
2024-04-29 21:27:55,602:INFO:_master_model_container: 6
2024-04-29 21:27:55,602:INFO:_display_container: 2
2024-04-29 21:27:55,603:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3896, solver='auto',
                tol=0.0001)
2024-04-29 21:27:55,603:INFO:create_model() successfully completed......................................
2024-04-29 21:27:56,014:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:56,015:INFO:Creating metrics dataframe
2024-04-29 21:27:56,023:INFO:Initializing Random Forest Classifier
2024-04-29 21:27:56,023:INFO:Total runtime is 0.16737043062845863 minutes
2024-04-29 21:27:56,024:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:56,024:INFO:Initializing create_model()
2024-04-29 21:27:56,025:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:56,025:INFO:Checking exceptions
2024-04-29 21:27:56,025:INFO:Importing libraries
2024-04-29 21:27:56,025:INFO:Copying training dataset
2024-04-29 21:27:56,044:INFO:Defining folds
2024-04-29 21:27:56,044:INFO:Declaring metric variables
2024-04-29 21:27:56,044:INFO:Importing untrained model
2024-04-29 21:27:56,046:INFO:Random Forest Classifier Imported successfully
2024-04-29 21:27:56,047:INFO:Starting cross validation
2024-04-29 21:27:56,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:56,088:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,088:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,100:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,105:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,113:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,113:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,200:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,228:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,701:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,811:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:56,897:INFO:Calculating mean and std
2024-04-29 21:27:56,898:WARNING:
2024-04-29 21:27:56,899:WARNING:Processing:  15%|#############2                                                                            | 9/61 [00:03<00:23,  2.25it/s]
2024-04-29 21:27:56,899:WARNING:[A
2024-04-29 21:27:56,899:INFO:Creating metrics dataframe
2024-04-29 21:27:56,906:INFO:Uploading results into container
2024-04-29 21:27:56,906:INFO:Uploading model into container now
2024-04-29 21:27:56,908:INFO:_master_model_container: 2
2024-04-29 21:27:56,909:INFO:_display_container: 2
2024-04-29 21:27:56,909:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-29 21:27:56,910:INFO:create_model() successfully completed......................................
2024-04-29 21:27:57,300:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,301:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,306:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,308:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,315:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,316:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,320:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,323:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:57,325:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,326:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,328:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:57,338:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,344:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,354:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,329:INFO:Creating metrics dataframe
2024-04-29 21:27:57,375:INFO:Initializing Naive Bayes
2024-04-29 21:27:57,376:INFO:Total runtime is 0.0680772304534912 minutes
2024-04-29 21:27:57,377:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:57,380:INFO:Initializing create_model()
2024-04-29 21:27:57,381:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:57,381:INFO:Checking exceptions
2024-04-29 21:27:57,382:INFO:Importing libraries
2024-04-29 21:27:57,382:INFO:Copying training dataset
2024-04-29 21:27:57,403:WARNING:
2024-04-29 21:27:57,404:WARNING:Processing:  18%|################                                                                         | 11/61 [00:04<00:19,  2.62it/s]
2024-04-29 21:27:57,404:WARNING:[A
2024-04-29 21:27:57,405:INFO:Defining folds
2024-04-29 21:27:57,405:INFO:Declaring metric variables
2024-04-29 21:27:57,405:INFO:Importing untrained model
2024-04-29 21:27:57,406:INFO:Naive Bayes Imported successfully
2024-04-29 21:27:57,407:INFO:Starting cross validation
2024-04-29 21:27:57,412:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:57,469:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,473:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,483:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,498:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,635:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,639:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,647:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,652:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:57,656:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,662:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,662:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:57,676:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,125:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,214:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,229:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:58,233:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,240:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,244:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:58,248:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,249:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,262:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,274:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,371:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,405:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,503:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:58,505:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:27:58,508:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,508:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,519:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,522:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:58,526:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,528:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:58,557:INFO:Calculating mean and std
2024-04-29 21:27:58,562:INFO:Creating metrics dataframe
2024-04-29 21:27:58,567:INFO:Uploading results into container
2024-04-29 21:27:58,569:INFO:Uploading model into container now
2024-04-29 21:27:58,571:INFO:_master_model_container: 7
2024-04-29 21:27:58,572:INFO:_display_container: 2
2024-04-29 21:27:58,574:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3896, verbose=0,
                       warm_start=False)
2024-04-29 21:27:58,574:INFO:create_model() successfully completed......................................
2024-04-29 21:27:58,695:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,742:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,745:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,781:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,812:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:58,813:INFO:Creating metrics dataframe
2024-04-29 21:27:58,824:INFO:Initializing Quadratic Discriminant Analysis
2024-04-29 21:27:58,824:INFO:Total runtime is 0.21405210494995114 minutes
2024-04-29 21:27:58,825:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:58,826:INFO:Initializing create_model()
2024-04-29 21:27:58,827:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:58,827:INFO:Checking exceptions
2024-04-29 21:27:58,827:INFO:Importing libraries
2024-04-29 21:27:58,828:INFO:Copying training dataset
2024-04-29 21:27:58,850:INFO:Defining folds
2024-04-29 21:27:58,850:INFO:Declaring metric variables
2024-04-29 21:27:58,851:INFO:Importing untrained model
2024-04-29 21:27:58,852:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-29 21:27:58,852:INFO:Starting cross validation
2024-04-29 21:27:58,855:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:58,859:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,901:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:27:58,979:INFO:Calculating mean and std
2024-04-29 21:27:58,981:WARNING:
2024-04-29 21:27:58,981:WARNING:Processing:  21%|##################9                                                                      | 13/61 [00:05<00:24,  1.95it/s]
2024-04-29 21:27:58,982:WARNING:[A
2024-04-29 21:27:58,982:INFO:Creating metrics dataframe
2024-04-29 21:27:58,988:INFO:Uploading results into container
2024-04-29 21:27:58,989:INFO:Uploading model into container now
2024-04-29 21:27:58,990:INFO:_master_model_container: 3
2024-04-29 21:27:58,990:INFO:_display_container: 2
2024-04-29 21:27:58,991:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-29 21:27:58,991:INFO:create_model() successfully completed......................................
2024-04-29 21:27:59,199:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,241:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,257:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,287:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,339:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,344:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,354:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,359:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,360:INFO:SubProcess create_model() end ==================================
2024-04-29 21:27:59,361:INFO:Creating metrics dataframe
2024-04-29 21:27:59,363:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,367:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,369:INFO:Initializing Decision Tree Classifier
2024-04-29 21:27:59,369:INFO:Total runtime is 0.101294207572937 minutes
2024-04-29 21:27:59,370:INFO:SubProcess create_model() called ==================================
2024-04-29 21:27:59,371:INFO:Initializing create_model()
2024-04-29 21:27:59,371:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:27:59,371:INFO:Checking exceptions
2024-04-29 21:27:59,371:INFO:Importing libraries
2024-04-29 21:27:59,371:INFO:Copying training dataset
2024-04-29 21:27:59,372:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,382:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,385:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,389:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,393:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,393:WARNING:
2024-04-29 21:27:59,394:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,394:WARNING:Processing:  25%|#####################8                                                                   | 15/61 [00:06<00:19,  2.40it/s]
2024-04-29 21:27:59,395:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,395:WARNING:[A
2024-04-29 21:27:59,395:INFO:Defining folds
2024-04-29 21:27:59,395:INFO:Declaring metric variables
2024-04-29 21:27:59,396:INFO:Importing untrained model
2024-04-29 21:27:59,397:INFO:Decision Tree Classifier Imported successfully
2024-04-29 21:27:59,398:INFO:Starting cross validation
2024-04-29 21:27:59,398:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,404:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,407:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,423:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,427:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:27:59,427:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,431:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,431:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,440:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,443:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,448:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,451:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,532:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,553:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,554:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,557:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,560:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,563:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,564:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,565:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,567:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,569:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,569:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,572:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,572:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,573:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,590:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,593:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,610:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,613:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,614:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,623:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,660:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:27:59,762:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,768:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,781:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,786:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,790:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,829:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:27:59,835:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,844:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,848:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:27:59,854:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:27:59,885:INFO:Calculating mean and std
2024-04-29 21:27:59,926:INFO:Creating metrics dataframe
2024-04-29 21:27:59,936:INFO:Uploading results into container
2024-04-29 21:27:59,937:INFO:Uploading model into container now
2024-04-29 21:27:59,938:INFO:_master_model_container: 8
2024-04-29 21:27:59,939:INFO:_display_container: 2
2024-04-29 21:27:59,943:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-29 21:27:59,944:INFO:create_model() successfully completed......................................
2024-04-29 21:27:59,992:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,010:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,011:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,032:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,043:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,059:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,121:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,142:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,143:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,153:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,164:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,173:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,264:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:00,265:INFO:Creating metrics dataframe
2024-04-29 21:28:00,276:INFO:Initializing Ada Boost Classifier
2024-04-29 21:28:00,276:INFO:Total runtime is 0.23824465672175085 minutes
2024-04-29 21:28:00,277:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:00,278:INFO:Initializing create_model()
2024-04-29 21:28:00,278:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:00,278:INFO:Checking exceptions
2024-04-29 21:28:00,279:INFO:Importing libraries
2024-04-29 21:28:00,280:INFO:Copying training dataset
2024-04-29 21:28:00,303:INFO:Defining folds
2024-04-29 21:28:00,303:INFO:Declaring metric variables
2024-04-29 21:28:00,304:INFO:Importing untrained model
2024-04-29 21:28:00,305:INFO:Ada Boost Classifier Imported successfully
2024-04-29 21:28:00,306:INFO:Starting cross validation
2024-04-29 21:28:00,310:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:00,340:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,353:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,405:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,423:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,497:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,516:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,650:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,658:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,662:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,682:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,693:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:00,698:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,711:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:00,739:INFO:Calculating mean and std
2024-04-29 21:28:00,740:WARNING:
2024-04-29 21:28:00,741:WARNING:Processing:  28%|########################8                                                                | 17/61 [00:07<00:21,  2.02it/s]
2024-04-29 21:28:00,741:WARNING:[A
2024-04-29 21:28:00,742:INFO:Creating metrics dataframe
2024-04-29 21:28:00,747:INFO:Uploading results into container
2024-04-29 21:28:00,749:INFO:Uploading model into container now
2024-04-29 21:28:00,750:INFO:_master_model_container: 4
2024-04-29 21:28:00,750:INFO:_display_container: 2
2024-04-29 21:28:00,751:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=635, splitter='best')
2024-04-29 21:28:00,751:INFO:create_model() successfully completed......................................
2024-04-29 21:28:00,757:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:00,823:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:01,000:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:01,055:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:01,055:INFO:Creating metrics dataframe
2024-04-29 21:28:01,063:INFO:Initializing SVM - Linear Kernel
2024-04-29 21:28:01,063:INFO:Total runtime is 0.1295133670171102 minutes
2024-04-29 21:28:01,063:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:01,063:INFO:Initializing create_model()
2024-04-29 21:28:01,064:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:01,064:INFO:Checking exceptions
2024-04-29 21:28:01,064:INFO:Importing libraries
2024-04-29 21:28:01,064:INFO:Copying training dataset
2024-04-29 21:28:01,077:WARNING:
2024-04-29 21:28:01,077:WARNING:Processing:  31%|###########################7                                                             | 19/61 [00:07<00:16,  2.53it/s]
2024-04-29 21:28:01,083:WARNING:[A
2024-04-29 21:28:01,083:INFO:Defining folds
2024-04-29 21:28:01,083:INFO:Declaring metric variables
2024-04-29 21:28:01,083:INFO:Importing untrained model
2024-04-29 21:28:01,085:INFO:SVM - Linear Kernel Imported successfully
2024-04-29 21:28:01,086:INFO:Starting cross validation
2024-04-29 21:28:01,090:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:01,225:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,229:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,241:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,245:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,250:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,258:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,261:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,263:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,265:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,274:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,275:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,278:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,282:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,284:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,295:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,301:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,312:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,318:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,325:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,325:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,329:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,342:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,356:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,360:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,400:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,403:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,412:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,417:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,422:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,453:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,457:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,466:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,469:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,474:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,506:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:01,514:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,520:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,528:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:01,533:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:01,573:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:01,650:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:01,773:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:02,103:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:02,110:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,120:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,124:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:02,126:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,167:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:02,169:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,175:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,178:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:02,183:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:02,201:INFO:Calculating mean and std
2024-04-29 21:28:02,203:INFO:Creating metrics dataframe
2024-04-29 21:28:02,205:INFO:Uploading results into container
2024-04-29 21:28:02,207:INFO:Uploading model into container now
2024-04-29 21:28:02,208:INFO:_master_model_container: 9
2024-04-29 21:28:02,208:INFO:_display_container: 2
2024-04-29 21:28:02,210:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3896)
2024-04-29 21:28:02,210:INFO:create_model() successfully completed......................................
2024-04-29 21:28:02,401:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:02,402:INFO:Creating metrics dataframe
2024-04-29 21:28:02,410:INFO:Initializing Gradient Boosting Classifier
2024-04-29 21:28:02,412:INFO:Total runtime is 0.2738522092501322 minutes
2024-04-29 21:28:02,412:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:02,413:INFO:Initializing create_model()
2024-04-29 21:28:02,413:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:02,413:INFO:Checking exceptions
2024-04-29 21:28:02,413:INFO:Importing libraries
2024-04-29 21:28:02,413:INFO:Copying training dataset
2024-04-29 21:28:02,431:INFO:Defining folds
2024-04-29 21:28:02,433:INFO:Calculating mean and std
2024-04-29 21:28:02,433:INFO:Declaring metric variables
2024-04-29 21:28:02,434:WARNING:
2024-04-29 21:28:02,434:INFO:Importing untrained model
2024-04-29 21:28:02,435:WARNING:Processing:  34%|##############################6                                                          | 21/61 [00:09<00:19,  2.08it/s]
2024-04-29 21:28:02,436:INFO:Gradient Boosting Classifier Imported successfully
2024-04-29 21:28:02,436:WARNING:[A
2024-04-29 21:28:02,437:INFO:Starting cross validation
2024-04-29 21:28:02,437:INFO:Creating metrics dataframe
2024-04-29 21:28:02,441:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:02,449:INFO:Uploading results into container
2024-04-29 21:28:02,457:INFO:Uploading model into container now
2024-04-29 21:28:02,458:INFO:_master_model_container: 5
2024-04-29 21:28:02,458:INFO:_display_container: 2
2024-04-29 21:28:02,460:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=635, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-29 21:28:02,460:INFO:create_model() successfully completed......................................
2024-04-29 21:28:02,609:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:02,609:INFO:Creating metrics dataframe
2024-04-29 21:28:02,615:INFO:Initializing Ridge Classifier
2024-04-29 21:28:02,616:INFO:Total runtime is 0.15540322462717693 minutes
2024-04-29 21:28:02,616:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:02,618:INFO:Initializing create_model()
2024-04-29 21:28:02,618:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:02,619:INFO:Checking exceptions
2024-04-29 21:28:02,621:INFO:Importing libraries
2024-04-29 21:28:02,621:INFO:Copying training dataset
2024-04-29 21:28:02,663:WARNING:
2024-04-29 21:28:02,667:WARNING:Processing:  38%|#################################5                                                       | 23/61 [00:09<00:14,  2.70it/s]
2024-04-29 21:28:02,667:WARNING:[A
2024-04-29 21:28:02,667:INFO:Defining folds
2024-04-29 21:28:02,667:INFO:Declaring metric variables
2024-04-29 21:28:02,667:INFO:Importing untrained model
2024-04-29 21:28:02,668:INFO:Ridge Classifier Imported successfully
2024-04-29 21:28:02,668:INFO:Starting cross validation
2024-04-29 21:28:02,671:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:04,085:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,089:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,091:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,093:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,099:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,102:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,102:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,087:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,103:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,105:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,107:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,108:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,111:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,112:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,117:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,120:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,123:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,124:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,126:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,135:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,137:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,140:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,143:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,147:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,151:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,157:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:04,161:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,179:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:04,183:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,193:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:04,200:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:04,205:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,093:INFO:Calculating mean and std
2024-04-29 21:28:05,095:WARNING:
2024-04-29 21:28:05,096:WARNING:Processing:  41%|####################################4                                                    | 25/61 [00:11<00:22,  1.60it/s]
2024-04-29 21:28:05,096:WARNING:[A
2024-04-29 21:28:05,096:INFO:Creating metrics dataframe
2024-04-29 21:28:05,098:INFO:Uploading results into container
2024-04-29 21:28:05,099:INFO:Uploading model into container now
2024-04-29 21:28:05,100:INFO:_master_model_container: 6
2024-04-29 21:28:05,100:INFO:_display_container: 2
2024-04-29 21:28:05,101:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=635, solver='auto',
                tol=0.0001)
2024-04-29 21:28:05,101:INFO:create_model() successfully completed......................................
2024-04-29 21:28:05,286:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:05,287:INFO:Creating metrics dataframe
2024-04-29 21:28:05,296:INFO:Initializing Random Forest Classifier
2024-04-29 21:28:05,296:INFO:Total runtime is 0.20007376670837404 minutes
2024-04-29 21:28:05,297:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:05,298:INFO:Initializing create_model()
2024-04-29 21:28:05,298:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:05,299:INFO:Checking exceptions
2024-04-29 21:28:05,299:INFO:Importing libraries
2024-04-29 21:28:05,299:INFO:Copying training dataset
2024-04-29 21:28:05,317:WARNING:
2024-04-29 21:28:05,317:WARNING:Processing:  44%|#######################################3                                                 | 27/61 [00:12<00:15,  2.13it/s]
2024-04-29 21:28:05,318:WARNING:[A
2024-04-29 21:28:05,318:INFO:Defining folds
2024-04-29 21:28:05,319:INFO:Declaring metric variables
2024-04-29 21:28:05,319:INFO:Importing untrained model
2024-04-29 21:28:05,320:INFO:Random Forest Classifier Imported successfully
2024-04-29 21:28:05,321:INFO:Starting cross validation
2024-04-29 21:28:05,326:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:05,476:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:05,480:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,489:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,497:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,581:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:05,584:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,594:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,605:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:05,633:INFO:Calculating mean and std
2024-04-29 21:28:05,640:INFO:Creating metrics dataframe
2024-04-29 21:28:05,651:INFO:Uploading results into container
2024-04-29 21:28:05,653:INFO:Uploading model into container now
2024-04-29 21:28:05,654:INFO:_master_model_container: 10
2024-04-29 21:28:05,655:INFO:_display_container: 2
2024-04-29 21:28:05,656:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3896, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-29 21:28:05,657:INFO:create_model() successfully completed......................................
2024-04-29 21:28:06,193:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:06,194:INFO:Creating metrics dataframe
2024-04-29 21:28:06,200:INFO:Initializing Linear Discriminant Analysis
2024-04-29 21:28:06,200:INFO:Total runtime is 0.33699280023574824 minutes
2024-04-29 21:28:06,201:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:06,203:INFO:Initializing create_model()
2024-04-29 21:28:06,203:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:06,203:INFO:Checking exceptions
2024-04-29 21:28:06,203:INFO:Importing libraries
2024-04-29 21:28:06,203:INFO:Copying training dataset
2024-04-29 21:28:06,234:INFO:Defining folds
2024-04-29 21:28:06,234:INFO:Declaring metric variables
2024-04-29 21:28:06,235:INFO:Importing untrained model
2024-04-29 21:28:06,236:INFO:Linear Discriminant Analysis Imported successfully
2024-04-29 21:28:06,237:INFO:Starting cross validation
2024-04-29 21:28:06,241:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:06,320:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,321:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,321:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,337:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,345:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,351:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,381:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,419:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,841:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:06,843:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:06,846:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,855:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,861:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,861:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:06,864:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,866:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,866:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,870:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,873:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,876:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,903:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:06,914:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,931:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,934:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:06,941:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,984:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:06,989:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:06,998:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:07,003:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,008:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,015:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,423:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,432:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,441:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,444:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,450:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,456:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:07,464:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:07,471:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,473:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,476:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,476:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,481:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,484:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,485:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,489:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,490:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,495:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,504:INFO:Calculating mean and std
2024-04-29 21:28:07,506:WARNING:
2024-04-29 21:28:07,506:WARNING:Processing:  48%|##########################################3                                              | 29/61 [00:14<00:21,  1.52it/s]
2024-04-29 21:28:07,507:WARNING:[A
2024-04-29 21:28:07,507:INFO:Creating metrics dataframe
2024-04-29 21:28:07,509:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,512:INFO:Uploading results into container
2024-04-29 21:28:07,514:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,514:INFO:Uploading model into container now
2024-04-29 21:28:07,516:INFO:_master_model_container: 7
2024-04-29 21:28:07,517:INFO:_display_container: 2
2024-04-29 21:28:07,520:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=635, verbose=0,
                       warm_start=False)
2024-04-29 21:28:07,520:INFO:create_model() successfully completed......................................
2024-04-29 21:28:07,523:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,526:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,532:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,566:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,574:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,586:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,593:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,601:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,602:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 136, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2024-04-29 21:28:07,608:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,620:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,624:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:07,629:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:07,703:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:07,703:INFO:Creating metrics dataframe
2024-04-29 21:28:07,708:INFO:Initializing Quadratic Discriminant Analysis
2024-04-29 21:28:07,709:INFO:Total runtime is 0.2402888615926107 minutes
2024-04-29 21:28:07,709:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:07,711:INFO:Initializing create_model()
2024-04-29 21:28:07,711:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:07,711:INFO:Checking exceptions
2024-04-29 21:28:07,711:INFO:Importing libraries
2024-04-29 21:28:07,711:INFO:Copying training dataset
2024-04-29 21:28:07,720:WARNING:
2024-04-29 21:28:07,720:WARNING:Processing:  51%|#############################################2                                           | 31/61 [00:14<00:14,  2.03it/s]
2024-04-29 21:28:07,720:WARNING:[A
2024-04-29 21:28:07,720:INFO:Defining folds
2024-04-29 21:28:07,721:INFO:Declaring metric variables
2024-04-29 21:28:07,721:INFO:Importing untrained model
2024-04-29 21:28:07,721:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-29 21:28:07,723:INFO:Starting cross validation
2024-04-29 21:28:07,728:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:07,742:INFO:Calculating mean and std
2024-04-29 21:28:07,750:INFO:Creating metrics dataframe
2024-04-29 21:28:07,758:INFO:Uploading results into container
2024-04-29 21:28:07,763:INFO:Uploading model into container now
2024-04-29 21:28:07,768:INFO:_master_model_container: 11
2024-04-29 21:28:07,769:INFO:_display_container: 2
2024-04-29 21:28:07,771:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-29 21:28:07,772:INFO:create_model() successfully completed......................................
2024-04-29 21:28:07,927:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:07,927:INFO:Creating metrics dataframe
2024-04-29 21:28:07,934:INFO:Initializing Extra Trees Classifier
2024-04-29 21:28:07,936:INFO:Total runtime is 0.36591049432754513 minutes
2024-04-29 21:28:07,937:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:07,941:INFO:Initializing create_model()
2024-04-29 21:28:07,941:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:07,943:INFO:Checking exceptions
2024-04-29 21:28:07,943:INFO:Importing libraries
2024-04-29 21:28:07,943:INFO:Copying training dataset
2024-04-29 21:28:08,048:INFO:Defining folds
2024-04-29 21:28:08,049:INFO:Declaring metric variables
2024-04-29 21:28:08,049:INFO:Importing untrained model
2024-04-29 21:28:08,051:INFO:Extra Trees Classifier Imported successfully
2024-04-29 21:28:08,052:INFO:Starting cross validation
2024-04-29 21:28:08,056:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:08,278:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,280:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,319:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,341:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,357:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,380:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,395:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,396:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,433:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,512:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,515:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,532:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,573:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,585:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,647:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,786:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,798:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:28:08,968:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:08,994:INFO:Calculating mean and std
2024-04-29 21:28:08,995:WARNING:
2024-04-29 21:28:08,995:WARNING:Processing:  54%|################################################1                                        | 33/61 [00:15<00:15,  1.87it/s]
2024-04-29 21:28:08,995:WARNING:[A
2024-04-29 21:28:08,996:INFO:Creating metrics dataframe
2024-04-29 21:28:09,001:INFO:Uploading results into container
2024-04-29 21:28:09,002:INFO:Uploading model into container now
2024-04-29 21:28:09,003:INFO:_master_model_container: 8
2024-04-29 21:28:09,003:INFO:_display_container: 2
2024-04-29 21:28:09,004:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-29 21:28:09,004:INFO:create_model() successfully completed......................................
2024-04-29 21:28:09,456:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:09,457:INFO:Creating metrics dataframe
2024-04-29 21:28:09,467:INFO:Initializing Ada Boost Classifier
2024-04-29 21:28:09,467:INFO:Total runtime is 0.26959350109100344 minutes
2024-04-29 21:28:09,468:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:09,469:INFO:Initializing create_model()
2024-04-29 21:28:09,469:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:09,470:INFO:Checking exceptions
2024-04-29 21:28:09,470:INFO:Importing libraries
2024-04-29 21:28:09,470:INFO:Copying training dataset
2024-04-29 21:28:09,492:WARNING:
2024-04-29 21:28:09,494:WARNING:Processing:  57%|###################################################                                      | 35/61 [00:16<00:11,  2.22it/s]
2024-04-29 21:28:09,494:WARNING:[A
2024-04-29 21:28:09,495:INFO:Defining folds
2024-04-29 21:28:09,495:INFO:Declaring metric variables
2024-04-29 21:28:09,496:INFO:Importing untrained model
2024-04-29 21:28:09,497:INFO:Ada Boost Classifier Imported successfully
2024-04-29 21:28:09,498:INFO:Starting cross validation
2024-04-29 21:28:09,502:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:09,672:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,672:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,677:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,677:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,688:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,688:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,703:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,707:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,716:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,719:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,721:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,724:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,751:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,756:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,764:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,778:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,909:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,914:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,922:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,939:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:09,943:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,958:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:09,979:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,011:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,387:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:10,440:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:10,446:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,452:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,455:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:10,460:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,554:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:10,553:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:10,593:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:10,597:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,603:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,611:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:10,697:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:10,758:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:10,835:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:10,871:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:10,939:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,034:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:11,038:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,046:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:11,047:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,052:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,056:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,063:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,067:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,084:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:11,113:INFO:Calculating mean and std
2024-04-29 21:28:11,115:INFO:Creating metrics dataframe
2024-04-29 21:28:11,122:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,125:INFO:Uploading results into container
2024-04-29 21:28:11,126:INFO:Uploading model into container now
2024-04-29 21:28:11,128:INFO:_master_model_container: 12
2024-04-29 21:28:11,128:INFO:_display_container: 2
2024-04-29 21:28:11,128:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,129:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3896, verbose=0,
                     warm_start=False)
2024-04-29 21:28:11,129:INFO:create_model() successfully completed......................................
2024-04-29 21:28:11,148:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,231:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,241:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:28:11,265:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,299:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,313:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,376:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,379:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:11,379:INFO:Creating metrics dataframe
2024-04-29 21:28:11,386:INFO:Initializing Light Gradient Boosting Machine
2024-04-29 21:28:11,387:INFO:Total runtime is 0.42343931198120116 minutes
2024-04-29 21:28:11,388:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:11,389:INFO:Initializing create_model()
2024-04-29 21:28:11,389:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:11,389:INFO:Checking exceptions
2024-04-29 21:28:11,390:INFO:Importing libraries
2024-04-29 21:28:11,390:INFO:Copying training dataset
2024-04-29 21:28:11,390:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:11,408:INFO:Defining folds
2024-04-29 21:28:11,408:INFO:Declaring metric variables
2024-04-29 21:28:11,409:INFO:Importing untrained model
2024-04-29 21:28:11,411:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-29 21:28:11,412:INFO:Starting cross validation
2024-04-29 21:28:11,417:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:11,445:INFO:Calculating mean and std
2024-04-29 21:28:11,450:WARNING:
2024-04-29 21:28:11,462:WARNING:Processing:  61%|#####################################################9                                   | 37/61 [00:18<00:14,  1.64it/s]
2024-04-29 21:28:11,466:WARNING:[A
2024-04-29 21:28:11,466:INFO:Creating metrics dataframe
2024-04-29 21:28:11,472:INFO:Uploading results into container
2024-04-29 21:28:11,474:INFO:Uploading model into container now
2024-04-29 21:28:11,475:INFO:_master_model_container: 9
2024-04-29 21:28:11,479:INFO:_display_container: 2
2024-04-29 21:28:11,480:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=635)
2024-04-29 21:28:11,483:INFO:create_model() successfully completed......................................
2024-04-29 21:28:11,647:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:11,648:INFO:Creating metrics dataframe
2024-04-29 21:28:11,653:INFO:Initializing Gradient Boosting Classifier
2024-04-29 21:28:11,654:INFO:Total runtime is 0.3060364047686259 minutes
2024-04-29 21:28:11,654:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:11,655:INFO:Initializing create_model()
2024-04-29 21:28:11,655:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:11,655:INFO:Checking exceptions
2024-04-29 21:28:11,655:INFO:Importing libraries
2024-04-29 21:28:11,655:INFO:Copying training dataset
2024-04-29 21:28:11,686:WARNING:
2024-04-29 21:28:11,692:WARNING:Processing:  64%|########################################################9                                | 39/61 [00:18<00:10,  2.17it/s]
2024-04-29 21:28:11,699:WARNING:[A
2024-04-29 21:28:11,711:INFO:Defining folds
2024-04-29 21:28:11,720:INFO:Declaring metric variables
2024-04-29 21:28:11,721:INFO:Importing untrained model
2024-04-29 21:28:11,724:INFO:Gradient Boosting Classifier Imported successfully
2024-04-29 21:28:11,726:INFO:Starting cross validation
2024-04-29 21:28:11,729:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:13,660:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:13,664:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,671:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,672:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:13,677:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:13,678:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,681:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,687:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:13,695:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,696:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,699:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:13,703:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,715:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:13,720:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:13,734:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,285:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:14,292:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,300:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,311:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:14,314:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,366:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:14,370:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,379:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,385:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:14,387:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,570:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:14,621:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:14,647:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,663:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,667:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:14,677:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,698:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:14,701:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,716:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:14,720:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:14,724:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:15,166:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:15,247:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:15,646:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:15,757:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:15,790:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:15,812:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:15,820:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:15,824:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:15,827:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:15,847:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:16,137:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:16,222:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:16,410:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:16,557:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:16,591:INFO:Calculating mean and std
2024-04-29 21:28:16,593:WARNING:
2024-04-29 21:28:16,593:WARNING:Processing:  67%|###########################################################8                             | 41/61 [00:23<00:21,  1.06s/it]
2024-04-29 21:28:16,593:WARNING:[A
2024-04-29 21:28:16,594:INFO:Creating metrics dataframe
2024-04-29 21:28:16,599:INFO:Uploading results into container
2024-04-29 21:28:16,601:INFO:Uploading model into container now
2024-04-29 21:28:16,603:INFO:_master_model_container: 10
2024-04-29 21:28:16,603:INFO:_display_container: 2
2024-04-29 21:28:16,604:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=635, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-29 21:28:16,604:INFO:create_model() successfully completed......................................
2024-04-29 21:28:16,810:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:16,811:INFO:Creating metrics dataframe
2024-04-29 21:28:16,816:INFO:Initializing Linear Discriminant Analysis
2024-04-29 21:28:16,816:INFO:Total runtime is 0.3920640548070272 minutes
2024-04-29 21:28:16,817:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:16,817:INFO:Initializing create_model()
2024-04-29 21:28:16,818:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:16,818:INFO:Checking exceptions
2024-04-29 21:28:16,818:INFO:Importing libraries
2024-04-29 21:28:16,818:INFO:Copying training dataset
2024-04-29 21:28:16,843:WARNING:
2024-04-29 21:28:16,844:WARNING:Processing:  70%|##############################################################7                          | 43/61 [00:23<00:14,  1.28it/s]
2024-04-29 21:28:16,844:WARNING:[A
2024-04-29 21:28:16,844:INFO:Defining folds
2024-04-29 21:28:16,844:INFO:Declaring metric variables
2024-04-29 21:28:16,844:INFO:Importing untrained model
2024-04-29 21:28:16,845:INFO:Linear Discriminant Analysis Imported successfully
2024-04-29 21:28:16,845:INFO:Starting cross validation
2024-04-29 21:28:16,849:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:17,119:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:17,123:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,132:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,135:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:17,136:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,142:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,144:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,149:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,158:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:17,185:INFO:Calculating mean and std
2024-04-29 21:28:17,187:INFO:Creating metrics dataframe
2024-04-29 21:28:17,193:INFO:Uploading results into container
2024-04-29 21:28:17,195:INFO:Uploading model into container now
2024-04-29 21:28:17,196:INFO:_master_model_container: 13
2024-04-29 21:28:17,197:INFO:_display_container: 2
2024-04-29 21:28:17,198:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3896, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-29 21:28:17,198:INFO:create_model() successfully completed......................................
2024-04-29 21:28:17,497:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,517:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,531:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,533:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,589:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,623:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:17,625:INFO:Creating metrics dataframe
2024-04-29 21:28:17,634:INFO:Initializing Dummy Classifier
2024-04-29 21:28:17,635:INFO:Total runtime is 0.5275655190149943 minutes
2024-04-29 21:28:17,635:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:17,636:INFO:Initializing create_model()
2024-04-29 21:28:17,636:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BB417CA0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:17,637:INFO:Checking exceptions
2024-04-29 21:28:17,637:INFO:Importing libraries
2024-04-29 21:28:17,638:INFO:Copying training dataset
2024-04-29 21:28:17,653:INFO:Defining folds
2024-04-29 21:28:17,654:INFO:Declaring metric variables
2024-04-29 21:28:17,654:INFO:Importing untrained model
2024-04-29 21:28:17,656:INFO:Dummy Classifier Imported successfully
2024-04-29 21:28:17,656:INFO:Starting cross validation
2024-04-29 21:28:17,661:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:17,795:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,900:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:17,916:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,046:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,053:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,063:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,066:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,073:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,163:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,167:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,169:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,171:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,175:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,177:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,179:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,185:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,186:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,191:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,194:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,194:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,197:INFO:Calculating mean and std
2024-04-29 21:28:18,198:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,200:WARNING:
2024-04-29 21:28:18,201:WARNING:Processing:  74%|#################################################################6                       | 45/61 [00:24<00:11,  1.34it/s]
2024-04-29 21:28:18,201:WARNING:[A
2024-04-29 21:28:18,201:INFO:Creating metrics dataframe
2024-04-29 21:28:18,202:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,206:INFO:Uploading results into container
2024-04-29 21:28:18,206:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,207:INFO:Uploading model into container now
2024-04-29 21:28:18,208:INFO:_master_model_container: 11
2024-04-29 21:28:18,209:INFO:_display_container: 2
2024-04-29 21:28:18,209:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-29 21:28:18,210:INFO:create_model() successfully completed......................................
2024-04-29 21:28:18,211:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,220:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,224:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,227:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,234:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,241:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,325:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,332:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,343:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,347:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,359:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,448:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,454:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,457:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,460:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,465:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,508:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:18,508:INFO:Creating metrics dataframe
2024-04-29 21:28:18,518:INFO:Initializing Extra Trees Classifier
2024-04-29 21:28:18,518:INFO:Total runtime is 0.4204426765441895 minutes
2024-04-29 21:28:18,520:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:18,521:INFO:Initializing create_model()
2024-04-29 21:28:18,522:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:18,522:INFO:Checking exceptions
2024-04-29 21:28:18,522:INFO:Importing libraries
2024-04-29 21:28:18,523:INFO:Copying training dataset
2024-04-29 21:28:18,544:WARNING:
2024-04-29 21:28:18,544:WARNING:Processing:  77%|####################################################################5                    | 47/61 [00:25<00:08,  1.74it/s]
2024-04-29 21:28:18,545:WARNING:[A
2024-04-29 21:28:18,545:INFO:Defining folds
2024-04-29 21:28:18,546:INFO:Declaring metric variables
2024-04-29 21:28:18,546:INFO:Importing untrained model
2024-04-29 21:28:18,548:INFO:Extra Trees Classifier Imported successfully
2024-04-29 21:28:18,549:INFO:Starting cross validation
2024-04-29 21:28:18,554:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,556:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:18,559:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,567:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,571:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,575:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,617:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,623:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,644:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 233, in transform
    X = to_df(X, index=getattr(y, "index", None))
  File "E:\Python 3.10.0\lib\site-packages\pycaret\utils\generic.py", line 103, in to_df
    data = pd.DataFrame(data, index, columns)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 822, in __init__
    mgr = ndarray_to_mgr(
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 319, in ndarray_to_mgr
    values = _prep_ndarraylike(values, copy=copy_on_sanitize)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\internals\construction.py", line 575, in _prep_ndarraylike
    values = np.array([convert(v) for v in values])
ValueError: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (2,) + inhomogeneous part.

  warnings.warn(

2024-04-29 21:28:18,654:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,663:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,671:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,678:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,726:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,729:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:18,733:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1561: UserWarning: Note that pos_label (set to 3) is ignored when average != 'binary' (got 'weighted'). You may use labels=[pos_label] to specify a single positive class.
  warnings.warn(

2024-04-29 21:28:18,757:INFO:Calculating mean and std
2024-04-29 21:28:18,775:INFO:Creating metrics dataframe
2024-04-29 21:28:18,779:INFO:Uploading results into container
2024-04-29 21:28:18,780:INFO:Uploading model into container now
2024-04-29 21:28:18,781:INFO:_master_model_container: 14
2024-04-29 21:28:18,784:INFO:_display_container: 2
2024-04-29 21:28:18,784:INFO:DummyClassifier(constant=None, random_state=3896, strategy='prior')
2024-04-29 21:28:18,784:INFO:create_model() successfully completed......................................
2024-04-29 21:28:19,171:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:19,172:INFO:Creating metrics dataframe
2024-04-29 21:28:19,180:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-29 21:28:19,190:INFO:Initializing create_model()
2024-04-29 21:28:19,190:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB4156C0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3896, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:19,191:INFO:Checking exceptions
2024-04-29 21:28:19,193:INFO:Importing libraries
2024-04-29 21:28:19,193:INFO:Copying training dataset
2024-04-29 21:28:19,226:INFO:Defining folds
2024-04-29 21:28:19,227:INFO:Declaring metric variables
2024-04-29 21:28:19,230:INFO:Importing untrained model
2024-04-29 21:28:19,230:INFO:Declaring custom model
2024-04-29 21:28:19,234:INFO:Logistic Regression Imported successfully
2024-04-29 21:28:19,240:INFO:Cross validation set to False
2024-04-29 21:28:19,240:INFO:Fitting Model
2024-04-29 21:28:19,647:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:19,724:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:19,790:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:19,824:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:19,936:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,010:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,025:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,027:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,290:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:28:20,292:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3896, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:28:20,292:INFO:create_model() successfully completed......................................
2024-04-29 21:28:20,472:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,511:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:20,523:INFO:                                    Model  Accuracy  AUC  Recall   Prec.  \
2024-04-29 21:28:20,523:INFO:lr                    Logistic Regression    0.8171  0.0  0.8171  0.8097   
2024-04-29 21:28:20,523:INFO:knn                K Neighbors Classifier    0.6838  0.0  0.6838  0.6474   
2024-04-29 21:28:20,524:INFO:ridge                    Ridge Classifier    0.6743  0.0  0.6743  0.7230   
2024-04-29 21:28:20,524:INFO:svm                   SVM - Linear Kernel    0.5728  0.0  0.5728  0.5281   
2024-04-29 21:28:20,524:INFO:dummy                    Dummy Classifier    0.5505  0.0  0.5505  0.3031   
2024-04-29 21:28:20,524:INFO:qda       Quadratic Discriminant Analysis    0.5167  0.0  0.5167  0.2774   
2024-04-29 21:28:20,525:INFO:gbc          Gradient Boosting Classifier    0.4465  0.0  0.4465  0.8002   
2024-04-29 21:28:20,525:INFO:et                 Extra Trees Classifier    0.4304  0.0  0.4304  0.8484   
2024-04-29 21:28:20,525:INFO:nb                            Naive Bayes    0.3870  0.0  0.3870  0.7474   
2024-04-29 21:28:20,525:INFO:dt               Decision Tree Classifier    0.3709  0.0  0.3709  0.6019   
2024-04-29 21:28:20,525:INFO:ada                  Ada Boost Classifier    0.3709  0.0  0.3709  0.6019   
2024-04-29 21:28:20,525:INFO:rf               Random Forest Classifier    0.3374  0.0  0.3374  0.7320   
2024-04-29 21:28:20,525:INFO:lda          Linear Discriminant Analysis    0.2071  0.0  0.2071  0.0429   
2024-04-29 21:28:20,525:INFO:lightgbm  Light Gradient Boosting Machine    0.2071  0.0  0.2071  0.0429   
2024-04-29 21:28:20,525:INFO:
2024-04-29 21:28:20,525:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-04-29 21:28:20,525:INFO:lr        0.8042  0.6793  0.6891     0.181  
2024-04-29 21:28:20,525:INFO:knn       0.6559  0.4373  0.4480     0.127  
2024-04-29 21:28:20,525:INFO:ridge     0.6350  0.3674  0.4196     0.096  
2024-04-29 21:28:20,525:INFO:svm       0.4931  0.2866  0.3369     0.151  
2024-04-29 21:28:20,525:INFO:dummy     0.3910  0.0000  0.0000     0.110  
2024-04-29 21:28:20,525:INFO:qda       0.3594  0.0000  0.0000     0.103  
2024-04-29 21:28:20,525:INFO:gbc       0.4466  0.2475  0.3724     0.318  
2024-04-29 21:28:20,525:INFO:et        0.4321  0.2306  0.3611     0.306  
2024-04-29 21:28:20,526:INFO:nb        0.3630  0.1679  0.2903     0.133  
2024-04-29 21:28:20,526:INFO:dt        0.3333  0.1466  0.2658     0.086  
2024-04-29 21:28:20,526:INFO:ada       0.3333  0.1466  0.2658     0.189  
2024-04-29 21:28:20,526:INFO:rf        0.2786  0.1474  0.3031     0.251  
2024-04-29 21:28:20,526:INFO:lda       0.0711  0.0000  0.0000     0.150  
2024-04-29 21:28:20,526:INFO:lightgbm  0.0711  0.0000  0.0000     0.577  
2024-04-29 21:28:20,526:INFO:_master_model_container: 14
2024-04-29 21:28:20,526:INFO:_display_container: 2
2024-04-29 21:28:20,528:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3896, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:28:20,529:INFO:compare_models() successfully completed......................................
2024-04-29 21:28:20,725:INFO:Calculating mean and std
2024-04-29 21:28:20,726:WARNING:
2024-04-29 21:28:20,726:WARNING:Processing:  80%|#######################################################################4                 | 49/61 [00:27<00:08,  1.37it/s]
2024-04-29 21:28:20,726:WARNING:[A
2024-04-29 21:28:20,727:INFO:Creating metrics dataframe
2024-04-29 21:28:20,732:INFO:Uploading results into container
2024-04-29 21:28:20,734:INFO:Uploading model into container now
2024-04-29 21:28:20,734:INFO:_master_model_container: 12
2024-04-29 21:28:20,734:INFO:_display_container: 2
2024-04-29 21:28:20,734:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=635, verbose=0,
                     warm_start=False)
2024-04-29 21:28:20,735:INFO:create_model() successfully completed......................................
2024-04-29 21:28:20,882:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:20,882:INFO:Creating metrics dataframe
2024-04-29 21:28:20,890:INFO:Initializing Light Gradient Boosting Machine
2024-04-29 21:28:20,890:INFO:Total runtime is 0.45996273756027223 minutes
2024-04-29 21:28:20,890:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:20,891:INFO:Initializing create_model()
2024-04-29 21:28:20,891:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:20,891:INFO:Checking exceptions
2024-04-29 21:28:20,891:INFO:Importing libraries
2024-04-29 21:28:20,891:INFO:Copying training dataset
2024-04-29 21:28:20,898:WARNING:
2024-04-29 21:28:20,899:WARNING:Processing:  84%|##########################################################################4              | 51/61 [00:27<00:05,  1.86it/s]
2024-04-29 21:28:20,899:WARNING:[A
2024-04-29 21:28:20,899:INFO:Defining folds
2024-04-29 21:28:20,899:INFO:Declaring metric variables
2024-04-29 21:28:20,899:INFO:Importing untrained model
2024-04-29 21:28:20,900:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-29 21:28:20,900:INFO:Starting cross validation
2024-04-29 21:28:20,902:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:22,304:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,321:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,326:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,331:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,352:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,354:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,424:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,438:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,534:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,544:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,720:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,735:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,755:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,771:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:22,774:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:22,791:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:23,133:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:23,136:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:23,149:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:23,150:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:23,166:INFO:Calculating mean and std
2024-04-29 21:28:23,167:WARNING:
2024-04-29 21:28:23,167:WARNING:Processing:  87%|#############################################################################3           | 53/61 [00:29<00:05,  1.40it/s]
2024-04-29 21:28:23,167:WARNING:[A
2024-04-29 21:28:23,167:INFO:Creating metrics dataframe
2024-04-29 21:28:23,171:INFO:Uploading results into container
2024-04-29 21:28:23,173:INFO:Uploading model into container now
2024-04-29 21:28:23,173:INFO:_master_model_container: 13
2024-04-29 21:28:23,173:INFO:_display_container: 2
2024-04-29 21:28:23,175:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=635, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-29 21:28:23,175:INFO:create_model() successfully completed......................................
2024-04-29 21:28:23,346:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:23,347:INFO:Creating metrics dataframe
2024-04-29 21:28:23,353:INFO:Initializing Dummy Classifier
2024-04-29 21:28:23,353:INFO:Total runtime is 0.5010245680809021 minutes
2024-04-29 21:28:23,354:INFO:SubProcess create_model() called ==================================
2024-04-29 21:28:23,355:INFO:Initializing create_model()
2024-04-29 21:28:23,355:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC8935E0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:23,355:INFO:Checking exceptions
2024-04-29 21:28:23,356:INFO:Importing libraries
2024-04-29 21:28:23,356:INFO:Copying training dataset
2024-04-29 21:28:23,367:WARNING:
2024-04-29 21:28:23,368:WARNING:Processing:  90%|################################################################################2        | 55/61 [00:30<00:03,  1.88it/s]
2024-04-29 21:28:23,368:WARNING:[A
2024-04-29 21:28:23,368:INFO:Defining folds
2024-04-29 21:28:23,368:INFO:Declaring metric variables
2024-04-29 21:28:23,368:INFO:Importing untrained model
2024-04-29 21:28:23,369:INFO:Dummy Classifier Imported successfully
2024-04-29 21:28:23,369:INFO:Starting cross validation
2024-04-29 21:28:23,373:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:28:23,957:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:23,975:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:23,993:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:23,993:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,008:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,009:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,030:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,047:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,100:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,122:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,124:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,152:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,154:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,170:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,247:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,263:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,469:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,486:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,538:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:28:24,548:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:28:24,576:INFO:Calculating mean and std
2024-04-29 21:28:24,579:WARNING:
2024-04-29 21:28:24,579:WARNING:Processing:  93%|###################################################################################1     | 57/61 [00:31<00:02,  1.81it/s]
2024-04-29 21:28:24,579:WARNING:[A
2024-04-29 21:28:24,580:INFO:Creating metrics dataframe
2024-04-29 21:28:24,584:INFO:Uploading results into container
2024-04-29 21:28:24,584:INFO:Uploading model into container now
2024-04-29 21:28:24,585:INFO:_master_model_container: 14
2024-04-29 21:28:24,585:INFO:_display_container: 2
2024-04-29 21:28:24,585:INFO:DummyClassifier(constant=None, random_state=635, strategy='prior')
2024-04-29 21:28:24,586:INFO:create_model() successfully completed......................................
2024-04-29 21:28:24,744:INFO:SubProcess create_model() end ==================================
2024-04-29 21:28:24,744:INFO:Creating metrics dataframe
2024-04-29 21:28:24,753:WARNING:
2024-04-29 21:28:24,753:WARNING:Processing:  97%|######################################################################################   | 59/61 [00:31<00:00,  2.42it/s]
2024-04-29 21:28:24,753:WARNING:[A
2024-04-29 21:28:24,753:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-29 21:28:24,758:INFO:Initializing create_model()
2024-04-29 21:28:24,759:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BD144490>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=635, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:28:24,759:INFO:Checking exceptions
2024-04-29 21:28:24,761:INFO:Importing libraries
2024-04-29 21:28:24,762:INFO:Copying training dataset
2024-04-29 21:28:24,772:INFO:Defining folds
2024-04-29 21:28:24,772:INFO:Declaring metric variables
2024-04-29 21:28:24,773:INFO:Importing untrained model
2024-04-29 21:28:24,773:INFO:Declaring custom model
2024-04-29 21:28:24,774:INFO:Logistic Regression Imported successfully
2024-04-29 21:28:24,777:INFO:Cross validation set to False
2024-04-29 21:28:24,778:INFO:Fitting Model
2024-04-29 21:28:24,994:WARNING:Summarize dataset:   0%|                                                                                            | 0/5 [00:00<?, ?it/s]
2024-04-29 21:28:25,156:WARNING:Summarize dataset:   0%|                                                                  | 0/17 [00:00<?, ?it/s, Describe variable:SibSp]
2024-04-29 21:28:25,164:WARNING:Summarize dataset:   6%|###4                                                      | 1/17 [00:00<00:02,  5.91it/s, Describe variable:SibSp]
2024-04-29 21:28:25,165:WARNING:Summarize dataset:   6%|###4                                                      | 1/17 [00:00<00:02,  5.91it/s, Describe variable:Parch]
2024-04-29 21:28:25,192:WARNING:Summarize dataset:  12%|######4                                                | 2/17 [00:00<00:02,  5.91it/s, Describe variable:Survived]
2024-04-29 21:28:25,237:WARNING:Summarize dataset:  18%|#########1                                          | 3/17 [00:00<00:02,  5.91it/s, Describe variable:PassengerId]
2024-04-29 21:28:25,246:WARNING:Summarize dataset:  24%|##############1                                             | 4/17 [00:00<00:02,  5.91it/s, Describe variable:Age]
2024-04-29 21:28:25,283:WARNING:Summarize dataset:  29%|################7                                        | 5/17 [00:00<00:02,  5.91it/s, Describe variable:Pclass]
2024-04-29 21:28:25,284:WARNING:Summarize dataset:  35%|####################1                                    | 6/17 [00:00<00:00, 23.76it/s, Describe variable:Pclass]
2024-04-29 21:28:25,308:WARNING:Summarize dataset:  35%|#####################1                                      | 6/17 [00:00<00:00, 23.76it/s, Describe variable:Sex]
2024-04-29 21:28:25,308:WARNING:Summarize dataset:  41%|########################2                                  | 7/17 [00:00<00:00, 23.76it/s, Describe variable:Fare]
2024-04-29 21:28:25,386:WARNING:Summarize dataset:  47%|#########################8                             | 8/17 [00:00<00:00, 23.76it/s, Describe variable:Embarked]
2024-04-29 21:28:25,386:WARNING:Summarize dataset:  53%|#############################1                         | 9/17 [00:00<00:00, 25.94it/s, Describe variable:Embarked]
2024-04-29 21:28:25,388:WARNING:Summarize dataset:  53%|###############################2                           | 9/17 [00:00<00:00, 25.94it/s, Describe variable:Name]
2024-04-29 21:28:25,411:WARNING:Summarize dataset:  59%|################################9                       | 10/17 [00:00<00:00, 25.94it/s, Describe variable:Ticket]
2024-04-29 21:28:25,415:WARNING:Summarize dataset:  65%|####################################8                    | 11/17 [00:00<00:00, 25.94it/s, Describe variable:Cabin]
2024-04-29 21:28:25,416:WARNING:Summarize dataset:  71%|###########################################7                  | 12/17 [00:00<00:00, 25.94it/s, Get variable types]
2024-04-29 21:28:25,417:WARNING:Summarize dataset:  72%|########################################4               | 13/18 [00:00<00:00, 25.94it/s, Get dataframe statistics]
2024-04-29 21:28:25,418:WARNING:Summarize dataset:  74%|#######################################7              | 14/19 [00:00<00:00, 25.94it/s, Calculate auto correlation]
2024-04-29 21:28:25,421:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001E4A218BC00, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-29 21:28:25,422:WARNING:Summarize dataset:  79%|################################################9             | 15/19 [00:00<00:00, 25.94it/s, Get scatter matrix]
2024-04-29 21:28:25,422:WARNING:Summarize dataset:  34%|################3                               | 15/44 [00:00<00:01, 25.94it/s, scatter PassengerId, PassengerId]
2024-04-29 21:28:25,706:WARNING:Summarize dataset:  36%|#################4                              | 16/44 [00:00<00:01, 23.44it/s, scatter PassengerId, PassengerId]
2024-04-29 21:28:25,707:WARNING:Summarize dataset:  36%|####################3                                   | 16/44 [00:00<00:01, 23.44it/s, scatter Age, PassengerId]
2024-04-29 21:28:25,976:WARNING:Summarize dataset:  39%|####################8                                 | 17/44 [00:00<00:01, 23.44it/s, scatter SibSp, PassengerId]
2024-04-29 21:28:26,244:WARNING:Summarize dataset:  41%|######################                                | 18/44 [00:01<00:01, 23.44it/s, scatter Parch, PassengerId]
2024-04-29 21:28:26,537:WARNING:Summarize dataset:  43%|#######################3                              | 19/44 [00:01<00:02,  9.53it/s, scatter Parch, PassengerId]
2024-04-29 21:28:26,538:WARNING:Summarize dataset:  43%|#######################7                               | 19/44 [00:01<00:02,  9.53it/s, scatter Fare, PassengerId]
2024-04-29 21:28:26,806:WARNING:Summarize dataset:  45%|#########################4                              | 20/44 [00:01<00:02,  9.53it/s, scatter PassengerId, Age]
2024-04-29 21:28:27,082:WARNING:Summarize dataset:  48%|##########################7                             | 21/44 [00:02<00:03,  7.22it/s, scatter PassengerId, Age]
2024-04-29 21:28:27,082:WARNING:Summarize dataset:  48%|##############################5                                 | 21/44 [00:02<00:03,  7.22it/s, scatter Age, Age]
2024-04-29 21:28:27,263:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:28:27,263:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=635, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:28:27,264:INFO:create_model() successfully completed......................................
2024-04-29 21:28:27,422:WARNING:
2024-04-29 21:28:27,423:WARNING:Processing: 100%|#########################################################################################| 61/61 [00:34<00:00,  1.45it/s]
2024-04-29 21:28:27,423:WARNING:[A
2024-04-29 21:28:27,423:WARNING:
2024-04-29 21:28:27,424:WARNING:                                                                                                                                          
2024-04-29 21:28:27,425:WARNING:[A
2024-04-29 21:28:27,472:INFO:                                    Model  Accuracy     AUC  Recall   Prec.      F1   Kappa     MCC  TT (Sec)
2024-04-29 21:28:27,474:INFO:lr                    Logistic Regression    0.8123  0.8635  0.6694  0.8139  0.7323  0.5900  0.5987     0.175
2024-04-29 21:28:27,474:INFO:ridge                    Ridge Classifier    0.7447  0.8522  0.4310  0.8126  0.5609  0.4062  0.4470     0.242
2024-04-29 21:28:27,474:INFO:et                 Extra Trees Classifier    0.7079  0.0000  0.3268  0.7960  0.4496  0.3026  0.3603     0.217
2024-04-29 21:28:27,474:INFO:nb                            Naive Bayes    0.6645  0.0000  0.1630  0.8429  0.2663  0.1635  0.2567     0.157
2024-04-29 21:28:27,474:INFO:knn                K Neighbors Classifier    0.6389  0.0000  0.3725  0.5381  0.4379  0.1874  0.1939     0.151
2024-04-29 21:28:27,481:INFO:rf               Random Forest Classifier    0.6308  0.0000  0.0502  0.6000  0.0903  0.0509  0.1155     0.218
2024-04-29 21:28:27,481:INFO:lda          Linear Discriminant Analysis    0.6228  0.5247  0.0304  0.0700  0.0424  0.0257  0.0299     0.135
2024-04-29 21:28:27,483:INFO:dt               Decision Tree Classifier    0.6164  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000     0.131
2024-04-29 21:28:27,483:INFO:ada                  Ada Boost Classifier    0.6164  0.5000  0.0000  0.0000  0.0000  0.0000  0.0000     0.194
2024-04-29 21:28:27,483:INFO:gbc          Gradient Boosting Classifier    0.6164  0.5000  0.0000  0.0000  0.0000  0.0000  0.0000     0.486
2024-04-29 21:28:27,483:INFO:lightgbm  Light Gradient Boosting Machine    0.6164  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000     0.226
2024-04-29 21:28:27,483:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000     0.120
2024-04-29 21:28:27,483:INFO:svm                   SVM - Linear Kernel    0.5940  0.6320  0.3583  0.4036  0.2987  0.1014  0.1308     0.134
2024-04-29 21:28:27,483:INFO:qda       Quadratic Discriminant Analysis    0.5906  0.5480  0.1000  0.0371  0.0541  0.0000  0.0000     0.127
2024-04-29 21:28:27,483:INFO:_master_model_container: 14
2024-04-29 21:28:27,483:INFO:_display_container: 2
2024-04-29 21:28:27,488:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=635, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:28:27,498:INFO:compare_models() successfully completed......................................
2024-04-29 21:28:27,756:WARNING:Summarize dataset:  50%|###############################                               | 22/44 [00:02<00:03,  7.22it/s, scatter SibSp, Age]
2024-04-29 21:28:28,031:WARNING:Summarize dataset:  52%|################################4                             | 23/44 [00:03<00:04,  4.68it/s, scatter SibSp, Age]
2024-04-29 21:28:28,032:WARNING:Summarize dataset:  52%|################################4                             | 23/44 [00:03<00:04,  4.68it/s, scatter Parch, Age]
2024-04-29 21:28:28,372:WARNING:Summarize dataset:  55%|#################################8                            | 24/44 [00:03<00:04,  4.33it/s, scatter Parch, Age]
2024-04-29 21:28:28,372:WARNING:Summarize dataset:  55%|##################################3                            | 24/44 [00:03<00:04,  4.33it/s, scatter Fare, Age]
2024-04-29 21:28:28,708:WARNING:Summarize dataset:  57%|###################################7                           | 25/44 [00:03<00:04,  4.03it/s, scatter Fare, Age]
2024-04-29 21:28:28,709:WARNING:Summarize dataset:  57%|##############################6                       | 25/44 [00:03<00:04,  4.03it/s, scatter PassengerId, SibSp]
2024-04-29 21:28:29,039:WARNING:Summarize dataset:  59%|###############################9                      | 26/44 [00:04<00:04,  3.78it/s, scatter PassengerId, SibSp]
2024-04-29 21:28:29,040:WARNING:Summarize dataset:  59%|####################################6                         | 26/44 [00:04<00:04,  3.78it/s, scatter Age, SibSp]
2024-04-29 21:28:29,340:WARNING:Summarize dataset:  61%|######################################                        | 27/44 [00:04<00:04,  3.67it/s, scatter Age, SibSp]
2024-04-29 21:28:29,340:WARNING:Summarize dataset:  61%|####################################8                       | 27/44 [00:04<00:04,  3.67it/s, scatter SibSp, SibSp]
2024-04-29 21:28:29,578:WARNING:Summarize dataset:  64%|######################################1                     | 28/44 [00:04<00:04,  3.79it/s, scatter SibSp, SibSp]
2024-04-29 21:28:29,579:WARNING:Summarize dataset:  64%|######################################1                     | 28/44 [00:04<00:04,  3.79it/s, scatter Parch, SibSp]
2024-04-29 21:28:29,886:WARNING:Summarize dataset:  66%|#######################################5                    | 29/44 [00:04<00:04,  3.64it/s, scatter Parch, SibSp]
2024-04-29 21:28:29,886:WARNING:Summarize dataset:  66%|########################################2                    | 29/44 [00:04<00:04,  3.64it/s, scatter Fare, SibSp]
2024-04-29 21:28:30,205:WARNING:Summarize dataset:  68%|#########################################5                   | 30/44 [00:05<00:04,  3.49it/s, scatter Fare, SibSp]
2024-04-29 21:28:30,206:WARNING:Summarize dataset:  68%|####################################8                 | 30/44 [00:05<00:04,  3.49it/s, scatter PassengerId, Parch]
2024-04-29 21:28:30,443:WARNING:Summarize dataset:  70%|######################################                | 31/44 [00:05<00:03,  3.66it/s, scatter PassengerId, Parch]
2024-04-29 21:28:30,444:WARNING:Summarize dataset:  70%|###########################################6                  | 31/44 [00:05<00:03,  3.66it/s, scatter Age, Parch]
2024-04-29 21:28:30,698:WARNING:Summarize dataset:  73%|#############################################                 | 32/44 [00:05<00:03,  3.73it/s, scatter Age, Parch]
2024-04-29 21:28:30,699:WARNING:Summarize dataset:  73%|###########################################6                | 32/44 [00:05<00:03,  3.73it/s, scatter SibSp, Parch]
2024-04-29 21:28:31,006:WARNING:Summarize dataset:  75%|#############################################               | 33/44 [00:06<00:03,  3.58it/s, scatter SibSp, Parch]
2024-04-29 21:28:31,007:WARNING:Summarize dataset:  75%|#############################################               | 33/44 [00:06<00:03,  3.58it/s, scatter Parch, Parch]
2024-04-29 21:28:31,303:WARNING:Summarize dataset:  77%|##############################################3             | 34/44 [00:06<00:02,  3.51it/s, scatter Parch, Parch]
2024-04-29 21:28:31,303:WARNING:Summarize dataset:  77%|###############################################1             | 34/44 [00:06<00:02,  3.51it/s, scatter Fare, Parch]
2024-04-29 21:28:31,592:WARNING:Summarize dataset:  80%|################################################5            | 35/44 [00:06<00:02,  3.50it/s, scatter Fare, Parch]
2024-04-29 21:28:31,593:WARNING:Summarize dataset:  80%|###########################################7           | 35/44 [00:06<00:02,  3.50it/s, scatter PassengerId, Fare]
2024-04-29 21:28:31,829:WARNING:Summarize dataset:  82%|#############################################          | 36/44 [00:06<00:02,  3.68it/s, scatter PassengerId, Fare]
2024-04-29 21:28:31,829:WARNING:Summarize dataset:  82%|###################################################5           | 36/44 [00:06<00:02,  3.68it/s, scatter Age, Fare]
2024-04-29 21:28:32,092:WARNING:Summarize dataset:  84%|####################################################9          | 37/44 [00:07<00:01,  3.72it/s, scatter Age, Fare]
2024-04-29 21:28:32,092:WARNING:Summarize dataset:  84%|###################################################2         | 37/44 [00:07<00:01,  3.72it/s, scatter SibSp, Fare]
2024-04-29 21:28:32,382:WARNING:Summarize dataset:  86%|####################################################6        | 38/44 [00:07<00:01,  3.63it/s, scatter SibSp, Fare]
2024-04-29 21:28:32,383:WARNING:Summarize dataset:  86%|####################################################6        | 38/44 [00:07<00:01,  3.63it/s, scatter Parch, Fare]
2024-04-29 21:28:32,636:WARNING:Summarize dataset:  89%|######################################################       | 39/44 [00:07<00:01,  3.72it/s, scatter Parch, Fare]
2024-04-29 21:28:32,637:WARNING:Summarize dataset:  89%|######################################################9       | 39/44 [00:07<00:01,  3.72it/s, scatter Fare, Fare]
2024-04-29 21:28:32,856:WARNING:Summarize dataset:  91%|########################################################3     | 40/44 [00:07<00:01,  3.93it/s, scatter Fare, Fare]
2024-04-29 21:28:32,856:WARNING:Summarize dataset:  85%|###################################################9         | 40/47 [00:07<00:01,  3.93it/s, Missing diagram bar]
2024-04-29 21:28:33,381:WARNING:Summarize dataset:  87%|#####################################################2       | 41/47 [00:08<00:02,  2.98it/s, Missing diagram bar]
2024-04-29 21:28:33,382:WARNING:Summarize dataset:  87%|##################################################5       | 41/47 [00:08<00:02,  2.98it/s, Missing diagram matrix]
2024-04-29 21:28:33,569:WARNING:Summarize dataset:  89%|###################################################8      | 42/47 [00:08<00:01,  3.43it/s, Missing diagram matrix]
2024-04-29 21:28:33,570:WARNING:Summarize dataset:  89%|##################################################9      | 42/47 [00:08<00:01,  3.43it/s, Missing diagram heatmap]
2024-04-29 21:28:33,848:WARNING:Summarize dataset:  91%|####################################################1    | 43/47 [00:08<00:01,  3.48it/s, Missing diagram heatmap]
2024-04-29 21:28:33,849:WARNING:Summarize dataset:  91%|###############################################################1     | 43/47 [00:08<00:01,  3.48it/s, Take sample]
2024-04-29 21:28:33,850:WARNING:Summarize dataset:  94%|########################################################1   | 44/47 [00:08<00:00,  3.48it/s, Detecting duplicates]
2024-04-29 21:28:33,864:WARNING:Summarize dataset:  96%|###################################################################   | 45/47 [00:08<00:00,  3.48it/s, Get alerts]
2024-04-29 21:28:33,865:WARNING:Summarize dataset:  98%|######################################################8 | 46/47 [00:08<00:00,  3.48it/s, Get reproduction details]
2024-04-29 21:28:33,867:WARNING:Summarize dataset: 100%|#######################################################################| 47/47 [00:08<00:00,  3.48it/s, Completed]
2024-04-29 21:28:33,867:WARNING:Summarize dataset: 100%|#######################################################################| 47/47 [00:08<00:00,  5.30it/s, Completed]
2024-04-29 21:28:33,867:WARNING:
2024-04-29 21:28:33,868:WARNING:Generate report structure:   0%|                                                                                    | 0/1 [00:00<?, ?it/s]
2024-04-29 21:28:45,427:WARNING:Generate report structure: 100%|############################################################################| 1/1 [00:11<00:00, 11.56s/it]
2024-04-29 21:28:45,428:WARNING:Generate report structure: 100%|############################################################################| 1/1 [00:11<00:00, 11.56s/it]
2024-04-29 21:28:45,428:WARNING:
2024-04-29 21:28:45,429:WARNING:Render HTML:   0%|                                                                                                  | 0/1 [00:00<?, ?it/s]
2024-04-29 21:28:48,099:WARNING:Render HTML: 100%|##########################################################################################| 1/1 [00:02<00:00,  2.67s/it]
2024-04-29 21:28:48,099:WARNING:Render HTML: 100%|##########################################################################################| 1/1 [00:02<00:00,  2.67s/it]
2024-04-29 21:28:48,100:WARNING:
2024-04-29 21:29:48,404:INFO:PyCaret ClassificationExperiment
2024-04-29 21:29:48,405:INFO:Logging name: clf-default-name
2024-04-29 21:29:48,405:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:29:48,405:INFO:version 3.3.1
2024-04-29 21:29:48,405:INFO:Initializing setup()
2024-04-29 21:29:48,405:INFO:self.USI: 4399
2024-04-29 21:29:48,405:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:29:48,405:INFO:Checking environment
2024-04-29 21:29:48,405:INFO:python_version: 3.10.0
2024-04-29 21:29:48,405:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:29:48,405:INFO:machine: AMD64
2024-04-29 21:29:48,405:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:29:48,409:INFO:Memory: svmem(total=8361132032, available=881598464, percent=89.5, used=7479533568, free=881598464)
2024-04-29 21:29:48,409:INFO:Physical Core: 4
2024-04-29 21:29:48,409:INFO:Logical Core: 8
2024-04-29 21:29:48,409:INFO:Checking libraries
2024-04-29 21:29:48,409:INFO:System:
2024-04-29 21:29:48,409:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:29:48,409:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:29:48,409:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:29:48,409:INFO:PyCaret required dependencies:
2024-04-29 21:29:48,410:INFO:                 pip: 21.2.3
2024-04-29 21:29:48,410:INFO:          setuptools: 57.4.0
2024-04-29 21:29:48,410:INFO:             pycaret: 3.3.1
2024-04-29 21:29:48,410:INFO:             IPython: 8.23.0
2024-04-29 21:29:48,410:INFO:          ipywidgets: 8.1.2
2024-04-29 21:29:48,410:INFO:                tqdm: 4.66.2
2024-04-29 21:29:48,410:INFO:               numpy: 1.26.4
2024-04-29 21:29:48,410:INFO:              pandas: 2.1.4
2024-04-29 21:29:48,410:INFO:              jinja2: 3.1.3
2024-04-29 21:29:48,410:INFO:               scipy: 1.11.4
2024-04-29 21:29:48,410:INFO:              joblib: 1.3.2
2024-04-29 21:29:48,410:INFO:             sklearn: 1.4.2
2024-04-29 21:29:48,410:INFO:                pyod: 1.1.3
2024-04-29 21:29:48,410:INFO:            imblearn: 0.12.2
2024-04-29 21:29:48,410:INFO:   category_encoders: 2.6.3
2024-04-29 21:29:48,410:INFO:            lightgbm: 4.3.0
2024-04-29 21:29:48,410:INFO:               numba: 0.59.1
2024-04-29 21:29:48,410:INFO:            requests: 2.31.0
2024-04-29 21:29:48,410:INFO:          matplotlib: 3.7.5
2024-04-29 21:29:48,410:INFO:          scikitplot: 0.3.7
2024-04-29 21:29:48,411:INFO:         yellowbrick: 1.5
2024-04-29 21:29:48,411:INFO:              plotly: 5.21.0
2024-04-29 21:29:48,411:INFO:    plotly-resampler: Not installed
2024-04-29 21:29:48,411:INFO:             kaleido: 0.2.1
2024-04-29 21:29:48,411:INFO:           schemdraw: 0.15
2024-04-29 21:29:48,411:INFO:         statsmodels: 0.14.2
2024-04-29 21:29:48,411:INFO:              sktime: 0.26.0
2024-04-29 21:29:48,411:INFO:               tbats: 1.1.3
2024-04-29 21:29:48,411:INFO:            pmdarima: 2.0.4
2024-04-29 21:29:48,411:INFO:              psutil: 5.9.8
2024-04-29 21:29:48,411:INFO:          markupsafe: 2.1.5
2024-04-29 21:29:48,411:INFO:             pickle5: Not installed
2024-04-29 21:29:48,411:INFO:         cloudpickle: 3.0.0
2024-04-29 21:29:48,411:INFO:         deprecation: 2.1.0
2024-04-29 21:29:48,411:INFO:              xxhash: 3.4.1
2024-04-29 21:29:48,411:INFO:           wurlitzer: Not installed
2024-04-29 21:29:48,411:INFO:PyCaret optional dependencies:
2024-04-29 21:29:48,411:INFO:                shap: Not installed
2024-04-29 21:29:48,411:INFO:           interpret: Not installed
2024-04-29 21:29:48,411:INFO:                umap: Not installed
2024-04-29 21:29:48,411:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:29:48,411:INFO:  explainerdashboard: Not installed
2024-04-29 21:29:48,411:INFO:             autoviz: Not installed
2024-04-29 21:29:48,411:INFO:           fairlearn: Not installed
2024-04-29 21:29:48,411:INFO:          deepchecks: Not installed
2024-04-29 21:29:48,412:INFO:             xgboost: Not installed
2024-04-29 21:29:48,412:INFO:            catboost: Not installed
2024-04-29 21:29:48,412:INFO:              kmodes: Not installed
2024-04-29 21:29:48,412:INFO:             mlxtend: Not installed
2024-04-29 21:29:48,412:INFO:       statsforecast: Not installed
2024-04-29 21:29:48,412:INFO:        tune_sklearn: Not installed
2024-04-29 21:29:48,412:INFO:                 ray: Not installed
2024-04-29 21:29:48,412:INFO:            hyperopt: Not installed
2024-04-29 21:29:48,412:INFO:              optuna: Not installed
2024-04-29 21:29:48,412:INFO:               skopt: Not installed
2024-04-29 21:29:48,412:INFO:              mlflow: Not installed
2024-04-29 21:29:48,412:INFO:              gradio: Not installed
2024-04-29 21:29:48,412:INFO:             fastapi: Not installed
2024-04-29 21:29:48,412:INFO:             uvicorn: Not installed
2024-04-29 21:29:48,412:INFO:              m2cgen: Not installed
2024-04-29 21:29:48,412:INFO:           evidently: Not installed
2024-04-29 21:29:48,412:INFO:               fugue: Not installed
2024-04-29 21:29:48,412:INFO:           streamlit: 1.33.0
2024-04-29 21:29:48,412:INFO:             prophet: Not installed
2024-04-29 21:29:48,412:INFO:None
2024-04-29 21:29:48,412:INFO:Set up data.
2024-04-29 21:29:48,429:INFO:Set up folding strategy.
2024-04-29 21:29:48,429:INFO:Set up train/test split.
2024-04-29 21:29:52,492:INFO:PyCaret ClassificationExperiment
2024-04-29 21:29:52,493:INFO:Logging name: clf-default-name
2024-04-29 21:29:52,493:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:29:52,493:INFO:version 3.3.1
2024-04-29 21:29:52,493:INFO:Initializing setup()
2024-04-29 21:29:52,493:INFO:self.USI: cb7d
2024-04-29 21:29:52,493:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:29:52,493:INFO:Checking environment
2024-04-29 21:29:52,493:INFO:python_version: 3.10.0
2024-04-29 21:29:52,493:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:29:52,493:INFO:machine: AMD64
2024-04-29 21:29:52,493:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:29:52,505:INFO:Memory: svmem(total=8361132032, available=893411328, percent=89.3, used=7467720704, free=893411328)
2024-04-29 21:29:52,505:INFO:Physical Core: 4
2024-04-29 21:29:52,505:INFO:Logical Core: 8
2024-04-29 21:29:52,505:INFO:Checking libraries
2024-04-29 21:29:52,505:INFO:System:
2024-04-29 21:29:52,505:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:29:52,505:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:29:52,505:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:29:52,505:INFO:PyCaret required dependencies:
2024-04-29 21:29:52,505:INFO:                 pip: 21.2.3
2024-04-29 21:29:52,505:INFO:          setuptools: 57.4.0
2024-04-29 21:29:52,506:INFO:             pycaret: 3.3.1
2024-04-29 21:29:52,506:INFO:             IPython: 8.23.0
2024-04-29 21:29:52,506:INFO:          ipywidgets: 8.1.2
2024-04-29 21:29:52,506:INFO:                tqdm: 4.66.2
2024-04-29 21:29:52,506:INFO:               numpy: 1.26.4
2024-04-29 21:29:52,506:INFO:              pandas: 2.1.4
2024-04-29 21:29:52,506:INFO:              jinja2: 3.1.3
2024-04-29 21:29:52,506:INFO:               scipy: 1.11.4
2024-04-29 21:29:52,506:INFO:              joblib: 1.3.2
2024-04-29 21:29:52,506:INFO:             sklearn: 1.4.2
2024-04-29 21:29:52,506:INFO:                pyod: 1.1.3
2024-04-29 21:29:52,506:INFO:            imblearn: 0.12.2
2024-04-29 21:29:52,506:INFO:   category_encoders: 2.6.3
2024-04-29 21:29:52,506:INFO:            lightgbm: 4.3.0
2024-04-29 21:29:52,507:INFO:               numba: 0.59.1
2024-04-29 21:29:52,507:INFO:            requests: 2.31.0
2024-04-29 21:29:52,507:INFO:          matplotlib: 3.7.5
2024-04-29 21:29:52,507:INFO:          scikitplot: 0.3.7
2024-04-29 21:29:52,507:INFO:         yellowbrick: 1.5
2024-04-29 21:29:52,507:INFO:              plotly: 5.21.0
2024-04-29 21:29:52,507:INFO:    plotly-resampler: Not installed
2024-04-29 21:29:52,507:INFO:             kaleido: 0.2.1
2024-04-29 21:29:52,507:INFO:           schemdraw: 0.15
2024-04-29 21:29:52,507:INFO:         statsmodels: 0.14.2
2024-04-29 21:29:52,507:INFO:              sktime: 0.26.0
2024-04-29 21:29:52,507:INFO:               tbats: 1.1.3
2024-04-29 21:29:52,507:INFO:            pmdarima: 2.0.4
2024-04-29 21:29:52,508:INFO:              psutil: 5.9.8
2024-04-29 21:29:52,508:INFO:          markupsafe: 2.1.5
2024-04-29 21:29:52,508:INFO:             pickle5: Not installed
2024-04-29 21:29:52,508:INFO:         cloudpickle: 3.0.0
2024-04-29 21:29:52,508:INFO:         deprecation: 2.1.0
2024-04-29 21:29:52,508:INFO:              xxhash: 3.4.1
2024-04-29 21:29:52,508:INFO:           wurlitzer: Not installed
2024-04-29 21:29:52,508:INFO:PyCaret optional dependencies:
2024-04-29 21:29:52,508:INFO:                shap: Not installed
2024-04-29 21:29:52,508:INFO:           interpret: Not installed
2024-04-29 21:29:52,509:INFO:                umap: Not installed
2024-04-29 21:29:52,509:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:29:52,509:INFO:  explainerdashboard: Not installed
2024-04-29 21:29:52,509:INFO:             autoviz: Not installed
2024-04-29 21:29:52,509:INFO:           fairlearn: Not installed
2024-04-29 21:29:52,509:INFO:          deepchecks: Not installed
2024-04-29 21:29:52,509:INFO:             xgboost: Not installed
2024-04-29 21:29:52,509:INFO:            catboost: Not installed
2024-04-29 21:29:52,509:INFO:              kmodes: Not installed
2024-04-29 21:29:52,509:INFO:             mlxtend: Not installed
2024-04-29 21:29:52,509:INFO:       statsforecast: Not installed
2024-04-29 21:29:52,509:INFO:        tune_sklearn: Not installed
2024-04-29 21:29:52,509:INFO:                 ray: Not installed
2024-04-29 21:29:52,510:INFO:            hyperopt: Not installed
2024-04-29 21:29:52,510:INFO:              optuna: Not installed
2024-04-29 21:29:52,510:INFO:               skopt: Not installed
2024-04-29 21:29:52,510:INFO:              mlflow: Not installed
2024-04-29 21:29:52,510:INFO:              gradio: Not installed
2024-04-29 21:29:52,510:INFO:             fastapi: Not installed
2024-04-29 21:29:52,510:INFO:             uvicorn: Not installed
2024-04-29 21:29:52,510:INFO:              m2cgen: Not installed
2024-04-29 21:29:52,510:INFO:           evidently: Not installed
2024-04-29 21:29:52,510:INFO:               fugue: Not installed
2024-04-29 21:29:52,510:INFO:           streamlit: 1.33.0
2024-04-29 21:29:52,510:INFO:             prophet: Not installed
2024-04-29 21:29:52,510:INFO:None
2024-04-29 21:29:52,510:INFO:Set up data.
2024-04-29 21:29:52,534:INFO:Set up folding strategy.
2024-04-29 21:29:52,536:INFO:Set up train/test split.
2024-04-29 21:29:52,556:INFO:Set up index.
2024-04-29 21:29:52,558:INFO:Assigning column types.
2024-04-29 21:29:52,563:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-29 21:29:52,637:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:29:52,639:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:29:52,702:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:52,703:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:52,772:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:29:52,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:29:52,856:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:52,857:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:52,857:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-29 21:29:52,940:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:29:52,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:52,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,068:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:29:53,106:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,106:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,107:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-29 21:29:53,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,236:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,415:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:53,421:INFO:Preparing preprocessing pipeline...
2024-04-29 21:29:53,425:INFO:Set up simple imputation.
2024-04-29 21:29:53,437:INFO:Set up encoding of ordinal features.
2024-04-29 21:29:53,441:INFO:Set up encoding of categorical features.
2024-04-29 21:29:53,660:INFO:Finished creating preprocessing pipeline.
2024-04-29 21:29:53,697:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-29 21:29:53,697:INFO:Creating final display dataframe.
2024-04-29 21:29:54,603:INFO:Setup _display_container:                     Description             Value
0                    Session id              3365
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              cb7d
2024-04-29 21:29:54,617:INFO:                    Description             Value
2024-04-29 21:29:54,618:INFO:0                    Session id              3365
2024-04-29 21:29:54,618:INFO:1                        Target          Survived
2024-04-29 21:29:54,618:INFO:2                   Target type            Binary
2024-04-29 21:29:54,618:INFO:3           Original data shape         (891, 12)
2024-04-29 21:29:54,618:INFO:4        Transformed data shape         (891, 14)
2024-04-29 21:29:54,619:INFO:5   Transformed train set shape         (623, 14)
2024-04-29 21:29:54,619:INFO:6    Transformed test set shape         (268, 14)
2024-04-29 21:29:54,619:INFO:7              Numeric features                 6
2024-04-29 21:29:54,619:INFO:8          Categorical features                 5
2024-04-29 21:29:54,619:INFO:9      Rows with missing values             79.5%
2024-04-29 21:29:54,619:INFO:10                   Preprocess              True
2024-04-29 21:29:54,620:INFO:11              Imputation type            simple
2024-04-29 21:29:54,620:INFO:12           Numeric imputation              mean
2024-04-29 21:29:54,620:INFO:13       Categorical imputation              mode
2024-04-29 21:29:54,620:INFO:14     Maximum one-hot encoding                25
2024-04-29 21:29:54,620:INFO:15              Encoding method              None
2024-04-29 21:29:54,620:INFO:16               Fold Generator   StratifiedKFold
2024-04-29 21:29:54,621:INFO:17                  Fold Number                10
2024-04-29 21:29:54,621:INFO:18                     CPU Jobs                -1
2024-04-29 21:29:54,621:INFO:19                      Use GPU             False
2024-04-29 21:29:54,621:INFO:20               Log Experiment             False
2024-04-29 21:29:54,621:INFO:21              Experiment Name  clf-default-name
2024-04-29 21:29:54,622:INFO:22                          USI              cb7d
2024-04-29 21:29:54,770:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:54,770:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:54,911:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:54,912:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:29:54,914:INFO:setup() successfully completed in 2.43s...............
2024-04-29 21:29:54,921:INFO:Initializing compare_models()
2024-04-29 21:29:54,921:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-29 21:29:54,922:INFO:Checking exceptions
2024-04-29 21:29:54,936:INFO:Preparing display monitor
2024-04-29 21:29:54,940:WARNING:Processing:   0%|                                                                                                  | 0/61 [00:00<?, ?it/s]
2024-04-29 21:29:54,941:INFO:Initializing Logistic Regression
2024-04-29 21:29:54,943:INFO:Total runtime is 2.386172612508138e-05 minutes
2024-04-29 21:29:54,943:INFO:SubProcess create_model() called ==================================
2024-04-29 21:29:54,944:INFO:Initializing create_model()
2024-04-29 21:29:54,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:29:54,944:INFO:Checking exceptions
2024-04-29 21:29:54,944:INFO:Importing libraries
2024-04-29 21:29:54,944:INFO:Copying training dataset
2024-04-29 21:29:54,952:INFO:Defining folds
2024-04-29 21:29:54,952:INFO:Declaring metric variables
2024-04-29 21:29:54,952:INFO:Importing untrained model
2024-04-29 21:29:54,952:INFO:Logistic Regression Imported successfully
2024-04-29 21:29:54,953:INFO:Starting cross validation
2024-04-29 21:29:54,955:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:29:55,575:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,583:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,626:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,675:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,722:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,725:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,823:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:55,890:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:56,333:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:56,365:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:29:56,452:INFO:Calculating mean and std
2024-04-29 21:29:56,454:WARNING:Processing:   8%|#######3                                                                                  | 5/61 [00:01<00:16,  3.31it/s]
2024-04-29 21:29:56,454:INFO:Creating metrics dataframe
2024-04-29 21:29:56,457:INFO:Uploading results into container
2024-04-29 21:29:56,457:INFO:Uploading model into container now
2024-04-29 21:29:56,458:INFO:_master_model_container: 1
2024-04-29 21:29:56,459:INFO:_display_container: 2
2024-04-29 21:29:56,460:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3365, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:29:56,460:INFO:create_model() successfully completed......................................
2024-04-29 21:29:56,615:INFO:SubProcess create_model() end ==================================
2024-04-29 21:29:56,615:INFO:Creating metrics dataframe
2024-04-29 21:29:56,618:INFO:Initializing K Neighbors Classifier
2024-04-29 21:29:56,618:INFO:Total runtime is 0.02794653574625651 minutes
2024-04-29 21:29:56,619:INFO:SubProcess create_model() called ==================================
2024-04-29 21:29:56,619:INFO:Initializing create_model()
2024-04-29 21:29:56,619:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:29:56,619:INFO:Checking exceptions
2024-04-29 21:29:56,619:INFO:Importing libraries
2024-04-29 21:29:56,619:INFO:Copying training dataset
2024-04-29 21:29:56,625:WARNING:Processing:  11%|##########3                                                                               | 7/61 [00:01<00:12,  4.47it/s]
2024-04-29 21:29:56,626:INFO:Defining folds
2024-04-29 21:29:56,626:INFO:Declaring metric variables
2024-04-29 21:29:56,626:INFO:Importing untrained model
2024-04-29 21:29:56,629:INFO:K Neighbors Classifier Imported successfully
2024-04-29 21:29:56,630:INFO:Starting cross validation
2024-04-29 21:29:56,636:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:29:57,172:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,221:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,273:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,274:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,280:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,292:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,295:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,302:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,580:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,583:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:57,620:INFO:Calculating mean and std
2024-04-29 21:29:57,622:WARNING:Processing:  15%|#############2                                                                            | 9/61 [00:02<00:16,  3.15it/s]
2024-04-29 21:29:57,622:INFO:Creating metrics dataframe
2024-04-29 21:29:57,626:INFO:Uploading results into container
2024-04-29 21:29:57,627:INFO:Uploading model into container now
2024-04-29 21:29:57,628:INFO:_master_model_container: 2
2024-04-29 21:29:57,629:INFO:_display_container: 2
2024-04-29 21:29:57,629:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-29 21:29:57,629:INFO:create_model() successfully completed......................................
2024-04-29 21:29:57,758:INFO:SubProcess create_model() end ==================================
2024-04-29 21:29:57,760:INFO:Creating metrics dataframe
2024-04-29 21:29:57,768:INFO:Initializing Naive Bayes
2024-04-29 21:29:57,768:INFO:Total runtime is 0.04711083571116129 minutes
2024-04-29 21:29:57,768:INFO:SubProcess create_model() called ==================================
2024-04-29 21:29:57,769:INFO:Initializing create_model()
2024-04-29 21:29:57,769:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:29:57,769:INFO:Checking exceptions
2024-04-29 21:29:57,770:INFO:Importing libraries
2024-04-29 21:29:57,770:INFO:Copying training dataset
2024-04-29 21:29:57,780:WARNING:Processing:  18%|################                                                                         | 11/61 [00:02<00:11,  4.18it/s]
2024-04-29 21:29:57,780:INFO:Defining folds
2024-04-29 21:29:57,780:INFO:Declaring metric variables
2024-04-29 21:29:57,781:INFO:Importing untrained model
2024-04-29 21:29:57,781:INFO:Naive Bayes Imported successfully
2024-04-29 21:29:57,782:INFO:Starting cross validation
2024-04-29 21:29:57,785:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:29:58,204:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,220:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,249:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,293:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,328:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,341:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,349:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,368:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,514:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,529:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:58,563:INFO:Calculating mean and std
2024-04-29 21:29:58,564:WARNING:Processing:  21%|##################9                                                                      | 13/61 [00:03<00:13,  3.47it/s]
2024-04-29 21:29:58,564:INFO:Creating metrics dataframe
2024-04-29 21:29:58,568:INFO:Uploading results into container
2024-04-29 21:29:58,569:INFO:Uploading model into container now
2024-04-29 21:29:58,570:INFO:_master_model_container: 3
2024-04-29 21:29:58,570:INFO:_display_container: 2
2024-04-29 21:29:58,570:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-29 21:29:58,570:INFO:create_model() successfully completed......................................
2024-04-29 21:29:58,724:INFO:SubProcess create_model() end ==================================
2024-04-29 21:29:58,725:INFO:Creating metrics dataframe
2024-04-29 21:29:58,729:INFO:Initializing Decision Tree Classifier
2024-04-29 21:29:58,729:INFO:Total runtime is 0.06313592990239461 minutes
2024-04-29 21:29:58,731:INFO:SubProcess create_model() called ==================================
2024-04-29 21:29:58,731:INFO:Initializing create_model()
2024-04-29 21:29:58,731:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:29:58,731:INFO:Checking exceptions
2024-04-29 21:29:58,731:INFO:Importing libraries
2024-04-29 21:29:58,731:INFO:Copying training dataset
2024-04-29 21:29:58,742:WARNING:Processing:  25%|#####################8                                                                   | 15/61 [00:03<00:10,  4.43it/s]
2024-04-29 21:29:58,743:INFO:Defining folds
2024-04-29 21:29:58,743:INFO:Declaring metric variables
2024-04-29 21:29:58,743:INFO:Importing untrained model
2024-04-29 21:29:58,744:INFO:Decision Tree Classifier Imported successfully
2024-04-29 21:29:58,744:INFO:Starting cross validation
2024-04-29 21:29:58,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:29:59,163:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,185:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,187:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,200:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,207:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,216:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,233:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,250:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,278:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,286:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,287:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,289:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,303:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,303:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,306:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,317:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,447:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,451:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,457:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:29:59,462:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:29:59,469:INFO:Calculating mean and std
2024-04-29 21:29:59,470:WARNING:Processing:  28%|########################8                                                                | 17/61 [00:04<00:11,  3.72it/s]
2024-04-29 21:29:59,470:INFO:Creating metrics dataframe
2024-04-29 21:29:59,473:INFO:Uploading results into container
2024-04-29 21:29:59,474:INFO:Uploading model into container now
2024-04-29 21:29:59,474:INFO:_master_model_container: 4
2024-04-29 21:29:59,474:INFO:_display_container: 2
2024-04-29 21:29:59,475:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=3365, splitter='best')
2024-04-29 21:29:59,475:INFO:create_model() successfully completed......................................
2024-04-29 21:29:59,657:INFO:SubProcess create_model() end ==================================
2024-04-29 21:29:59,657:INFO:Creating metrics dataframe
2024-04-29 21:29:59,663:INFO:Initializing SVM - Linear Kernel
2024-04-29 21:29:59,663:INFO:Total runtime is 0.07870306173960367 minutes
2024-04-29 21:29:59,664:INFO:SubProcess create_model() called ==================================
2024-04-29 21:29:59,664:INFO:Initializing create_model()
2024-04-29 21:29:59,664:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:29:59,664:INFO:Checking exceptions
2024-04-29 21:29:59,664:INFO:Importing libraries
2024-04-29 21:29:59,664:INFO:Copying training dataset
2024-04-29 21:29:59,674:WARNING:Processing:  31%|###########################7                                                             | 19/61 [00:04<00:09,  4.60it/s]
2024-04-29 21:29:59,674:INFO:Defining folds
2024-04-29 21:29:59,675:INFO:Declaring metric variables
2024-04-29 21:29:59,675:INFO:Importing untrained model
2024-04-29 21:29:59,675:INFO:SVM - Linear Kernel Imported successfully
2024-04-29 21:29:59,676:INFO:Starting cross validation
2024-04-29 21:29:59,679:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:00,368:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:00,635:INFO:Calculating mean and std
2024-04-29 21:30:00,637:WARNING:Processing:  34%|##############################6                                                          | 21/61 [00:05<00:11,  3.36it/s]
2024-04-29 21:30:00,638:INFO:Creating metrics dataframe
2024-04-29 21:30:00,645:INFO:Uploading results into container
2024-04-29 21:30:00,647:INFO:Uploading model into container now
2024-04-29 21:30:00,649:INFO:_master_model_container: 5
2024-04-29 21:30:00,651:INFO:_display_container: 2
2024-04-29 21:30:00,652:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=3365, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-29 21:30:00,653:INFO:create_model() successfully completed......................................
2024-04-29 21:30:00,814:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:00,815:INFO:Creating metrics dataframe
2024-04-29 21:30:00,826:INFO:Initializing Ridge Classifier
2024-04-29 21:30:00,826:INFO:Total runtime is 0.09808241526285807 minutes
2024-04-29 21:30:00,827:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:00,827:INFO:Initializing create_model()
2024-04-29 21:30:00,828:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:00,828:INFO:Checking exceptions
2024-04-29 21:30:00,828:INFO:Importing libraries
2024-04-29 21:30:00,828:INFO:Copying training dataset
2024-04-29 21:30:00,844:WARNING:Processing:  38%|#################################5                                                       | 23/61 [00:05<00:09,  4.19it/s]
2024-04-29 21:30:00,844:INFO:Defining folds
2024-04-29 21:30:00,844:INFO:Declaring metric variables
2024-04-29 21:30:00,845:INFO:Importing untrained model
2024-04-29 21:30:00,846:INFO:Ridge Classifier Imported successfully
2024-04-29 21:30:00,847:INFO:Starting cross validation
2024-04-29 21:30:00,851:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:01,825:INFO:Calculating mean and std
2024-04-29 21:30:01,826:WARNING:Processing:  41%|####################################4                                                    | 25/61 [00:06<00:11,  3.17it/s]
2024-04-29 21:30:01,826:INFO:Creating metrics dataframe
2024-04-29 21:30:01,828:INFO:Uploading results into container
2024-04-29 21:30:01,829:INFO:Uploading model into container now
2024-04-29 21:30:01,830:INFO:_master_model_container: 6
2024-04-29 21:30:01,830:INFO:_display_container: 2
2024-04-29 21:30:01,830:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=3365, solver='auto',
                tol=0.0001)
2024-04-29 21:30:01,830:INFO:create_model() successfully completed......................................
2024-04-29 21:30:01,985:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:01,985:INFO:Creating metrics dataframe
2024-04-29 21:30:01,990:INFO:Initializing Random Forest Classifier
2024-04-29 21:30:01,990:INFO:Total runtime is 0.11748607158660888 minutes
2024-04-29 21:30:01,990:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:01,992:INFO:Initializing create_model()
2024-04-29 21:30:01,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:01,992:INFO:Checking exceptions
2024-04-29 21:30:01,992:INFO:Importing libraries
2024-04-29 21:30:01,992:INFO:Copying training dataset
2024-04-29 21:30:02,005:WARNING:Processing:  44%|#######################################3                                                 | 27/61 [00:07<00:08,  4.05it/s]
2024-04-29 21:30:02,005:INFO:Defining folds
2024-04-29 21:30:02,005:INFO:Declaring metric variables
2024-04-29 21:30:02,005:INFO:Importing untrained model
2024-04-29 21:30:02,006:INFO:Random Forest Classifier Imported successfully
2024-04-29 21:30:02,007:INFO:Starting cross validation
2024-04-29 21:30:02,010:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:02,906:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,914:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,918:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,923:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:02,929:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:02,945:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,948:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,961:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:02,976:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:02,993:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:03,036:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:03,204:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:03,212:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:03,432:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:03,443:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:03,480:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:03,488:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:03,513:INFO:Calculating mean and std
2024-04-29 21:30:03,514:WARNING:Processing:  48%|##########################################3                                              | 29/61 [00:08<00:12,  2.50it/s]
2024-04-29 21:30:03,514:INFO:Creating metrics dataframe
2024-04-29 21:30:03,518:INFO:Uploading results into container
2024-04-29 21:30:03,519:INFO:Uploading model into container now
2024-04-29 21:30:03,520:INFO:_master_model_container: 7
2024-04-29 21:30:03,520:INFO:_display_container: 2
2024-04-29 21:30:03,521:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=3365, verbose=0,
                       warm_start=False)
2024-04-29 21:30:03,521:INFO:create_model() successfully completed......................................
2024-04-29 21:30:03,659:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:03,660:INFO:Creating metrics dataframe
2024-04-29 21:30:03,663:INFO:Initializing Quadratic Discriminant Analysis
2024-04-29 21:30:03,664:INFO:Total runtime is 0.1453862428665161 minutes
2024-04-29 21:30:03,664:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:03,665:INFO:Initializing create_model()
2024-04-29 21:30:03,665:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:03,665:INFO:Checking exceptions
2024-04-29 21:30:03,665:INFO:Importing libraries
2024-04-29 21:30:03,665:INFO:Copying training dataset
2024-04-29 21:30:03,678:WARNING:Processing:  51%|#############################################2                                           | 31/61 [00:08<00:09,  3.29it/s]
2024-04-29 21:30:03,678:INFO:Defining folds
2024-04-29 21:30:03,678:INFO:Declaring metric variables
2024-04-29 21:30:03,679:INFO:Importing untrained model
2024-04-29 21:30:03,680:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-29 21:30:03,680:INFO:Starting cross validation
2024-04-29 21:30:03,684:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:03,988:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:03,993:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,002:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,071:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,077:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,105:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,107:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,110:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,141:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,143:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,154:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,207:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,247:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,258:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,263:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,272:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,382:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,384:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:04,486:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:04,507:INFO:Calculating mean and std
2024-04-29 21:30:04,508:WARNING:Processing:  54%|################################################1                                        | 33/61 [00:09<00:09,  2.96it/s]
2024-04-29 21:30:04,508:INFO:Creating metrics dataframe
2024-04-29 21:30:04,513:INFO:Uploading results into container
2024-04-29 21:30:04,513:INFO:Uploading model into container now
2024-04-29 21:30:04,514:INFO:_master_model_container: 8
2024-04-29 21:30:04,514:INFO:_display_container: 2
2024-04-29 21:30:04,515:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-29 21:30:04,515:INFO:create_model() successfully completed......................................
2024-04-29 21:30:04,672:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:04,672:INFO:Creating metrics dataframe
2024-04-29 21:30:04,678:INFO:Initializing Ada Boost Classifier
2024-04-29 21:30:04,678:INFO:Total runtime is 0.1622856060663859 minutes
2024-04-29 21:30:04,679:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:04,679:INFO:Initializing create_model()
2024-04-29 21:30:04,679:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:04,679:INFO:Checking exceptions
2024-04-29 21:30:04,680:INFO:Importing libraries
2024-04-29 21:30:04,680:INFO:Copying training dataset
2024-04-29 21:30:04,690:WARNING:Processing:  57%|###################################################                                      | 35/61 [00:09<00:06,  3.80it/s]
2024-04-29 21:30:04,690:INFO:Defining folds
2024-04-29 21:30:04,690:INFO:Declaring metric variables
2024-04-29 21:30:04,691:INFO:Importing untrained model
2024-04-29 21:30:04,691:INFO:Ada Boost Classifier Imported successfully
2024-04-29 21:30:04,691:INFO:Starting cross validation
2024-04-29 21:30:04,696:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:05,028:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,034:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,034:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,040:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,052:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,061:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,105:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,110:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,152:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,153:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,153:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,173:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,191:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,195:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,252:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,280:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,324:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,334:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:05,433:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,456:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:05,473:INFO:Calculating mean and std
2024-04-29 21:30:05,475:WARNING:Processing:  61%|#####################################################9                                   | 37/61 [00:10<00:07,  3.31it/s]
2024-04-29 21:30:05,475:INFO:Creating metrics dataframe
2024-04-29 21:30:05,479:INFO:Uploading results into container
2024-04-29 21:30:05,480:INFO:Uploading model into container now
2024-04-29 21:30:05,481:INFO:_master_model_container: 9
2024-04-29 21:30:05,481:INFO:_display_container: 2
2024-04-29 21:30:05,481:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=3365)
2024-04-29 21:30:05,481:INFO:create_model() successfully completed......................................
2024-04-29 21:30:05,633:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:05,634:INFO:Creating metrics dataframe
2024-04-29 21:30:05,637:INFO:Initializing Gradient Boosting Classifier
2024-04-29 21:30:05,638:INFO:Total runtime is 0.17827775875727334 minutes
2024-04-29 21:30:05,638:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:05,638:INFO:Initializing create_model()
2024-04-29 21:30:05,638:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:05,638:INFO:Checking exceptions
2024-04-29 21:30:05,638:INFO:Importing libraries
2024-04-29 21:30:05,638:INFO:Copying training dataset
2024-04-29 21:30:05,643:WARNING:Processing:  64%|########################################################9                                | 39/61 [00:10<00:05,  4.22it/s]
2024-04-29 21:30:05,644:INFO:Defining folds
2024-04-29 21:30:05,644:INFO:Declaring metric variables
2024-04-29 21:30:05,644:INFO:Importing untrained model
2024-04-29 21:30:05,644:INFO:Gradient Boosting Classifier Imported successfully
2024-04-29 21:30:05,645:INFO:Starting cross validation
2024-04-29 21:30:05,646:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:06,247:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,264:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,270:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,282:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,326:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,346:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,423:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,464:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,882:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,902:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:06,914:INFO:Calculating mean and std
2024-04-29 21:30:06,915:WARNING:Processing:  67%|###########################################################8                             | 41/61 [00:11<00:07,  2.80it/s]
2024-04-29 21:30:06,916:INFO:Creating metrics dataframe
2024-04-29 21:30:06,920:INFO:Uploading results into container
2024-04-29 21:30:06,921:INFO:Uploading model into container now
2024-04-29 21:30:06,922:INFO:_master_model_container: 10
2024-04-29 21:30:06,922:INFO:_display_container: 2
2024-04-29 21:30:06,923:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=3365, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-29 21:30:06,923:INFO:create_model() successfully completed......................................
2024-04-29 21:30:07,043:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:07,044:INFO:Creating metrics dataframe
2024-04-29 21:30:07,047:INFO:Initializing Linear Discriminant Analysis
2024-04-29 21:30:07,047:INFO:Total runtime is 0.20176604986190794 minutes
2024-04-29 21:30:07,048:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:07,048:INFO:Initializing create_model()
2024-04-29 21:30:07,048:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:07,048:INFO:Checking exceptions
2024-04-29 21:30:07,048:INFO:Importing libraries
2024-04-29 21:30:07,048:INFO:Copying training dataset
2024-04-29 21:30:07,054:WARNING:Processing:  70%|##############################################################7                          | 43/61 [00:12<00:04,  3.70it/s]
2024-04-29 21:30:07,054:INFO:Defining folds
2024-04-29 21:30:07,054:INFO:Declaring metric variables
2024-04-29 21:30:07,054:INFO:Importing untrained model
2024-04-29 21:30:07,055:INFO:Linear Discriminant Analysis Imported successfully
2024-04-29 21:30:07,055:INFO:Starting cross validation
2024-04-29 21:30:07,059:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:07,515:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,535:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,601:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,631:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,631:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,644:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,646:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,799:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,815:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:07,838:INFO:Calculating mean and std
2024-04-29 21:30:07,840:WARNING:Processing:  74%|#################################################################6                       | 45/61 [00:12<00:04,  3.25it/s]
2024-04-29 21:30:07,841:INFO:Creating metrics dataframe
2024-04-29 21:30:07,844:INFO:Uploading results into container
2024-04-29 21:30:07,845:INFO:Uploading model into container now
2024-04-29 21:30:07,846:INFO:_master_model_container: 11
2024-04-29 21:30:07,846:INFO:_display_container: 2
2024-04-29 21:30:07,847:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-29 21:30:07,847:INFO:create_model() successfully completed......................................
2024-04-29 21:30:07,988:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:07,988:INFO:Creating metrics dataframe
2024-04-29 21:30:07,991:INFO:Initializing Extra Trees Classifier
2024-04-29 21:30:07,991:INFO:Total runtime is 0.2174919486045837 minutes
2024-04-29 21:30:07,992:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:07,992:INFO:Initializing create_model()
2024-04-29 21:30:07,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:07,992:INFO:Checking exceptions
2024-04-29 21:30:07,992:INFO:Importing libraries
2024-04-29 21:30:07,992:INFO:Copying training dataset
2024-04-29 21:30:07,996:WARNING:Processing:  77%|####################################################################5                    | 47/61 [00:13<00:03,  4.19it/s]
2024-04-29 21:30:07,996:INFO:Defining folds
2024-04-29 21:30:07,996:INFO:Declaring metric variables
2024-04-29 21:30:07,996:INFO:Importing untrained model
2024-04-29 21:30:07,996:INFO:Extra Trees Classifier Imported successfully
2024-04-29 21:30:07,997:INFO:Starting cross validation
2024-04-29 21:30:07,999:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:08,786:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,805:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,805:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,805:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,836:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,838:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,874:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:08,936:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:09,328:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:09,371:INFO:Calculating mean and std
2024-04-29 21:30:09,372:WARNING:Processing:  80%|#######################################################################4                 | 49/61 [00:14<00:04,  2.68it/s]
2024-04-29 21:30:09,372:INFO:Creating metrics dataframe
2024-04-29 21:30:09,375:INFO:Uploading results into container
2024-04-29 21:30:09,376:INFO:Uploading model into container now
2024-04-29 21:30:09,376:INFO:_master_model_container: 12
2024-04-29 21:30:09,377:INFO:_display_container: 2
2024-04-29 21:30:09,377:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=3365, verbose=0,
                     warm_start=False)
2024-04-29 21:30:09,377:INFO:create_model() successfully completed......................................
2024-04-29 21:30:09,525:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:09,525:INFO:Creating metrics dataframe
2024-04-29 21:30:09,533:INFO:Initializing Light Gradient Boosting Machine
2024-04-29 21:30:09,533:INFO:Total runtime is 0.24320049285888667 minutes
2024-04-29 21:30:09,533:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:09,534:INFO:Initializing create_model()
2024-04-29 21:30:09,534:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:09,534:INFO:Checking exceptions
2024-04-29 21:30:09,534:INFO:Importing libraries
2024-04-29 21:30:09,535:INFO:Copying training dataset
2024-04-29 21:30:09,548:WARNING:Processing:  84%|##########################################################################4              | 51/61 [00:14<00:02,  3.48it/s]
2024-04-29 21:30:09,548:INFO:Defining folds
2024-04-29 21:30:09,548:INFO:Declaring metric variables
2024-04-29 21:30:09,548:INFO:Importing untrained model
2024-04-29 21:30:09,549:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-29 21:30:09,549:INFO:Starting cross validation
2024-04-29 21:30:09,552:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:10,332:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,341:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,343:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,351:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,410:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,418:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,423:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,432:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,432:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,439:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,561:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,573:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,616:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,631:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,811:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,821:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,922:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,923:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:10,930:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,932:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:10,947:INFO:Calculating mean and std
2024-04-29 21:30:10,948:WARNING:Processing:  87%|#############################################################################3           | 53/61 [00:16<00:03,  2.43it/s]
2024-04-29 21:30:10,949:INFO:Creating metrics dataframe
2024-04-29 21:30:10,952:INFO:Uploading results into container
2024-04-29 21:30:10,953:INFO:Uploading model into container now
2024-04-29 21:30:10,954:INFO:_master_model_container: 13
2024-04-29 21:30:10,954:INFO:_display_container: 2
2024-04-29 21:30:10,955:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=3365, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-29 21:30:10,955:INFO:create_model() successfully completed......................................
2024-04-29 21:30:11,082:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:11,082:INFO:Creating metrics dataframe
2024-04-29 21:30:11,089:INFO:Initializing Dummy Classifier
2024-04-29 21:30:11,089:INFO:Total runtime is 0.2691371122996012 minutes
2024-04-29 21:30:11,089:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:11,091:INFO:Initializing create_model()
2024-04-29 21:30:11,091:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BA951FC0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:11,091:INFO:Checking exceptions
2024-04-29 21:30:11,091:INFO:Importing libraries
2024-04-29 21:30:11,091:INFO:Copying training dataset
2024-04-29 21:30:11,100:WARNING:Processing:  90%|################################################################################2        | 55/61 [00:16<00:01,  3.22it/s]
2024-04-29 21:30:11,101:INFO:Defining folds
2024-04-29 21:30:11,101:INFO:Declaring metric variables
2024-04-29 21:30:11,101:INFO:Importing untrained model
2024-04-29 21:30:11,102:INFO:Dummy Classifier Imported successfully
2024-04-29 21:30:11,102:INFO:Starting cross validation
2024-04-29 21:30:11,106:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:11,522:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,525:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,533:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,534:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,537:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,540:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,547:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,550:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,563:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,563:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,573:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,602:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,610:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,617:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,627:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,844:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,857:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:11,857:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,873:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:11,900:INFO:Calculating mean and std
2024-04-29 21:30:11,902:WARNING:Processing:  93%|###################################################################################1     | 57/61 [00:16<00:01,  2.96it/s]
2024-04-29 21:30:11,902:INFO:Creating metrics dataframe
2024-04-29 21:30:11,907:INFO:Uploading results into container
2024-04-29 21:30:11,908:INFO:Uploading model into container now
2024-04-29 21:30:11,909:INFO:_master_model_container: 14
2024-04-29 21:30:11,909:INFO:_display_container: 2
2024-04-29 21:30:11,909:INFO:DummyClassifier(constant=None, random_state=3365, strategy='prior')
2024-04-29 21:30:11,909:INFO:create_model() successfully completed......................................
2024-04-29 21:30:12,101:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:12,101:INFO:Creating metrics dataframe
2024-04-29 21:30:12,108:WARNING:Processing:  97%|######################################################################################   | 59/61 [00:17<00:00,  3.74it/s]
2024-04-29 21:30:12,108:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-29 21:30:12,113:INFO:Initializing create_model()
2024-04-29 21:30:12,113:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BB391D80>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3365, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:12,113:INFO:Checking exceptions
2024-04-29 21:30:12,115:INFO:Importing libraries
2024-04-29 21:30:12,115:INFO:Copying training dataset
2024-04-29 21:30:12,126:INFO:Defining folds
2024-04-29 21:30:12,127:INFO:Declaring metric variables
2024-04-29 21:30:12,127:INFO:Importing untrained model
2024-04-29 21:30:12,127:INFO:Declaring custom model
2024-04-29 21:30:12,128:INFO:Logistic Regression Imported successfully
2024-04-29 21:30:12,131:INFO:Cross validation set to False
2024-04-29 21:30:12,132:INFO:Fitting Model
2024-04-29 21:30:12,586:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:12,587:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3365, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:30:12,588:INFO:create_model() successfully completed......................................
2024-04-29 21:30:12,733:WARNING:Processing: 100%|#########################################################################################| 61/61 [00:17<00:00,  3.56it/s]
2024-04-29 21:30:12,733:WARNING:                                                                                                                                          
2024-04-29 21:30:12,746:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2024-04-29 21:30:12,746:INFO:lr                    Logistic Regression    0.8216  0.8620  0.6817  0.8306   
2024-04-29 21:30:12,746:INFO:ridge                    Ridge Classifier    0.7479  0.8466  0.4308  0.8392   
2024-04-29 21:30:12,746:INFO:et                 Extra Trees Classifier    0.7254  0.0000  0.3763  0.8026   
2024-04-29 21:30:12,746:INFO:nb                            Naive Bayes    0.6660  0.0000  0.1589  0.8240   
2024-04-29 21:30:12,746:INFO:rf               Random Forest Classifier    0.6244  0.0000  0.0210  0.3000   
2024-04-29 21:30:12,746:INFO:dt               Decision Tree Classifier    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:12,746:INFO:ada                  Ada Boost Classifier    0.6164  0.5000  0.0000  0.0000   
2024-04-29 21:30:12,746:INFO:gbc          Gradient Boosting Classifier    0.6164  0.5000  0.0000  0.0000   
2024-04-29 21:30:12,746:INFO:lightgbm  Light Gradient Boosting Machine    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:12,746:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:12,746:INFO:lda          Linear Discriminant Analysis    0.6147  0.5274  0.0087  0.0400   
2024-04-29 21:30:12,746:INFO:knn                K Neighbors Classifier    0.6146  0.0000  0.3971  0.5005   
2024-04-29 21:30:12,746:INFO:qda       Quadratic Discriminant Analysis    0.5938  0.4409  0.1000  0.0387   
2024-04-29 21:30:12,746:INFO:svm                   SVM - Linear Kernel    0.5266  0.5908  0.5293  0.4170   
2024-04-29 21:30:12,746:INFO:
2024-04-29 21:30:12,746:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-04-29 21:30:12,746:INFO:lr        0.7460  0.6105  0.6200     0.150  
2024-04-29 21:30:12,746:INFO:ridge     0.5641  0.4128  0.4609     0.097  
2024-04-29 21:30:12,746:INFO:et        0.5077  0.3531  0.4029     0.137  
2024-04-29 21:30:12,746:INFO:nb        0.2632  0.1652  0.2565     0.078  
2024-04-29 21:30:12,746:INFO:rf        0.0391  0.0256  0.0627     0.150  
2024-04-29 21:30:12,746:INFO:dt        0.0000  0.0000  0.0000     0.072  
2024-04-29 21:30:12,747:INFO:ada       0.0000  0.0000  0.0000     0.078  
2024-04-29 21:30:12,747:INFO:gbc       0.0000  0.0000  0.0000     0.127  
2024-04-29 21:30:12,747:INFO:lightgbm  0.0000  0.0000  0.0000     0.140  
2024-04-29 21:30:12,747:INFO:dummy     0.0000  0.0000  0.0000     0.079  
2024-04-29 21:30:12,747:INFO:lda       0.0143  0.0012  0.0018     0.078  
2024-04-29 21:30:12,747:INFO:knn       0.4395  0.1529  0.1569     0.098  
2024-04-29 21:30:12,747:INFO:qda       0.0558  0.0000  0.0000     0.082  
2024-04-29 21:30:12,747:INFO:svm       0.3733  0.0545  0.0671     0.096  
2024-04-29 21:30:12,747:INFO:_master_model_container: 14
2024-04-29 21:30:12,747:INFO:_display_container: 2
2024-04-29 21:30:12,747:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3365, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:30:12,747:INFO:compare_models() successfully completed......................................
2024-04-29 21:30:12,811:INFO:Initializing save_model()
2024-04-29 21:30:12,812:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=3365, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-29 21:30:12,814:INFO:Adding model into prep_pipe
2024-04-29 21:30:12,911:INFO:Transformation Pipeline and Model Successfully Saved
2024-04-29 21:30:12,911:INFO:best_classifier.pkl saved in current working directory
2024-04-29 21:30:12,966:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=3365,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-29 21:30:12,966:INFO:save_model() successfully completed......................................
2024-04-29 21:30:33,157:INFO:PyCaret ClassificationExperiment
2024-04-29 21:30:33,158:INFO:Logging name: clf-default-name
2024-04-29 21:30:33,158:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2024-04-29 21:30:33,158:INFO:version 3.3.1
2024-04-29 21:30:33,158:INFO:Initializing setup()
2024-04-29 21:30:33,158:INFO:self.USI: 3509
2024-04-29 21:30:33,158:INFO:self._variable_keys: {'exp_name_log', 'X_train', 'logging_param', '_available_plots', 'exp_id', 'log_plots_param', 'fold_groups_param', 'is_multiclass', 'target_param', 'idx', 'html_param', 'y', 'USI', '_ml_usecase', 'y_train', 'X_test', 'n_jobs_param', 'data', 'X', 'seed', 'fold_shuffle_param', 'y_test', 'fix_imbalance', 'gpu_param', 'gpu_n_jobs_param', 'memory', 'pipeline', 'fold_generator'}
2024-04-29 21:30:33,158:INFO:Checking environment
2024-04-29 21:30:33,158:INFO:python_version: 3.10.0
2024-04-29 21:30:33,158:INFO:python_build: ('tags/v3.10.0:b494f59', 'Oct  4 2021 19:00:18')
2024-04-29 21:30:33,159:INFO:machine: AMD64
2024-04-29 21:30:33,159:INFO:platform: Windows-10-10.0.22000-SP0
2024-04-29 21:30:33,167:INFO:Memory: svmem(total=8361132032, available=1105371136, percent=86.8, used=7255760896, free=1105371136)
2024-04-29 21:30:33,168:INFO:Physical Core: 4
2024-04-29 21:30:33,168:INFO:Logical Core: 8
2024-04-29 21:30:33,168:INFO:Checking libraries
2024-04-29 21:30:33,168:INFO:System:
2024-04-29 21:30:33,168:INFO:    python: 3.10.0 (tags/v3.10.0:b494f59, Oct  4 2021, 19:00:18) [MSC v.1929 64 bit (AMD64)]
2024-04-29 21:30:33,169:INFO:executable: E:\Python 3.10.0\python.exe
2024-04-29 21:30:33,169:INFO:   machine: Windows-10-10.0.22000-SP0
2024-04-29 21:30:33,169:INFO:PyCaret required dependencies:
2024-04-29 21:30:33,169:INFO:                 pip: 21.2.3
2024-04-29 21:30:33,169:INFO:          setuptools: 57.4.0
2024-04-29 21:30:33,169:INFO:             pycaret: 3.3.1
2024-04-29 21:30:33,169:INFO:             IPython: 8.23.0
2024-04-29 21:30:33,169:INFO:          ipywidgets: 8.1.2
2024-04-29 21:30:33,169:INFO:                tqdm: 4.66.2
2024-04-29 21:30:33,169:INFO:               numpy: 1.26.4
2024-04-29 21:30:33,169:INFO:              pandas: 2.1.4
2024-04-29 21:30:33,169:INFO:              jinja2: 3.1.3
2024-04-29 21:30:33,169:INFO:               scipy: 1.11.4
2024-04-29 21:30:33,169:INFO:              joblib: 1.3.2
2024-04-29 21:30:33,169:INFO:             sklearn: 1.4.2
2024-04-29 21:30:33,169:INFO:                pyod: 1.1.3
2024-04-29 21:30:33,169:INFO:            imblearn: 0.12.2
2024-04-29 21:30:33,169:INFO:   category_encoders: 2.6.3
2024-04-29 21:30:33,170:INFO:            lightgbm: 4.3.0
2024-04-29 21:30:33,170:INFO:               numba: 0.59.1
2024-04-29 21:30:33,170:INFO:            requests: 2.31.0
2024-04-29 21:30:33,170:INFO:          matplotlib: 3.7.5
2024-04-29 21:30:33,170:INFO:          scikitplot: 0.3.7
2024-04-29 21:30:33,170:INFO:         yellowbrick: 1.5
2024-04-29 21:30:33,170:INFO:              plotly: 5.21.0
2024-04-29 21:30:33,170:INFO:    plotly-resampler: Not installed
2024-04-29 21:30:33,170:INFO:             kaleido: 0.2.1
2024-04-29 21:30:33,170:INFO:           schemdraw: 0.15
2024-04-29 21:30:33,170:INFO:         statsmodels: 0.14.2
2024-04-29 21:30:33,170:INFO:              sktime: 0.26.0
2024-04-29 21:30:33,170:INFO:               tbats: 1.1.3
2024-04-29 21:30:33,170:INFO:            pmdarima: 2.0.4
2024-04-29 21:30:33,170:INFO:              psutil: 5.9.8
2024-04-29 21:30:33,170:INFO:          markupsafe: 2.1.5
2024-04-29 21:30:33,170:INFO:             pickle5: Not installed
2024-04-29 21:30:33,171:INFO:         cloudpickle: 3.0.0
2024-04-29 21:30:33,171:INFO:         deprecation: 2.1.0
2024-04-29 21:30:33,171:INFO:              xxhash: 3.4.1
2024-04-29 21:30:33,171:INFO:           wurlitzer: Not installed
2024-04-29 21:30:33,171:INFO:PyCaret optional dependencies:
2024-04-29 21:30:33,171:INFO:                shap: Not installed
2024-04-29 21:30:33,171:INFO:           interpret: Not installed
2024-04-29 21:30:33,171:INFO:                umap: Not installed
2024-04-29 21:30:33,171:INFO:     ydata_profiling: 4.7.0
2024-04-29 21:30:33,171:INFO:  explainerdashboard: Not installed
2024-04-29 21:30:33,171:INFO:             autoviz: Not installed
2024-04-29 21:30:33,171:INFO:           fairlearn: Not installed
2024-04-29 21:30:33,171:INFO:          deepchecks: Not installed
2024-04-29 21:30:33,171:INFO:             xgboost: Not installed
2024-04-29 21:30:33,171:INFO:            catboost: Not installed
2024-04-29 21:30:33,171:INFO:              kmodes: Not installed
2024-04-29 21:30:33,172:INFO:             mlxtend: Not installed
2024-04-29 21:30:33,172:INFO:       statsforecast: Not installed
2024-04-29 21:30:33,172:INFO:        tune_sklearn: Not installed
2024-04-29 21:30:33,172:INFO:                 ray: Not installed
2024-04-29 21:30:33,172:INFO:            hyperopt: Not installed
2024-04-29 21:30:33,172:INFO:              optuna: Not installed
2024-04-29 21:30:33,172:INFO:               skopt: Not installed
2024-04-29 21:30:33,172:INFO:              mlflow: Not installed
2024-04-29 21:30:33,172:INFO:              gradio: Not installed
2024-04-29 21:30:33,172:INFO:             fastapi: Not installed
2024-04-29 21:30:33,172:INFO:             uvicorn: Not installed
2024-04-29 21:30:33,172:INFO:              m2cgen: Not installed
2024-04-29 21:30:33,172:INFO:           evidently: Not installed
2024-04-29 21:30:33,172:INFO:               fugue: Not installed
2024-04-29 21:30:33,172:INFO:           streamlit: 1.33.0
2024-04-29 21:30:33,172:INFO:             prophet: Not installed
2024-04-29 21:30:33,173:INFO:None
2024-04-29 21:30:33,173:INFO:Set up data.
2024-04-29 21:30:33,185:INFO:Set up folding strategy.
2024-04-29 21:30:33,185:INFO:Set up train/test split.
2024-04-29 21:30:33,199:INFO:Set up index.
2024-04-29 21:30:33,199:INFO:Assigning column types.
2024-04-29 21:30:33,207:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2024-04-29 21:30:33,317:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,384:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,385:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,493:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,495:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,531:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,532:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,532:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2024-04-29 21:30:33,604:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,734:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2024-04-29 21:30:33,792:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,793:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2024-04-29 21:30:33,934:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:33,934:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:34,059:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:34,060:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:34,061:INFO:Preparing preprocessing pipeline...
2024-04-29 21:30:34,063:INFO:Set up simple imputation.
2024-04-29 21:30:34,067:INFO:Set up encoding of ordinal features.
2024-04-29 21:30:34,069:INFO:Set up encoding of categorical features.
2024-04-29 21:30:34,310:INFO:Finished creating preprocessing pipeline.
2024-04-29 21:30:34,352:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False)
2024-04-29 21:30:34,352:INFO:Creating final display dataframe.
2024-04-29 21:30:35,041:INFO:Setup _display_container:                     Description             Value
0                    Session id              8840
1                        Target          Survived
2                   Target type            Binary
3           Original data shape         (891, 12)
4        Transformed data shape         (891, 14)
5   Transformed train set shape         (623, 14)
6    Transformed test set shape         (268, 14)
7              Numeric features                 6
8          Categorical features                 5
9      Rows with missing values             79.5%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator   StratifiedKFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  clf-default-name
22                          USI              3509
2024-04-29 21:30:35,051:INFO:                    Description             Value
2024-04-29 21:30:35,051:INFO:0                    Session id              8840
2024-04-29 21:30:35,051:INFO:1                        Target          Survived
2024-04-29 21:30:35,051:INFO:2                   Target type            Binary
2024-04-29 21:30:35,051:INFO:3           Original data shape         (891, 12)
2024-04-29 21:30:35,052:INFO:4        Transformed data shape         (891, 14)
2024-04-29 21:30:35,052:INFO:5   Transformed train set shape         (623, 14)
2024-04-29 21:30:35,052:INFO:6    Transformed test set shape         (268, 14)
2024-04-29 21:30:35,052:INFO:7              Numeric features                 6
2024-04-29 21:30:35,052:INFO:8          Categorical features                 5
2024-04-29 21:30:35,052:INFO:9      Rows with missing values             79.5%
2024-04-29 21:30:35,052:INFO:10                   Preprocess              True
2024-04-29 21:30:35,052:INFO:11              Imputation type            simple
2024-04-29 21:30:35,052:INFO:12           Numeric imputation              mean
2024-04-29 21:30:35,052:INFO:13       Categorical imputation              mode
2024-04-29 21:30:35,052:INFO:14     Maximum one-hot encoding                25
2024-04-29 21:30:35,052:INFO:15              Encoding method              None
2024-04-29 21:30:35,053:INFO:16               Fold Generator   StratifiedKFold
2024-04-29 21:30:35,053:INFO:17                  Fold Number                10
2024-04-29 21:30:35,053:INFO:18                     CPU Jobs                -1
2024-04-29 21:30:35,053:INFO:19                      Use GPU             False
2024-04-29 21:30:35,053:INFO:20               Log Experiment             False
2024-04-29 21:30:35,053:INFO:21              Experiment Name  clf-default-name
2024-04-29 21:30:35,053:INFO:22                          USI              3509
2024-04-29 21:30:35,181:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:35,182:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:35,293:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:35,294:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2024-04-29 21:30:35,295:INFO:setup() successfully completed in 2.14s...............
2024-04-29 21:30:35,300:INFO:Initializing compare_models()
2024-04-29 21:30:35,301:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2024-04-29 21:30:35,301:INFO:Checking exceptions
2024-04-29 21:30:35,311:INFO:Preparing display monitor
2024-04-29 21:30:35,315:WARNING:
2024-04-29 21:30:35,316:WARNING:Processing:   0%|                                                                                                  | 0/61 [00:00<?, ?it/s]
2024-04-29 21:30:35,318:INFO:Initializing Logistic Regression
2024-04-29 21:30:35,321:INFO:Total runtime is 4.2708714803059894e-05 minutes
2024-04-29 21:30:35,322:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:35,323:INFO:Initializing create_model()
2024-04-29 21:30:35,324:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:35,324:INFO:Checking exceptions
2024-04-29 21:30:35,324:INFO:Importing libraries
2024-04-29 21:30:35,324:INFO:Copying training dataset
2024-04-29 21:30:35,343:INFO:Defining folds
2024-04-29 21:30:35,344:INFO:Declaring metric variables
2024-04-29 21:30:35,345:INFO:Importing untrained model
2024-04-29 21:30:35,346:INFO:Logistic Regression Imported successfully
2024-04-29 21:30:35,346:INFO:Starting cross validation
2024-04-29 21:30:35,349:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:36,186:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,193:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,228:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,288:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,294:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,326:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,344:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,361:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,874:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,902:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:36,991:INFO:Calculating mean and std
2024-04-29 21:30:36,993:WARNING:Processing:   8%|#######3                                                                                  | 5/61 [00:01<00:18,  2.98it/s]
2024-04-29 21:30:36,993:INFO:Creating metrics dataframe
2024-04-29 21:30:36,996:INFO:Uploading results into container
2024-04-29 21:30:36,997:INFO:Uploading model into container now
2024-04-29 21:30:36,998:INFO:_master_model_container: 1
2024-04-29 21:30:36,998:INFO:_display_container: 2
2024-04-29 21:30:36,999:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:30:36,999:INFO:create_model() successfully completed......................................
2024-04-29 21:30:37,152:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:37,152:INFO:Creating metrics dataframe
2024-04-29 21:30:37,158:INFO:Initializing K Neighbors Classifier
2024-04-29 21:30:37,158:INFO:Total runtime is 0.030655451615651447 minutes
2024-04-29 21:30:37,158:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:37,159:INFO:Initializing create_model()
2024-04-29 21:30:37,159:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:37,159:INFO:Checking exceptions
2024-04-29 21:30:37,160:INFO:Importing libraries
2024-04-29 21:30:37,160:INFO:Copying training dataset
2024-04-29 21:30:37,169:WARNING:Processing:  11%|##########3                                                                               | 7/61 [00:01<00:13,  4.07it/s]
2024-04-29 21:30:37,169:INFO:Defining folds
2024-04-29 21:30:37,169:INFO:Declaring metric variables
2024-04-29 21:30:37,169:INFO:Importing untrained model
2024-04-29 21:30:37,170:INFO:K Neighbors Classifier Imported successfully
2024-04-29 21:30:37,170:INFO:Starting cross validation
2024-04-29 21:30:37,175:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:37,643:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,647:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,657:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,673:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,676:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,688:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,705:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,721:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,947:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,951:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:37,973:INFO:Calculating mean and std
2024-04-29 21:30:37,974:WARNING:Processing:  15%|#############2                                                                            | 9/61 [00:02<00:15,  3.34it/s]
2024-04-29 21:30:37,974:INFO:Creating metrics dataframe
2024-04-29 21:30:37,978:INFO:Uploading results into container
2024-04-29 21:30:37,979:INFO:Uploading model into container now
2024-04-29 21:30:37,980:INFO:_master_model_container: 2
2024-04-29 21:30:37,980:INFO:_display_container: 2
2024-04-29 21:30:37,981:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2024-04-29 21:30:37,981:INFO:create_model() successfully completed......................................
2024-04-29 21:30:38,100:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:38,100:INFO:Creating metrics dataframe
2024-04-29 21:30:38,104:INFO:Initializing Naive Bayes
2024-04-29 21:30:38,105:INFO:Total runtime is 0.04644226630528768 minutes
2024-04-29 21:30:38,105:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:38,105:INFO:Initializing create_model()
2024-04-29 21:30:38,105:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:38,105:INFO:Checking exceptions
2024-04-29 21:30:38,105:INFO:Importing libraries
2024-04-29 21:30:38,105:INFO:Copying training dataset
2024-04-29 21:30:38,109:WARNING:Processing:  18%|################                                                                         | 11/61 [00:02<00:11,  4.48it/s]
2024-04-29 21:30:38,109:INFO:Defining folds
2024-04-29 21:30:38,109:INFO:Declaring metric variables
2024-04-29 21:30:38,110:INFO:Importing untrained model
2024-04-29 21:30:38,110:INFO:Naive Bayes Imported successfully
2024-04-29 21:30:38,110:INFO:Starting cross validation
2024-04-29 21:30:38,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:38,509:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,514:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,541:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,623:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,624:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,625:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,645:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,655:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,802:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,802:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:38,827:INFO:Calculating mean and std
2024-04-29 21:30:38,827:WARNING:Processing:  21%|##################9                                                                      | 13/61 [00:03<00:12,  3.75it/s]
2024-04-29 21:30:38,827:INFO:Creating metrics dataframe
2024-04-29 21:30:38,831:INFO:Uploading results into container
2024-04-29 21:30:38,832:INFO:Uploading model into container now
2024-04-29 21:30:38,834:INFO:_master_model_container: 3
2024-04-29 21:30:38,834:INFO:_display_container: 2
2024-04-29 21:30:38,834:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2024-04-29 21:30:38,834:INFO:create_model() successfully completed......................................
2024-04-29 21:30:38,983:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:38,985:INFO:Creating metrics dataframe
2024-04-29 21:30:38,992:INFO:Initializing Decision Tree Classifier
2024-04-29 21:30:38,992:INFO:Total runtime is 0.061232535044352214 minutes
2024-04-29 21:30:38,992:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:38,992:INFO:Initializing create_model()
2024-04-29 21:30:38,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:38,992:INFO:Checking exceptions
2024-04-29 21:30:38,992:INFO:Importing libraries
2024-04-29 21:30:38,992:INFO:Copying training dataset
2024-04-29 21:30:39,005:WARNING:Processing:  25%|#####################8                                                                   | 15/61 [00:03<00:09,  4.75it/s]
2024-04-29 21:30:39,005:INFO:Defining folds
2024-04-29 21:30:39,005:INFO:Declaring metric variables
2024-04-29 21:30:39,006:INFO:Importing untrained model
2024-04-29 21:30:39,007:INFO:Decision Tree Classifier Imported successfully
2024-04-29 21:30:39,008:INFO:Starting cross validation
2024-04-29 21:30:39,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:39,425:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,436:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,447:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,460:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,480:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,484:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,491:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,494:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,518:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,520:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,534:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,539:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,553:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,554:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,562:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,562:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,731:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,743:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,757:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:39,768:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:39,792:INFO:Calculating mean and std
2024-04-29 21:30:39,793:WARNING:Processing:  28%|########################8                                                                | 17/61 [00:04<00:11,  3.74it/s]
2024-04-29 21:30:39,794:INFO:Creating metrics dataframe
2024-04-29 21:30:39,799:INFO:Uploading results into container
2024-04-29 21:30:39,800:INFO:Uploading model into container now
2024-04-29 21:30:39,801:INFO:_master_model_container: 4
2024-04-29 21:30:39,801:INFO:_display_container: 2
2024-04-29 21:30:39,802:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=8840, splitter='best')
2024-04-29 21:30:39,802:INFO:create_model() successfully completed......................................
2024-04-29 21:30:39,950:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:39,950:INFO:Creating metrics dataframe
2024-04-29 21:30:39,953:INFO:Initializing SVM - Linear Kernel
2024-04-29 21:30:39,953:INFO:Total runtime is 0.07725221713383992 minutes
2024-04-29 21:30:39,954:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:39,954:INFO:Initializing create_model()
2024-04-29 21:30:39,954:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:39,954:INFO:Checking exceptions
2024-04-29 21:30:39,954:INFO:Importing libraries
2024-04-29 21:30:39,954:INFO:Copying training dataset
2024-04-29 21:30:39,959:WARNING:Processing:  31%|###########################7                                                             | 19/61 [00:04<00:08,  4.74it/s]
2024-04-29 21:30:39,959:INFO:Defining folds
2024-04-29 21:30:39,959:INFO:Declaring metric variables
2024-04-29 21:30:39,959:INFO:Importing untrained model
2024-04-29 21:30:39,960:INFO:SVM - Linear Kernel Imported successfully
2024-04-29 21:30:39,960:INFO:Starting cross validation
2024-04-29 21:30:39,963:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:40,380:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:40,685:INFO:Calculating mean and std
2024-04-29 21:30:40,687:WARNING:Processing:  34%|##############################6                                                          | 21/61 [00:05<00:10,  3.88it/s]
2024-04-29 21:30:40,688:INFO:Creating metrics dataframe
2024-04-29 21:30:40,691:INFO:Uploading results into container
2024-04-29 21:30:40,693:INFO:Uploading model into container now
2024-04-29 21:30:40,694:INFO:_master_model_container: 5
2024-04-29 21:30:40,694:INFO:_display_container: 2
2024-04-29 21:30:40,695:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8840, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2024-04-29 21:30:40,695:INFO:create_model() successfully completed......................................
2024-04-29 21:30:40,846:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:40,847:INFO:Creating metrics dataframe
2024-04-29 21:30:40,854:INFO:Initializing Ridge Classifier
2024-04-29 21:30:40,854:INFO:Total runtime is 0.09226360321044921 minutes
2024-04-29 21:30:40,854:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:40,855:INFO:Initializing create_model()
2024-04-29 21:30:40,855:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:40,855:INFO:Checking exceptions
2024-04-29 21:30:40,855:INFO:Importing libraries
2024-04-29 21:30:40,855:INFO:Copying training dataset
2024-04-29 21:30:40,861:WARNING:Processing:  38%|#################################5                                                       | 23/61 [00:05<00:07,  4.86it/s]
2024-04-29 21:30:40,861:INFO:Defining folds
2024-04-29 21:30:40,862:INFO:Declaring metric variables
2024-04-29 21:30:40,862:INFO:Importing untrained model
2024-04-29 21:30:40,862:INFO:Ridge Classifier Imported successfully
2024-04-29 21:30:40,862:INFO:Starting cross validation
2024-04-29 21:30:40,864:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:41,564:INFO:Calculating mean and std
2024-04-29 21:30:41,565:WARNING:Processing:  41%|####################################4                                                    | 25/61 [00:06<00:09,  4.00it/s]
2024-04-29 21:30:41,566:INFO:Creating metrics dataframe
2024-04-29 21:30:41,570:INFO:Uploading results into container
2024-04-29 21:30:41,571:INFO:Uploading model into container now
2024-04-29 21:30:41,572:INFO:_master_model_container: 6
2024-04-29 21:30:41,573:INFO:_display_container: 2
2024-04-29 21:30:41,573:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8840, solver='auto',
                tol=0.0001)
2024-04-29 21:30:41,573:INFO:create_model() successfully completed......................................
2024-04-29 21:30:41,725:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:41,726:INFO:Creating metrics dataframe
2024-04-29 21:30:41,735:INFO:Initializing Random Forest Classifier
2024-04-29 21:30:41,735:INFO:Total runtime is 0.10694038073221843 minutes
2024-04-29 21:30:41,735:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:41,735:INFO:Initializing create_model()
2024-04-29 21:30:41,736:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:41,736:INFO:Checking exceptions
2024-04-29 21:30:41,736:INFO:Importing libraries
2024-04-29 21:30:41,736:INFO:Copying training dataset
2024-04-29 21:30:41,747:WARNING:Processing:  44%|#######################################3                                                 | 27/61 [00:06<00:06,  4.95it/s]
2024-04-29 21:30:41,747:INFO:Defining folds
2024-04-29 21:30:41,747:INFO:Declaring metric variables
2024-04-29 21:30:41,748:INFO:Importing untrained model
2024-04-29 21:30:41,749:INFO:Random Forest Classifier Imported successfully
2024-04-29 21:30:41,750:INFO:Starting cross validation
2024-04-29 21:30:41,752:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:42,607:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,624:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,630:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,640:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:42,667:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,671:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,683:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:42,688:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,846:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,859:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:42,867:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,202:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:43,227:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:43,239:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,251:INFO:Calculating mean and std
2024-04-29 21:30:43,253:WARNING:Processing:  48%|##########################################3                                              | 29/61 [00:07<00:11,  2.72it/s]
2024-04-29 21:30:43,254:INFO:Creating metrics dataframe
2024-04-29 21:30:43,256:INFO:Uploading results into container
2024-04-29 21:30:43,257:INFO:Uploading model into container now
2024-04-29 21:30:43,257:INFO:_master_model_container: 7
2024-04-29 21:30:43,258:INFO:_display_container: 2
2024-04-29 21:30:43,258:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=8840, verbose=0,
                       warm_start=False)
2024-04-29 21:30:43,258:INFO:create_model() successfully completed......................................
2024-04-29 21:30:43,389:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:43,389:INFO:Creating metrics dataframe
2024-04-29 21:30:43,394:INFO:Initializing Quadratic Discriminant Analysis
2024-04-29 21:30:43,394:INFO:Total runtime is 0.13459890286127726 minutes
2024-04-29 21:30:43,395:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:43,395:INFO:Initializing create_model()
2024-04-29 21:30:43,395:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:43,395:INFO:Checking exceptions
2024-04-29 21:30:43,395:INFO:Importing libraries
2024-04-29 21:30:43,395:INFO:Copying training dataset
2024-04-29 21:30:43,403:WARNING:Processing:  51%|#############################################2                                           | 31/61 [00:08<00:08,  3.57it/s]
2024-04-29 21:30:43,403:INFO:Defining folds
2024-04-29 21:30:43,403:INFO:Declaring metric variables
2024-04-29 21:30:43,403:INFO:Importing untrained model
2024-04-29 21:30:43,404:INFO:Quadratic Discriminant Analysis Imported successfully
2024-04-29 21:30:43,404:INFO:Starting cross validation
2024-04-29 21:30:43,406:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:43,669:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,692:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,695:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,709:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,727:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,746:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,754:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,774:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,790:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,801:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,851:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,853:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,882:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,907:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,927:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:43,980:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:43,990:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\discriminant_analysis.py:935: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2024-04-29 21:30:44,031:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,045:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,051:INFO:Calculating mean and std
2024-04-29 21:30:44,052:WARNING:Processing:  54%|################################################1                                        | 33/61 [00:08<00:08,  3.41it/s]
2024-04-29 21:30:44,052:INFO:Creating metrics dataframe
2024-04-29 21:30:44,053:INFO:Uploading results into container
2024-04-29 21:30:44,054:INFO:Uploading model into container now
2024-04-29 21:30:44,054:INFO:_master_model_container: 8
2024-04-29 21:30:44,054:INFO:_display_container: 2
2024-04-29 21:30:44,055:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2024-04-29 21:30:44,055:INFO:create_model() successfully completed......................................
2024-04-29 21:30:44,187:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:44,188:INFO:Creating metrics dataframe
2024-04-29 21:30:44,195:INFO:Initializing Ada Boost Classifier
2024-04-29 21:30:44,195:INFO:Total runtime is 0.14794681469599405 minutes
2024-04-29 21:30:44,196:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:44,196:INFO:Initializing create_model()
2024-04-29 21:30:44,196:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:44,197:INFO:Checking exceptions
2024-04-29 21:30:44,197:INFO:Importing libraries
2024-04-29 21:30:44,197:INFO:Copying training dataset
2024-04-29 21:30:44,204:WARNING:Processing:  57%|###################################################                                      | 35/61 [00:08<00:05,  4.38it/s]
2024-04-29 21:30:44,204:INFO:Defining folds
2024-04-29 21:30:44,205:INFO:Declaring metric variables
2024-04-29 21:30:44,205:INFO:Importing untrained model
2024-04-29 21:30:44,205:INFO:Ada Boost Classifier Imported successfully
2024-04-29 21:30:44,205:INFO:Starting cross validation
2024-04-29 21:30:44,207:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:44,481:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,485:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,506:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,511:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,520:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,520:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,527:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,602:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,615:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,624:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,636:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,636:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,638:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,652:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,669:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,758:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,779:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2024-04-29 21:30:44,822:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,839:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:44,866:INFO:Calculating mean and std
2024-04-29 21:30:44,868:WARNING:Processing:  61%|#####################################################9                                   | 37/61 [00:09<00:06,  3.86it/s]
2024-04-29 21:30:44,868:INFO:Creating metrics dataframe
2024-04-29 21:30:44,871:INFO:Uploading results into container
2024-04-29 21:30:44,872:INFO:Uploading model into container now
2024-04-29 21:30:44,873:INFO:_master_model_container: 9
2024-04-29 21:30:44,873:INFO:_display_container: 2
2024-04-29 21:30:44,874:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=8840)
2024-04-29 21:30:44,874:INFO:create_model() successfully completed......................................
2024-04-29 21:30:45,037:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:45,037:INFO:Creating metrics dataframe
2024-04-29 21:30:45,044:INFO:Initializing Gradient Boosting Classifier
2024-04-29 21:30:45,044:INFO:Total runtime is 0.16209426323572793 minutes
2024-04-29 21:30:45,044:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:45,045:INFO:Initializing create_model()
2024-04-29 21:30:45,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:45,045:INFO:Checking exceptions
2024-04-29 21:30:45,045:INFO:Importing libraries
2024-04-29 21:30:45,045:INFO:Copying training dataset
2024-04-29 21:30:45,056:WARNING:Processing:  64%|########################################################9                                | 39/61 [00:09<00:04,  4.77it/s]
2024-04-29 21:30:45,056:INFO:Defining folds
2024-04-29 21:30:45,056:INFO:Declaring metric variables
2024-04-29 21:30:45,057:INFO:Importing untrained model
2024-04-29 21:30:45,058:INFO:Gradient Boosting Classifier Imported successfully
2024-04-29 21:30:45,058:INFO:Starting cross validation
2024-04-29 21:30:45,061:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:45,660:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,673:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,702:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,704:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,783:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,784:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,792:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:45,822:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,086:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,107:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,117:INFO:Calculating mean and std
2024-04-29 21:30:46,118:WARNING:Processing:  67%|###########################################################8                             | 41/61 [00:10<00:06,  3.27it/s]
2024-04-29 21:30:46,118:INFO:Creating metrics dataframe
2024-04-29 21:30:46,122:INFO:Uploading results into container
2024-04-29 21:30:46,123:INFO:Uploading model into container now
2024-04-29 21:30:46,124:INFO:_master_model_container: 10
2024-04-29 21:30:46,124:INFO:_display_container: 2
2024-04-29 21:30:46,125:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8840, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2024-04-29 21:30:46,125:INFO:create_model() successfully completed......................................
2024-04-29 21:30:46,268:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:46,268:INFO:Creating metrics dataframe
2024-04-29 21:30:46,273:INFO:Initializing Linear Discriminant Analysis
2024-04-29 21:30:46,273:INFO:Total runtime is 0.1825805346171061 minutes
2024-04-29 21:30:46,274:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:46,274:INFO:Initializing create_model()
2024-04-29 21:30:46,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:46,274:INFO:Checking exceptions
2024-04-29 21:30:46,275:INFO:Importing libraries
2024-04-29 21:30:46,275:INFO:Copying training dataset
2024-04-29 21:30:46,280:WARNING:Processing:  70%|##############################################################7                          | 43/61 [00:10<00:04,  4.19it/s]
2024-04-29 21:30:46,280:INFO:Defining folds
2024-04-29 21:30:46,280:INFO:Declaring metric variables
2024-04-29 21:30:46,280:INFO:Importing untrained model
2024-04-29 21:30:46,281:INFO:Linear Discriminant Analysis Imported successfully
2024-04-29 21:30:46,281:INFO:Starting cross validation
2024-04-29 21:30:46,282:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:46,717:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,721:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,725:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,739:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,746:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,752:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,760:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:46,790:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:47,034:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:47,047:INFO:Calculating mean and std
2024-04-29 21:30:47,048:WARNING:Processing:  74%|#################################################################6                       | 45/61 [00:11<00:04,  3.54it/s]
2024-04-29 21:30:47,048:INFO:Creating metrics dataframe
2024-04-29 21:30:47,052:INFO:Uploading results into container
2024-04-29 21:30:47,053:INFO:Uploading model into container now
2024-04-29 21:30:47,053:INFO:_master_model_container: 11
2024-04-29 21:30:47,054:INFO:_display_container: 2
2024-04-29 21:30:47,054:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2024-04-29 21:30:47,054:INFO:create_model() successfully completed......................................
2024-04-29 21:30:47,199:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:47,200:INFO:Creating metrics dataframe
2024-04-29 21:30:47,206:INFO:Initializing Extra Trees Classifier
2024-04-29 21:30:47,206:INFO:Total runtime is 0.1981205383936564 minutes
2024-04-29 21:30:47,206:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:47,206:INFO:Initializing create_model()
2024-04-29 21:30:47,207:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:47,207:INFO:Checking exceptions
2024-04-29 21:30:47,207:INFO:Importing libraries
2024-04-29 21:30:47,207:INFO:Copying training dataset
2024-04-29 21:30:47,214:WARNING:Processing:  77%|####################################################################5                    | 47/61 [00:11<00:03,  4.50it/s]
2024-04-29 21:30:47,214:INFO:Defining folds
2024-04-29 21:30:47,214:INFO:Declaring metric variables
2024-04-29 21:30:47,214:INFO:Importing untrained model
2024-04-29 21:30:47,215:INFO:Extra Trees Classifier Imported successfully
2024-04-29 21:30:47,215:INFO:Starting cross validation
2024-04-29 21:30:47,217:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:48,058:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,070:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,087:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,107:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,138:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,201:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,237:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,285:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,591:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,592:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:48,627:INFO:Calculating mean and std
2024-04-29 21:30:48,628:WARNING:Processing:  80%|#######################################################################4                 | 49/61 [00:13<00:04,  2.72it/s]
2024-04-29 21:30:48,628:INFO:Creating metrics dataframe
2024-04-29 21:30:48,632:INFO:Uploading results into container
2024-04-29 21:30:48,633:INFO:Uploading model into container now
2024-04-29 21:30:48,634:INFO:_master_model_container: 12
2024-04-29 21:30:48,634:INFO:_display_container: 2
2024-04-29 21:30:48,635:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=8840, verbose=0,
                     warm_start=False)
2024-04-29 21:30:48,635:INFO:create_model() successfully completed......................................
2024-04-29 21:30:48,774:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:48,774:INFO:Creating metrics dataframe
2024-04-29 21:30:48,777:INFO:Initializing Light Gradient Boosting Machine
2024-04-29 21:30:48,777:INFO:Total runtime is 0.22431766986846924 minutes
2024-04-29 21:30:48,777:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:48,778:INFO:Initializing create_model()
2024-04-29 21:30:48,778:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:48,778:INFO:Checking exceptions
2024-04-29 21:30:48,778:INFO:Importing libraries
2024-04-29 21:30:48,778:INFO:Copying training dataset
2024-04-29 21:30:48,783:WARNING:Processing:  84%|##########################################################################4              | 51/61 [00:13<00:02,  3.56it/s]
2024-04-29 21:30:48,783:INFO:Defining folds
2024-04-29 21:30:48,783:INFO:Declaring metric variables
2024-04-29 21:30:48,783:INFO:Importing untrained model
2024-04-29 21:30:48,784:INFO:Light Gradient Boosting Machine Imported successfully
2024-04-29 21:30:48,784:INFO:Starting cross validation
2024-04-29 21:30:48,787:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:49,527:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,540:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,549:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,560:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,574:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,602:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,656:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,670:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,735:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,753:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,821:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:49,831:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:49,991:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,003:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,004:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,013:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,128:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,136:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,137:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,143:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,162:INFO:Calculating mean and std
2024-04-29 21:30:50,163:WARNING:Processing:  87%|#############################################################################3           | 53/61 [00:14<00:03,  2.48it/s]
2024-04-29 21:30:50,163:INFO:Creating metrics dataframe
2024-04-29 21:30:50,166:INFO:Uploading results into container
2024-04-29 21:30:50,166:INFO:Uploading model into container now
2024-04-29 21:30:50,167:INFO:_master_model_container: 13
2024-04-29 21:30:50,167:INFO:_display_container: 2
2024-04-29 21:30:50,168:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8840, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2024-04-29 21:30:50,168:INFO:create_model() successfully completed......................................
2024-04-29 21:30:50,305:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:50,306:INFO:Creating metrics dataframe
2024-04-29 21:30:50,314:INFO:Initializing Dummy Classifier
2024-04-29 21:30:50,314:INFO:Total runtime is 0.24992115100224813 minutes
2024-04-29 21:30:50,314:INFO:SubProcess create_model() called ==================================
2024-04-29 21:30:50,315:INFO:Initializing create_model()
2024-04-29 21:30:50,315:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001E4BC7E1660>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:50,315:INFO:Checking exceptions
2024-04-29 21:30:50,315:INFO:Importing libraries
2024-04-29 21:30:50,315:INFO:Copying training dataset
2024-04-29 21:30:50,334:WARNING:Processing:  90%|################################################################################2        | 55/61 [00:15<00:01,  3.25it/s]
2024-04-29 21:30:50,334:INFO:Defining folds
2024-04-29 21:30:50,334:INFO:Declaring metric variables
2024-04-29 21:30:50,336:INFO:Importing untrained model
2024-04-29 21:30:50,336:INFO:Dummy Classifier Imported successfully
2024-04-29 21:30:50,336:INFO:Starting cross validation
2024-04-29 21:30:50,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2024-04-29 21:30:50,842:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,852:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,853:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,853:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,862:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,863:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,893:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,899:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,911:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,911:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,931:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,932:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,942:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,944:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:50,955:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:50,965:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:51,077:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:51,085:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:51,098:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py:196: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\metrics.py", line 188, in _score
    return super()._score(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 345, in _score
    y_pred = method_caller(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_scorer.py", line 87, in _cached_call
    result, _ = _get_response_values(
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_response.py", line 210, in _get_response_values
    y_pred = prediction_method(X)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\pipeline.py", line 341, in predict_proba
    Xt = transform.transform(Xt)
  File "E:\Python 3.10.0\lib\site-packages\sklearn\utils\_set_output.py", line 295, in wrapped
    data_to_wrap = f(self, X, *args, **kwargs)
  File "E:\Python 3.10.0\lib\site-packages\pycaret\internal\preprocess\transformers.py", line 248, in transform
    args.append(X[self._include])
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\frame.py", line 3899, in __getitem__
    indexer = self.columns._get_indexer_strict(key, "columns")[1]
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6115, in _get_indexer_strict
    self._raise_if_missing(keyarr, indexer, axis_name)
  File "E:\Python 3.10.0\lib\site-packages\pandas\core\indexes\base.py", line 6179, in _raise_if_missing
    raise KeyError(f"{not_found} not in index")
KeyError: "['Embarked'] not in index"

  warnings.warn(

2024-04-29 21:30:51,102:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2024-04-29 21:30:51,114:INFO:Calculating mean and std
2024-04-29 21:30:51,115:WARNING:Processing:  93%|###################################################################################1     | 57/61 [00:15<00:01,  3.00it/s]
2024-04-29 21:30:51,115:INFO:Creating metrics dataframe
2024-04-29 21:30:51,118:INFO:Uploading results into container
2024-04-29 21:30:51,118:INFO:Uploading model into container now
2024-04-29 21:30:51,119:INFO:_master_model_container: 14
2024-04-29 21:30:51,119:INFO:_display_container: 2
2024-04-29 21:30:51,119:INFO:DummyClassifier(constant=None, random_state=8840, strategy='prior')
2024-04-29 21:30:51,119:INFO:create_model() successfully completed......................................
2024-04-29 21:30:51,265:INFO:SubProcess create_model() end ==================================
2024-04-29 21:30:51,266:INFO:Creating metrics dataframe
2024-04-29 21:30:51,272:WARNING:Processing:  97%|######################################################################################   | 59/61 [00:15<00:00,  3.90it/s]
2024-04-29 21:30:51,273:WARNING:E:\Python 3.10.0\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:323: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  master_display_.apply(

2024-04-29 21:30:51,281:INFO:Initializing create_model()
2024-04-29 21:30:51,282:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2024-04-29 21:30:51,283:INFO:Checking exceptions
2024-04-29 21:30:51,284:INFO:Importing libraries
2024-04-29 21:30:51,285:INFO:Copying training dataset
2024-04-29 21:30:51,303:INFO:Defining folds
2024-04-29 21:30:51,303:INFO:Declaring metric variables
2024-04-29 21:30:51,304:INFO:Importing untrained model
2024-04-29 21:30:51,304:INFO:Declaring custom model
2024-04-29 21:30:51,305:INFO:Logistic Regression Imported successfully
2024-04-29 21:30:51,309:INFO:Cross validation set to False
2024-04-29 21:30:51,310:INFO:Fitting Model
2024-04-29 21:30:51,733:WARNING:E:\Python 3.10.0\lib\site-packages\sklearn\linear_model\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
Please also refer to the documentation for alternative solver options:
    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression
  n_iter_i = _check_optimize_result(

2024-04-29 21:30:51,734:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:30:51,734:INFO:create_model() successfully completed......................................
2024-04-29 21:30:51,861:WARNING:Processing: 100%|#########################################################################################| 61/61 [00:16<00:00,  3.73it/s]
2024-04-29 21:30:51,861:WARNING:                                                                                                                                          
2024-04-29 21:30:51,873:INFO:                                    Model  Accuracy     AUC  Recall   Prec.  \
2024-04-29 21:30:51,873:INFO:lr                    Logistic Regression    0.8122  0.8649  0.6902  0.7952   
2024-04-29 21:30:51,873:INFO:ridge                    Ridge Classifier    0.7542  0.8534  0.4520  0.8346   
2024-04-29 21:30:51,873:INFO:et                 Extra Trees Classifier    0.7302  0.0000  0.4062  0.7932   
2024-04-29 21:30:51,873:INFO:nb                            Naive Bayes    0.6580  0.0000  0.1466  0.8390   
2024-04-29 21:30:51,873:INFO:rf               Random Forest Classifier    0.6356  0.0000  0.0500  0.6000   
2024-04-29 21:30:51,873:INFO:lda          Linear Discriminant Analysis    0.6260  0.5248  0.0348  0.0800   
2024-04-29 21:30:51,873:INFO:knn                K Neighbors Classifier    0.6197  0.0000  0.3768  0.5024   
2024-04-29 21:30:51,873:INFO:dt               Decision Tree Classifier    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:51,873:INFO:ada                  Ada Boost Classifier    0.6164  0.5000  0.0000  0.0000   
2024-04-29 21:30:51,873:INFO:gbc          Gradient Boosting Classifier    0.6164  0.5000  0.0000  0.0000   
2024-04-29 21:30:51,873:INFO:lightgbm  Light Gradient Boosting Machine    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:51,873:INFO:dummy                    Dummy Classifier    0.6164  0.0000  0.0000  0.0000   
2024-04-29 21:30:51,873:INFO:svm                   SVM - Linear Kernel    0.5967  0.6162  0.3504  0.5399   
2024-04-29 21:30:51,873:INFO:qda       Quadratic Discriminant Analysis    0.5925  0.5552  0.1000  0.0381   
2024-04-29 21:30:51,873:INFO:
2024-04-29 21:30:51,873:INFO:              F1   Kappa     MCC  TT (Sec)  
2024-04-29 21:30:51,873:INFO:lr        0.7376  0.5926  0.5974     0.164  
2024-04-29 21:30:51,873:INFO:ridge     0.5841  0.4314  0.4733     0.070  
2024-04-29 21:30:51,873:INFO:et        0.5310  0.3711  0.4138     0.141  
2024-04-29 21:30:51,873:INFO:nb        0.2446  0.1453  0.2400     0.071  
2024-04-29 21:30:51,873:INFO:rf        0.0912  0.0602  0.1352     0.150  
2024-04-29 21:30:51,873:INFO:lda       0.0485  0.0335  0.0389     0.076  
2024-04-29 21:30:51,874:INFO:knn       0.4230  0.1533  0.1583     0.080  
2024-04-29 21:30:51,874:INFO:dt        0.0000  0.0000  0.0000     0.078  
2024-04-29 21:30:51,874:INFO:ada       0.0000  0.0000  0.0000     0.066  
2024-04-29 21:30:51,874:INFO:gbc       0.0000  0.0000  0.0000     0.106  
2024-04-29 21:30:51,874:INFO:lightgbm  0.0000  0.0000  0.0000     0.137  
2024-04-29 21:30:51,874:INFO:dummy     0.0000  0.0000  0.0000     0.077  
2024-04-29 21:30:51,874:INFO:svm       0.3234  0.1083  0.1433     0.072  
2024-04-29 21:30:51,874:INFO:qda       0.0552  0.0000  0.0000     0.064  
2024-04-29 21:30:51,874:INFO:_master_model_container: 14
2024-04-29 21:30:51,874:INFO:_display_container: 2
2024-04-29 21:30:51,874:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2024-04-29 21:30:51,874:INFO:compare_models() successfully completed......................................
2024-04-29 21:30:51,932:INFO:Initializing save_model()
2024-04-29 21:30:51,933:INFO:save_model(model=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8840, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), model_name=best_classifier, prep_pipe_=Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categoric...
                                                              return_df=True,
                                                              use_cat_names=True,
                                                              verbose=0))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              drop_invariant=False,
                                                              handle_missing='return_nan',
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0)))],
         verbose=False), verbose=True, use_case=MLUsecase.CLASSIFICATION, kwargs={})
2024-04-29 21:30:51,933:INFO:Adding model into prep_pipe
2024-04-29 21:30:51,949:INFO:Transformation Pipeline and Model Successfully Saved
2024-04-29 21:30:51,950:INFO:best_classifier.pkl saved in current working directory
2024-04-29 21:30:51,994:INFO:Pipeline(memory=Memory(location=None),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None...
                                                              handle_unknown='value',
                                                              hierarchy=None,
                                                              min_samples_leaf=20,
                                                              return_df=True,
                                                              smoothing=10,
                                                              verbose=0))),
                ('trained_model',
                 LogisticRegression(C=1.0, class_weight=None, dual=False,
                                    fit_intercept=True, intercept_scaling=1,
                                    l1_ratio=None, max_iter=1000,
                                    multi_class='auto', n_jobs=None,
                                    penalty='l2', random_state=8840,
                                    solver='lbfgs', tol=0.0001, verbose=0,
                                    warm_start=False))],
         verbose=False)
2024-04-29 21:30:51,995:INFO:save_model() successfully completed......................................
2024-04-29 21:34:08,877:INFO:Initializing load_model()
2024-04-29 21:34:08,878:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-29 21:34:42,046:INFO:Initializing load_model()
2024-04-29 21:34:42,046:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-29 21:36:55,224:INFO:Initializing load_model()
2024-04-29 21:36:55,224:INFO:load_model(model_name=trained_classifier, platform=None, authentication=None, verbose=True)
2024-04-29 21:36:55,243:INFO:Transformation Pipeline and Model Successfully Loaded
2024-04-29 21:36:55,313:INFO:Initializing predict_model()
2024-04-29 21:36:55,313:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001E4BA644E50>, estimator=Pipeline(memory=FastMemory(location=C:\Users\AVIJIT~1\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['PassengerId', 'Pclass', 'Age',
                                             'SibSp', 'Parch', 'Fare'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Name', 'Sex', 'Ticket', 'Cabin',
                                             'Embarked'],
                                    transformer=SimpleImputer(strategy='m...
                 TransformerWrapper(include=['Embarked'],
                                    transformer=OneHotEncoder(cols=['Embarked'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True))),
                ('rest_encoding',
                 TransformerWrapper(include=['Name', 'Ticket', 'Cabin'],
                                    transformer=TargetEncoder(cols=['Name',
                                                                    'Ticket',
                                                                    'Cabin'],
                                                              handle_missing='return_nan'))),
                ('trained_model',
                 LogisticRegression(max_iter=1000, random_state=8840))]), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x000001E4B7EE2050>)
2024-04-29 21:36:55,314:INFO:Checking exceptions
2024-04-29 21:36:55,314:INFO:Preloading libraries
2024-04-29 21:36:55,328:INFO:Set up data.
2024-04-29 21:36:55,348:INFO:Set up index.
2024-04-29 21:41:16,178:WARNING:
2024-04-29 21:41:16,178:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,248:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,253:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,266:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,281:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,281:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,300:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,351:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,355:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,406:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,407:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,426:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,453:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,454:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,462:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,464:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,464:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,465:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,467:WARNING:E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\correlations.py:66: UserWarning: There was an attempt to calculate the auto correlation, but this failed.
To hide this warning, disable the calculation
(using `df.profile_report(correlations={"auto": {"calculate": False}})`
If this is problematic for your use case, please report this as an issue:
https://github.com/ydataai/ydata-profiling/issues
(include the error message: 'Function <code object pandas_auto_compute at 0x000001E4A218BC00, file "E:\Python 3.10.0\lib\site-packages\ydata_profiling\model\pandas\correlations_pandas.py", line 164>')
  warnings.warn(

2024-04-29 21:41:16,467:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,468:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,664:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,664:WARNING: ... (more hidden) ...
2024-04-29 21:41:16,858:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,101:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,323:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,531:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,531:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,797:WARNING: ... (more hidden) ...
2024-04-29 21:41:17,990:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,141:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,141:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,303:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,486:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,486:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,643:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,821:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,821:WARNING: ... (more hidden) ...
2024-04-29 21:41:18,975:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,139:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,139:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,267:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,268:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,398:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,398:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,535:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,535:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,740:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,741:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,950:WARNING: ... (more hidden) ...
2024-04-29 21:41:19,950:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,167:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,168:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,360:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,360:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,603:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,604:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,871:WARNING: ... (more hidden) ...
2024-04-29 21:41:20,872:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,112:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,112:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,337:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,337:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,790:WARNING: ... (more hidden) ...
2024-04-29 21:41:21,790:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,008:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,008:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,264:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,264:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,265:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,282:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,283:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,284:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,285:WARNING: ... (more hidden) ...
2024-04-29 21:41:22,285:WARNING:
2024-04-29 21:41:22,286:WARNING: ... (more hidden) ...
2024-04-29 21:41:33,334:WARNING: ... (more hidden) ...
2024-04-29 21:41:33,335:WARNING: ... (more hidden) ...
2024-04-29 21:41:33,335:WARNING:
2024-04-29 21:41:33,336:WARNING: ... (more hidden) ...
2024-04-29 21:41:35,626:WARNING: ... (more hidden) ...
2024-04-29 21:41:35,627:WARNING: ... (more hidden) ...
2024-04-29 21:41:35,627:WARNING:
